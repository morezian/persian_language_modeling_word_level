{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils import *\n",
    "from data_utils import Vocabulary\n",
    "from train_utils import train\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus_path):\n",
    "    num_lines = len(open(corpus_path, encoding='utf8').read().split('\\n'))\n",
    "    \n",
    "    # tokenize corpus\n",
    "    output = ''\n",
    "    with open(corpus_path, encoding='utf8') as f:\n",
    "        for line in tqdm_notebook(f, desc='Tokenizing', total=num_lines):\n",
    "            tokens = tokenizer(line.strip()) + ['\\n']\n",
    "            output += ' '.join(tokens)\n",
    "    \n",
    "    # save tokenized corpus\n",
    "    tok_corpus_path = corpus_path[:-4] + '_tok.txt'\n",
    "    with open(tok_corpus_path, 'w', encoding='utf8') as f:\n",
    "        f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'moulavi_norm.txt'\n",
    "train_data_tok = train_data[:-4] + '_tok.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f410f3f302ca47bf8698c68804cd405f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Tokenizing', max=53313, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['', '  \\t', 'بشنو این نی چون شکایت می کند', 'از جداییها حکایت می کند', 'کز نیستان تا مرا ببریده اند', 'در نفیرم مرد و زن نالیده اند', 'سینه خواهم شرحه شرحه از فراق', 'تا بگویم شرح درد اشتیاق', 'هر کسی کو دور ماند از اصل خویش', 'باز جوید روزگار وصل خویش']\n",
      "\n",
      "\n",
      "After Tokenizing:\n",
      "\n",
      "\n",
      "[' \\t ', 'بشنو', 'این', 'نی', 'چون', 'شکایت', 'می', 'کند', 'از', 'جداییها', 'حکایت', 'می', 'کند', 'کز', 'نیستان', 'تا', 'مرا', 'ببریده', 'اند', 'در', 'نفیرم', 'مرد', 'و', 'زن', 'نالیده', 'اند', 'سینه', 'خواهم', 'شرحه', 'شرحه', 'از', 'فراق', 'تا', 'بگویم', 'شرح', 'درد', 'اشتیاق', 'هر', 'کسی', 'کو', 'دور', 'ماند', 'از', 'اصل', 'خویش', 'باز', 'جوید', 'روزگار', 'وصل', 'خویش']\n"
     ]
    }
   ],
   "source": [
    "tokenize_corpus(train_data)\n",
    "\n",
    "text = open(train_data, encoding='utf8').read().split('\\n')[:10]\n",
    "print(text)\n",
    "\n",
    "print('\\n\\nAfter Tokenizing:\\n\\n')\n",
    "print(tokenizer('\\n'.join(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    \n",
    "    def __init__(self, corpus_path):\n",
    "        self.vocabulary = Vocabulary()\n",
    "        self.corpus_path = corpus_path\n",
    "        self.num_sentences = len([line for line in open(corpus_path, encoding='utf8')])\n",
    "    \n",
    "    def get_data(self, max_vocab=30000, min_count=3, batch_size=20, split_ratio=0.2):\n",
    "        \n",
    "        # First pass: add words to the vocabulary\n",
    "        trn_tokens, val_tokens = [], []\n",
    "        with open(self.corpus_path, encoding='utf8') as f:\n",
    "            for line in tqdm_notebook(f, desc='Building Vocab...', total=self.num_sentences):\n",
    "                tokens = line.split() + ['<EOS>']\n",
    "                if len(line) <= 10: continue\n",
    "                if random.random() < split_ratio:\n",
    "                    val_tokens += tokens\n",
    "                else:\n",
    "                    trn_tokens += tokens\n",
    "        \n",
    "        counter = Counter(trn_tokens + val_tokens)\n",
    "        \n",
    "        vocabs = [(w, c) for (w, c) in counter.most_common(max_vocab) if c >= min_count]\n",
    "        \n",
    "        for i, (word, count) in enumerate(vocabs):\n",
    "            self.vocabulary.word2index[word] = i\n",
    "            self.vocabulary.word2count[word] = count\n",
    "            self.vocabulary.index2word[i] = word\n",
    "            self.vocabulary.num_words += 1\n",
    "        self.vocabulary.add_word('<UNK>')\n",
    "        \n",
    "        \n",
    "        UNK_TOKEN = self.vocabulary.word2index['<UNK>']\n",
    "        \n",
    "        # train ids\n",
    "        trn_ids = torch.LongTensor(len(trn_tokens))\n",
    "        for idx, token in enumerate(trn_tokens):\n",
    "            if token in self.vocabulary.word2index:\n",
    "                trn_ids[idx] = self.vocabulary.word2index[token] \n",
    "            else:\n",
    "                trn_ids[idx] = UNK_TOKEN\n",
    "        \n",
    "        val_ids = torch.LongTensor(len(val_tokens))\n",
    "        for idx, token in enumerate(val_tokens):\n",
    "            if token in self.vocabulary.word2index:\n",
    "                val_ids[idx] = self.vocabulary.word2index[token] \n",
    "            else:\n",
    "                val_ids[idx] = UNK_TOKEN\n",
    "        \n",
    "        num_batches = trn_ids.size(0) // batch_size\n",
    "        trn_ids = trn_ids[: num_batches * batch_size]\n",
    "        \n",
    "        num_batches = val_ids.size(0) // batch_size\n",
    "        val_ids = trn_ids[: num_batches * batch_size]\n",
    "\n",
    "        return trn_ids.view(batch_size, -1), val_ids.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 30000\n",
    "min_count = 1\n",
    "\n",
    "# LSTM hyper-parameters\n",
    "embed_size = 1500\n",
    "hidden_size = 1500\n",
    "num_layers = 2\n",
    "\n",
    "# Training hyper-parameters\n",
    "num_epochs = 40\n",
    "batch_size = 50\n",
    "seq_length = 60\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45337728c05b4a418386eadddbe5d4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Building Vocab...', max=53313, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(train_data_tok)\n",
    "trn_ids, val_ids = corpus.get_data(max_vocab, min_count, batch_size)\n",
    "vocab_size = len(corpus.vocabulary)\n",
    "\n",
    "# save vocabs and ids\n",
    "pickle.dump(corpus.vocabulary, open('vocab.pkl', 'wb'))\n",
    "np.save('trn_ids.npy', trn_ids.view(-1).numpy())\n",
    "np.save('val_ids.npy', val_ids.view(-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25175\n",
      "torch.Size([50, 6341])\n",
      "torch.Size([50, 1571])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(corpus.vocabulary)\n",
    "print(vocab_size)\n",
    "print(trn_ids.size())\n",
    "print(val_ids.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EOS> 52956\n",
      "و 12871\n",
      "از 7709\n",
      "را 6764\n",
      "در 6362\n",
      "که 6355\n",
      "آن 5799\n",
      "تو 4578\n",
      "می 4078\n",
      "او 3878\n",
      "بر 3873\n",
      "ای 3650\n",
      "این 3496\n",
      "چون 3398\n",
      "ز 3286\n",
      "به 2848\n",
      "تا 2847\n",
      "من 2821\n",
      "بود 2163\n",
      "هر 2092\n"
     ]
    }
   ],
   "source": [
    "most_commons = [(w, c) for (w, c) in corpus.vocabulary.word2count.items()][:20]\n",
    "\n",
    "for w, c in most_commons:\n",
    "    print(w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_LM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1, drop=0.35, tie=True):\n",
    "        super(LSTM_LM, self).__init__()\n",
    "        \n",
    "        if tie:\n",
    "            embed_size = hidden_size\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "            \n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, dropout=0.35)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        if tie:\n",
    "            # Use the same weights both for embedding and classification\n",
    "            self.fc.weight.data = self.embedding.weight.data\n",
    "            \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.fc.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (to_var(torch.zeros(self.num_layers, batch_size, self.hidden_size)),\n",
    "                to_var(torch.zeros(self.num_layers, batch_size, self.hidden_size)))\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # embed word ids to vectors\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)  # DROPOUT\n",
    "        \n",
    "        # forward RNN step\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        x = self.dropout(x)  # DROPOUT\n",
    "        \n",
    "        # reshape output to (bs * seq_length, hidden_size)\n",
    "        x = x.contiguous().view(x.size(0) * x.size(1), x.size(2))\n",
    "        \n",
    "        # decode hidden states of all time steps\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x, hidden\n",
    "    \n",
    "    def save(self, epoch, loss):\n",
    "        filename = 'lm-masnavi-epoch-{}-em-{}-hi-{}-nl-{}-{:.2f}-{:.2f}.pth'.format(\n",
    "            epoch, self.embed_size, self.hidden_size, self.num_layers, loss, np.exp(loss))\n",
    "        torch.save(self.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.init()\n",
    "# # model\n",
    "model = LSTM_LM(vocab_size, embed_size, hidden_size, num_layers, drop=0.65).cuda()\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    \n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamarez/Language_model/utils.py:13: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(x, volatile=volatile)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mamarez/Language_model/train_utils.py:38: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [1/40], Step [1/105], Loss: 10.131, Perp: 25106.65, Acc: 0.00           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [2/105], Loss: 10.128, Perp: 25027.48, Acc: 0.00           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [3/105], Loss: 10.159, Perp: 25811.83, Acc: 0.00           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [4/105], Loss: 10.155, Perp: 25719.59, Acc: 0.00           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [5/105], Loss: 10.151, Perp: 25607.64, Acc: 0.00           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [6/105], Loss: 10.145, Perp: 25462.66, Acc: 0.00           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [7/105], Loss: 10.139, Perp: 25311.25, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [8/105], Loss: 10.134, Perp: 25183.54, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [9/105], Loss: 10.129, Perp: 25067.94, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [10/105], Loss: 10.125, Perp: 24954.01, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [11/105], Loss: 10.120, Perp: 24841.75, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [12/105], Loss: 10.116, Perp: 24740.49, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [13/105], Loss: 10.112, Perp: 24644.92, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [14/105], Loss: 10.109, Perp: 24552.92, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [15/105], Loss: 10.105, Perp: 24466.35, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [16/105], Loss: 10.102, Perp: 24383.54, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [17/105], Loss: 10.099, Perp: 24306.65, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [18/105], Loss: 10.096, Perp: 24235.34, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [19/105], Loss: 10.093, Perp: 24165.47, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [20/105], Loss: 10.090, Perp: 24098.71, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [21/105], Loss: 10.087, Perp: 24036.13, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [22/105], Loss: 10.085, Perp: 23975.81, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [23/105], Loss: 10.082, Perp: 23917.57, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [24/105], Loss: 10.080, Perp: 23860.86, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [25/105], Loss: 10.078, Perp: 23807.25, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [26/105], Loss: 10.076, Perp: 23755.77, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [27/105], Loss: 10.073, Perp: 23705.39, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [28/105], Loss: 10.071, Perp: 23656.77, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [29/105], Loss: 10.069, Perp: 23610.27, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [30/105], Loss: 10.068, Perp: 23564.83, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [31/105], Loss: 10.066, Perp: 23521.67, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [32/105], Loss: 10.064, Perp: 23479.13, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [33/105], Loss: 10.062, Perp: 23438.61, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [34/105], Loss: 10.060, Perp: 23398.78, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [35/105], Loss: 10.059, Perp: 23359.75, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [36/105], Loss: 10.057, Perp: 23321.84, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [37/105], Loss: 10.056, Perp: 23284.68, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [38/105], Loss: 10.054, Perp: 23248.72, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [39/105], Loss: 10.052, Perp: 23213.63, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [40/105], Loss: 10.051, Perp: 23179.36, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [41/105], Loss: 10.050, Perp: 23146.88, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [42/105], Loss: 10.048, Perp: 23115.11, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [43/105], Loss: 10.047, Perp: 23083.75, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [44/105], Loss: 10.046, Perp: 23052.99, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [45/105], Loss: 10.044, Perp: 23023.14, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [46/105], Loss: 10.043, Perp: 22994.48, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [47/105], Loss: 10.042, Perp: 22965.30, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [48/105], Loss: 10.041, Perp: 22937.69, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [49/105], Loss: 10.039, Perp: 22910.29, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [50/105], Loss: 10.038, Perp: 22882.69, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [51/105], Loss: 10.037, Perp: 22856.04, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [52/105], Loss: 10.036, Perp: 22829.73, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [53/105], Loss: 10.035, Perp: 22804.66, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [54/105], Loss: 10.034, Perp: 22780.00, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [55/105], Loss: 10.033, Perp: 22755.65, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [56/105], Loss: 10.032, Perp: 22732.15, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [57/105], Loss: 10.031, Perp: 22709.05, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [58/105], Loss: 10.030, Perp: 22686.14, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [59/105], Loss: 10.029, Perp: 22663.64, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [60/105], Loss: 10.028, Perp: 22641.11, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [61/105], Loss: 10.027, Perp: 22619.54, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [62/105], Loss: 10.026, Perp: 22597.94, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [63/105], Loss: 10.025, Perp: 22576.69, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [64/105], Loss: 10.024, Perp: 22556.10, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [65/105], Loss: 10.023, Perp: 22535.86, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [66/105], Loss: 10.022, Perp: 22515.60, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [67/105], Loss: 10.021, Perp: 22495.68, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [68/105], Loss: 10.020, Perp: 22476.43, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [69/105], Loss: 10.019, Perp: 22457.45, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [70/105], Loss: 10.019, Perp: 22438.39, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [71/105], Loss: 10.018, Perp: 22420.08, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [72/105], Loss: 10.017, Perp: 22401.46, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [73/105], Loss: 10.016, Perp: 22383.56, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [74/105], Loss: 10.015, Perp: 22365.82, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [75/105], Loss: 10.015, Perp: 22348.19, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [76/105], Loss: 10.014, Perp: 22330.70, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [77/105], Loss: 10.013, Perp: 22313.18, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [78/105], Loss: 10.012, Perp: 22295.97, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [79/105], Loss: 10.011, Perp: 22279.11, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [80/105], Loss: 10.011, Perp: 22262.22, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [81/105], Loss: 10.010, Perp: 22245.74, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [82/105], Loss: 10.009, Perp: 22229.81, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [83/105], Loss: 10.008, Perp: 22213.93, Acc: 0.01           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [1/40], Step [84/105], Loss: 10.008, Perp: 22198.44, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [85/105], Loss: 10.007, Perp: 22182.97, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [86/105], Loss: 10.006, Perp: 22167.47, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [87/105], Loss: 10.006, Perp: 22151.81, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [88/105], Loss: 10.005, Perp: 22137.17, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [89/105], Loss: 10.004, Perp: 22122.55, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [90/105], Loss: 10.004, Perp: 22107.59, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [91/105], Loss: 10.003, Perp: 22093.02, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [92/105], Loss: 10.002, Perp: 22078.53, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [93/105], Loss: 10.002, Perp: 22064.41, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [94/105], Loss: 10.001, Perp: 22050.20, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [95/105], Loss: 10.000, Perp: 22036.56, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [96/105], Loss: 10.000, Perp: 22022.70, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [97/105], Loss: 9.999, Perp: 22009.06, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [98/105], Loss: 9.999, Perp: 21995.50, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [99/105], Loss: 9.998, Perp: 21981.88, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [100/105], Loss: 9.997, Perp: 21968.63, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [101/105], Loss: 9.997, Perp: 21955.65, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [102/105], Loss: 9.996, Perp: 21942.92, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [103/105], Loss: 9.996, Perp: 21930.42, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [104/105], Loss: 9.995, Perp: 21917.78, Acc: 0.01           here\n",
      "here\n",
      "Training: Epoch [1/40], Step [105/105], Loss: 9.994, Perp: 21905.47, Acc: 0.01           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [1/26], Loss: 6.262, Perp: 524.11, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [2/26], Loss: 6.260, Perp: 523.16, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [3/26], Loss: 6.259, Perp: 522.73, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [4/26], Loss: 6.259, Perp: 522.60, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [5/26], Loss: 6.259, Perp: 522.46, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [6/26], Loss: 6.258, Perp: 522.31, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [7/26], Loss: 6.258, Perp: 522.19, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [8/26], Loss: 6.258, Perp: 522.13, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [9/26], Loss: 6.258, Perp: 522.04, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [10/26], Loss: 6.258, Perp: 521.98, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [11/26], Loss: 6.258, Perp: 521.95, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [12/26], Loss: 6.257, Perp: 521.91, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [13/26], Loss: 6.257, Perp: 521.91, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [14/26], Loss: 6.257, Perp: 521.86, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [15/26], Loss: 6.257, Perp: 521.87, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [16/26], Loss: 6.257, Perp: 521.81, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [17/26], Loss: 6.257, Perp: 521.75, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [18/26], Loss: 6.257, Perp: 521.74, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [19/26], Loss: 6.257, Perp: 521.75, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [20/26], Loss: 6.257, Perp: 521.70, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [21/26], Loss: 6.257, Perp: 521.70, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [22/26], Loss: 6.257, Perp: 521.65, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [23/26], Loss: 6.257, Perp: 521.68, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [24/26], Loss: 6.257, Perp: 521.66, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [25/26], Loss: 6.257, Perp: 521.65, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [1/40], Step [26/26], Loss: 6.257, Perp: 521.64, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [1/105], Loss: 6.491, Perp: 659.32, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [2/105], Loss: 6.489, Perp: 657.65, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [3/105], Loss: 6.488, Perp: 656.98, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [4/105], Loss: 6.487, Perp: 656.44, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [5/105], Loss: 6.486, Perp: 655.98, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [6/105], Loss: 6.486, Perp: 655.68, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [7/105], Loss: 6.485, Perp: 655.35, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [8/105], Loss: 6.485, Perp: 655.13, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [9/105], Loss: 6.485, Perp: 655.02, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [10/105], Loss: 6.484, Perp: 654.83, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [11/105], Loss: 6.484, Perp: 654.63, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [12/105], Loss: 6.484, Perp: 654.49, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [13/105], Loss: 6.484, Perp: 654.37, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [14/105], Loss: 6.483, Perp: 654.21, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [15/105], Loss: 6.483, Perp: 654.09, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [16/105], Loss: 6.483, Perp: 653.96, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [17/105], Loss: 6.483, Perp: 653.87, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [18/105], Loss: 6.483, Perp: 653.86, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [19/105], Loss: 6.483, Perp: 653.78, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [20/105], Loss: 6.483, Perp: 653.68, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [21/105], Loss: 6.483, Perp: 653.63, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [22/105], Loss: 6.482, Perp: 653.58, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [23/105], Loss: 6.482, Perp: 653.52, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [24/105], Loss: 6.482, Perp: 653.44, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [25/105], Loss: 6.482, Perp: 653.37, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [26/105], Loss: 6.482, Perp: 653.31, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [27/105], Loss: 6.482, Perp: 653.23, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [28/105], Loss: 6.482, Perp: 653.17, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [29/105], Loss: 6.482, Perp: 653.12, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [30/105], Loss: 6.482, Perp: 653.06, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [31/105], Loss: 6.482, Perp: 653.01, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [32/105], Loss: 6.482, Perp: 652.95, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [33/105], Loss: 6.481, Perp: 652.91, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [34/105], Loss: 6.481, Perp: 652.87, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [35/105], Loss: 6.481, Perp: 652.82, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [36/105], Loss: 6.481, Perp: 652.76, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [37/105], Loss: 6.481, Perp: 652.70, Acc: 0.16           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [2/40], Step [38/105], Loss: 6.481, Perp: 652.64, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [39/105], Loss: 6.481, Perp: 652.58, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [40/105], Loss: 6.481, Perp: 652.52, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [41/105], Loss: 6.481, Perp: 652.49, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [42/105], Loss: 6.481, Perp: 652.46, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [43/105], Loss: 6.481, Perp: 652.41, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [44/105], Loss: 6.481, Perp: 652.36, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [45/105], Loss: 6.481, Perp: 652.32, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [46/105], Loss: 6.481, Perp: 652.30, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [47/105], Loss: 6.480, Perp: 652.24, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [48/105], Loss: 6.480, Perp: 652.21, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [49/105], Loss: 6.480, Perp: 652.16, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [50/105], Loss: 6.480, Perp: 652.11, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [51/105], Loss: 6.480, Perp: 652.06, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [52/105], Loss: 6.480, Perp: 652.00, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [53/105], Loss: 6.480, Perp: 651.97, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [54/105], Loss: 6.480, Perp: 651.94, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [55/105], Loss: 6.480, Perp: 651.89, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [56/105], Loss: 6.480, Perp: 651.87, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [57/105], Loss: 6.480, Perp: 651.84, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [58/105], Loss: 6.480, Perp: 651.81, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [59/105], Loss: 6.480, Perp: 651.77, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [60/105], Loss: 6.480, Perp: 651.72, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [61/105], Loss: 6.480, Perp: 651.69, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [62/105], Loss: 6.479, Perp: 651.64, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [63/105], Loss: 6.479, Perp: 651.62, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [64/105], Loss: 6.479, Perp: 651.59, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [65/105], Loss: 6.479, Perp: 651.56, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [66/105], Loss: 6.479, Perp: 651.52, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [67/105], Loss: 6.479, Perp: 651.49, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [68/105], Loss: 6.479, Perp: 651.46, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [69/105], Loss: 6.479, Perp: 651.43, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [70/105], Loss: 6.479, Perp: 651.39, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [71/105], Loss: 6.479, Perp: 651.37, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [72/105], Loss: 6.479, Perp: 651.33, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [73/105], Loss: 6.479, Perp: 651.30, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [74/105], Loss: 6.479, Perp: 651.27, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [75/105], Loss: 6.479, Perp: 651.24, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [76/105], Loss: 6.479, Perp: 651.20, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [77/105], Loss: 6.479, Perp: 651.16, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [78/105], Loss: 6.479, Perp: 651.12, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [79/105], Loss: 6.479, Perp: 651.08, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [80/105], Loss: 6.479, Perp: 651.04, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [81/105], Loss: 6.479, Perp: 651.00, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [82/105], Loss: 6.478, Perp: 650.97, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [83/105], Loss: 6.478, Perp: 650.94, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [84/105], Loss: 6.478, Perp: 650.91, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [85/105], Loss: 6.478, Perp: 650.89, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [86/105], Loss: 6.478, Perp: 650.85, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [87/105], Loss: 6.478, Perp: 650.80, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [88/105], Loss: 6.478, Perp: 650.78, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [89/105], Loss: 6.478, Perp: 650.75, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [90/105], Loss: 6.478, Perp: 650.71, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [91/105], Loss: 6.478, Perp: 650.68, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [92/105], Loss: 6.478, Perp: 650.65, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [93/105], Loss: 6.478, Perp: 650.62, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [94/105], Loss: 6.478, Perp: 650.58, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [95/105], Loss: 6.478, Perp: 650.56, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [96/105], Loss: 6.478, Perp: 650.52, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [97/105], Loss: 6.478, Perp: 650.49, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [98/105], Loss: 6.478, Perp: 650.46, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [99/105], Loss: 6.478, Perp: 650.42, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [100/105], Loss: 6.478, Perp: 650.39, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [101/105], Loss: 6.478, Perp: 650.36, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [102/105], Loss: 6.477, Perp: 650.34, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [103/105], Loss: 6.477, Perp: 650.31, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [104/105], Loss: 6.477, Perp: 650.28, Acc: 0.16           here\n",
      "here\n",
      "Training: Epoch [2/40], Step [105/105], Loss: 6.477, Perp: 650.27, Acc: 0.16           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [1/26], Loss: 6.040, Perp: 420.03, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [2/26], Loss: 6.039, Perp: 419.27, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [3/26], Loss: 6.038, Perp: 418.86, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [4/26], Loss: 6.037, Perp: 418.72, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [5/26], Loss: 6.037, Perp: 418.58, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [6/26], Loss: 6.037, Perp: 418.45, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [7/26], Loss: 6.036, Perp: 418.34, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [8/26], Loss: 6.036, Perp: 418.27, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [9/26], Loss: 6.036, Perp: 418.19, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [10/26], Loss: 6.036, Perp: 418.14, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [11/26], Loss: 6.036, Perp: 418.11, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [12/26], Loss: 6.036, Perp: 418.07, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [13/26], Loss: 6.036, Perp: 418.07, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [14/26], Loss: 6.036, Perp: 418.02, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [15/26], Loss: 6.036, Perp: 418.03, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [16/26], Loss: 6.035, Perp: 417.97, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [17/26], Loss: 6.035, Perp: 417.92, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [18/26], Loss: 6.035, Perp: 417.91, Acc: 0.18           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [2/40], Step [19/26], Loss: 6.035, Perp: 417.91, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [20/26], Loss: 6.035, Perp: 417.87, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [21/26], Loss: 6.035, Perp: 417.86, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [22/26], Loss: 6.035, Perp: 417.82, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [23/26], Loss: 6.035, Perp: 417.84, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [24/26], Loss: 6.035, Perp: 417.82, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [25/26], Loss: 6.035, Perp: 417.81, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [2/40], Step [26/26], Loss: 6.035, Perp: 417.80, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [1/105], Loss: 6.261, Perp: 523.84, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [2/105], Loss: 6.259, Perp: 522.80, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [3/105], Loss: 6.258, Perp: 522.32, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [4/105], Loss: 6.258, Perp: 521.98, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [5/105], Loss: 6.257, Perp: 521.71, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [6/105], Loss: 6.257, Perp: 521.57, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [7/105], Loss: 6.257, Perp: 521.41, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [8/105], Loss: 6.256, Perp: 521.27, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [9/105], Loss: 6.256, Perp: 521.24, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [10/105], Loss: 6.256, Perp: 521.11, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [11/105], Loss: 6.256, Perp: 521.01, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [12/105], Loss: 6.256, Perp: 520.93, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [13/105], Loss: 6.255, Perp: 520.86, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [14/105], Loss: 6.255, Perp: 520.76, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [15/105], Loss: 6.255, Perp: 520.68, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [16/105], Loss: 6.255, Perp: 520.62, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [17/105], Loss: 6.255, Perp: 520.57, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [18/105], Loss: 6.255, Perp: 520.57, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [19/105], Loss: 6.255, Perp: 520.52, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [20/105], Loss: 6.255, Perp: 520.47, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [21/105], Loss: 6.255, Perp: 520.45, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [22/105], Loss: 6.255, Perp: 520.43, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [23/105], Loss: 6.255, Perp: 520.38, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [24/105], Loss: 6.254, Perp: 520.33, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [25/105], Loss: 6.254, Perp: 520.28, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [26/105], Loss: 6.254, Perp: 520.26, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [27/105], Loss: 6.254, Perp: 520.22, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [28/105], Loss: 6.254, Perp: 520.17, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [29/105], Loss: 6.254, Perp: 520.15, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [30/105], Loss: 6.254, Perp: 520.12, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [31/105], Loss: 6.254, Perp: 520.09, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [32/105], Loss: 6.254, Perp: 520.04, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [33/105], Loss: 6.254, Perp: 520.02, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [34/105], Loss: 6.254, Perp: 519.99, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [35/105], Loss: 6.254, Perp: 519.94, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [36/105], Loss: 6.254, Perp: 519.91, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [37/105], Loss: 6.254, Perp: 519.87, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [38/105], Loss: 6.254, Perp: 519.83, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [39/105], Loss: 6.253, Perp: 519.79, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [40/105], Loss: 6.253, Perp: 519.75, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [41/105], Loss: 6.253, Perp: 519.74, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [42/105], Loss: 6.253, Perp: 519.72, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [43/105], Loss: 6.253, Perp: 519.69, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [44/105], Loss: 6.253, Perp: 519.65, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [45/105], Loss: 6.253, Perp: 519.63, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [46/105], Loss: 6.253, Perp: 519.61, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [47/105], Loss: 6.253, Perp: 519.58, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [48/105], Loss: 6.253, Perp: 519.55, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [49/105], Loss: 6.253, Perp: 519.53, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [50/105], Loss: 6.253, Perp: 519.49, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [51/105], Loss: 6.253, Perp: 519.46, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [52/105], Loss: 6.253, Perp: 519.42, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [53/105], Loss: 6.253, Perp: 519.40, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [54/105], Loss: 6.253, Perp: 519.37, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [55/105], Loss: 6.253, Perp: 519.34, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [56/105], Loss: 6.253, Perp: 519.33, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [57/105], Loss: 6.253, Perp: 519.31, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [58/105], Loss: 6.252, Perp: 519.29, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [59/105], Loss: 6.252, Perp: 519.26, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [60/105], Loss: 6.252, Perp: 519.23, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [61/105], Loss: 6.252, Perp: 519.20, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [62/105], Loss: 6.252, Perp: 519.17, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [63/105], Loss: 6.252, Perp: 519.15, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [64/105], Loss: 6.252, Perp: 519.14, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [65/105], Loss: 6.252, Perp: 519.13, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [66/105], Loss: 6.252, Perp: 519.10, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [67/105], Loss: 6.252, Perp: 519.07, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [68/105], Loss: 6.252, Perp: 519.05, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [69/105], Loss: 6.252, Perp: 519.03, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [70/105], Loss: 6.252, Perp: 519.01, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [71/105], Loss: 6.252, Perp: 519.00, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [72/105], Loss: 6.252, Perp: 518.97, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [73/105], Loss: 6.252, Perp: 518.96, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [74/105], Loss: 6.252, Perp: 518.94, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [75/105], Loss: 6.252, Perp: 518.91, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [76/105], Loss: 6.252, Perp: 518.89, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [77/105], Loss: 6.252, Perp: 518.86, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [78/105], Loss: 6.252, Perp: 518.83, Acc: 0.17           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [3/40], Step [79/105], Loss: 6.252, Perp: 518.81, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [80/105], Loss: 6.251, Perp: 518.78, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [81/105], Loss: 6.251, Perp: 518.75, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [82/105], Loss: 6.251, Perp: 518.73, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [83/105], Loss: 6.251, Perp: 518.71, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [84/105], Loss: 6.251, Perp: 518.69, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [85/105], Loss: 6.251, Perp: 518.67, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [86/105], Loss: 6.251, Perp: 518.65, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [87/105], Loss: 6.251, Perp: 518.62, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [88/105], Loss: 6.251, Perp: 518.60, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [89/105], Loss: 6.251, Perp: 518.59, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [90/105], Loss: 6.251, Perp: 518.56, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [91/105], Loss: 6.251, Perp: 518.54, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [92/105], Loss: 6.251, Perp: 518.51, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [93/105], Loss: 6.251, Perp: 518.50, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [94/105], Loss: 6.251, Perp: 518.48, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [95/105], Loss: 6.251, Perp: 518.46, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [96/105], Loss: 6.251, Perp: 518.44, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [97/105], Loss: 6.251, Perp: 518.42, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [98/105], Loss: 6.251, Perp: 518.40, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [99/105], Loss: 6.251, Perp: 518.37, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [100/105], Loss: 6.251, Perp: 518.35, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [101/105], Loss: 6.251, Perp: 518.33, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [102/105], Loss: 6.251, Perp: 518.32, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [103/105], Loss: 6.251, Perp: 518.31, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [104/105], Loss: 6.251, Perp: 518.29, Acc: 0.17           here\n",
      "here\n",
      "Training: Epoch [3/40], Step [105/105], Loss: 6.251, Perp: 518.28, Acc: 0.17           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [1/26], Loss: 5.889, Perp: 360.98, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [2/26], Loss: 5.887, Perp: 360.29, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [3/26], Loss: 5.886, Perp: 359.91, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [4/26], Loss: 5.885, Perp: 359.75, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [5/26], Loss: 5.885, Perp: 359.61, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [6/26], Loss: 5.885, Perp: 359.47, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [7/26], Loss: 5.884, Perp: 359.36, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [8/26], Loss: 5.884, Perp: 359.30, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [9/26], Loss: 5.884, Perp: 359.22, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [10/26], Loss: 5.884, Perp: 359.16, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [11/26], Loss: 5.884, Perp: 359.13, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [12/26], Loss: 5.884, Perp: 359.09, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [13/26], Loss: 5.884, Perp: 359.08, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [14/26], Loss: 5.883, Perp: 359.03, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [15/26], Loss: 5.883, Perp: 359.04, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [16/26], Loss: 5.883, Perp: 358.98, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [17/26], Loss: 5.883, Perp: 358.94, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [18/26], Loss: 5.883, Perp: 358.92, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [19/26], Loss: 5.883, Perp: 358.91, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [20/26], Loss: 5.883, Perp: 358.87, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [21/26], Loss: 5.883, Perp: 358.86, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [22/26], Loss: 5.883, Perp: 358.82, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [23/26], Loss: 5.883, Perp: 358.84, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [24/26], Loss: 5.883, Perp: 358.82, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [25/26], Loss: 5.883, Perp: 358.80, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [3/40], Step [26/26], Loss: 5.883, Perp: 358.79, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [1/105], Loss: 6.084, Perp: 438.84, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [2/105], Loss: 6.082, Perp: 437.82, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [3/105], Loss: 6.081, Perp: 437.43, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [4/105], Loss: 6.080, Perp: 437.09, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [5/105], Loss: 6.080, Perp: 436.85, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [6/105], Loss: 6.079, Perp: 436.76, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [7/105], Loss: 6.079, Perp: 436.62, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [8/105], Loss: 6.079, Perp: 436.51, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [9/105], Loss: 6.079, Perp: 436.47, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [10/105], Loss: 6.079, Perp: 436.38, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [11/105], Loss: 6.078, Perp: 436.29, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [12/105], Loss: 6.078, Perp: 436.22, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [13/105], Loss: 6.078, Perp: 436.17, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [14/105], Loss: 6.078, Perp: 436.10, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [15/105], Loss: 6.078, Perp: 436.03, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [16/105], Loss: 6.078, Perp: 435.96, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [17/105], Loss: 6.077, Perp: 435.92, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [18/105], Loss: 6.077, Perp: 435.92, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [19/105], Loss: 6.077, Perp: 435.88, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [20/105], Loss: 6.077, Perp: 435.83, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [21/105], Loss: 6.077, Perp: 435.82, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [22/105], Loss: 6.077, Perp: 435.79, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [23/105], Loss: 6.077, Perp: 435.76, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [24/105], Loss: 6.077, Perp: 435.72, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [25/105], Loss: 6.077, Perp: 435.68, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [26/105], Loss: 6.077, Perp: 435.66, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [27/105], Loss: 6.077, Perp: 435.62, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [28/105], Loss: 6.077, Perp: 435.58, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [29/105], Loss: 6.077, Perp: 435.56, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [30/105], Loss: 6.077, Perp: 435.52, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [31/105], Loss: 6.076, Perp: 435.50, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [32/105], Loss: 6.076, Perp: 435.46, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [33/105], Loss: 6.076, Perp: 435.43, Acc: 0.18           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [4/40], Step [34/105], Loss: 6.076, Perp: 435.40, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [35/105], Loss: 6.076, Perp: 435.36, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [36/105], Loss: 6.076, Perp: 435.33, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [37/105], Loss: 6.076, Perp: 435.29, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [38/105], Loss: 6.076, Perp: 435.25, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [39/105], Loss: 6.076, Perp: 435.22, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [40/105], Loss: 6.076, Perp: 435.18, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [41/105], Loss: 6.076, Perp: 435.17, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [42/105], Loss: 6.076, Perp: 435.15, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [43/105], Loss: 6.076, Perp: 435.12, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [44/105], Loss: 6.076, Perp: 435.09, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [45/105], Loss: 6.075, Perp: 435.06, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [46/105], Loss: 6.075, Perp: 435.05, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [47/105], Loss: 6.075, Perp: 435.02, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [48/105], Loss: 6.075, Perp: 434.99, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [49/105], Loss: 6.075, Perp: 434.97, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [50/105], Loss: 6.075, Perp: 434.93, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [51/105], Loss: 6.075, Perp: 434.90, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [52/105], Loss: 6.075, Perp: 434.87, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [53/105], Loss: 6.075, Perp: 434.85, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [54/105], Loss: 6.075, Perp: 434.83, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [55/105], Loss: 6.075, Perp: 434.80, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [56/105], Loss: 6.075, Perp: 434.78, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [57/105], Loss: 6.075, Perp: 434.77, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [58/105], Loss: 6.075, Perp: 434.75, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [59/105], Loss: 6.075, Perp: 434.73, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [60/105], Loss: 6.075, Perp: 434.69, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [61/105], Loss: 6.075, Perp: 434.67, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [62/105], Loss: 6.075, Perp: 434.65, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [63/105], Loss: 6.074, Perp: 434.63, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [64/105], Loss: 6.074, Perp: 434.62, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [65/105], Loss: 6.074, Perp: 434.60, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [66/105], Loss: 6.074, Perp: 434.58, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [67/105], Loss: 6.074, Perp: 434.55, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [68/105], Loss: 6.074, Perp: 434.54, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [69/105], Loss: 6.074, Perp: 434.51, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [70/105], Loss: 6.074, Perp: 434.50, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [71/105], Loss: 6.074, Perp: 434.48, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [72/105], Loss: 6.074, Perp: 434.45, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [73/105], Loss: 6.074, Perp: 434.44, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [74/105], Loss: 6.074, Perp: 434.42, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [75/105], Loss: 6.074, Perp: 434.40, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [76/105], Loss: 6.074, Perp: 434.38, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [77/105], Loss: 6.074, Perp: 434.35, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [78/105], Loss: 6.074, Perp: 434.33, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [79/105], Loss: 6.074, Perp: 434.30, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [80/105], Loss: 6.074, Perp: 434.28, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [81/105], Loss: 6.074, Perp: 434.26, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [82/105], Loss: 6.074, Perp: 434.24, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [83/105], Loss: 6.074, Perp: 434.22, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [84/105], Loss: 6.074, Perp: 434.20, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [85/105], Loss: 6.073, Perp: 434.18, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [86/105], Loss: 6.073, Perp: 434.16, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [87/105], Loss: 6.073, Perp: 434.13, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [88/105], Loss: 6.073, Perp: 434.12, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [89/105], Loss: 6.073, Perp: 434.10, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [90/105], Loss: 6.073, Perp: 434.08, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [91/105], Loss: 6.073, Perp: 434.06, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [92/105], Loss: 6.073, Perp: 434.04, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [93/105], Loss: 6.073, Perp: 434.03, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [94/105], Loss: 6.073, Perp: 434.01, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [95/105], Loss: 6.073, Perp: 433.99, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [96/105], Loss: 6.073, Perp: 433.97, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [97/105], Loss: 6.073, Perp: 433.96, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [98/105], Loss: 6.073, Perp: 433.94, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [99/105], Loss: 6.073, Perp: 433.91, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [100/105], Loss: 6.073, Perp: 433.89, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [101/105], Loss: 6.073, Perp: 433.88, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [102/105], Loss: 6.073, Perp: 433.86, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [103/105], Loss: 6.073, Perp: 433.85, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [104/105], Loss: 6.073, Perp: 433.83, Acc: 0.18           here\n",
      "here\n",
      "Training: Epoch [4/40], Step [105/105], Loss: 6.073, Perp: 433.82, Acc: 0.18           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [1/26], Loss: 5.716, Perp: 303.66, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [2/26], Loss: 5.714, Perp: 302.99, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [3/26], Loss: 5.712, Perp: 302.60, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [4/26], Loss: 5.712, Perp: 302.42, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [5/26], Loss: 5.711, Perp: 302.24, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [6/26], Loss: 5.711, Perp: 302.09, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [7/26], Loss: 5.710, Perp: 301.96, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [8/26], Loss: 5.710, Perp: 301.88, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [9/26], Loss: 5.710, Perp: 301.78, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [10/26], Loss: 5.709, Perp: 301.72, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [11/26], Loss: 5.709, Perp: 301.67, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [12/26], Loss: 5.709, Perp: 301.62, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [13/26], Loss: 5.709, Perp: 301.58, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [14/26], Loss: 5.709, Perp: 301.52, Acc: 0.20           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [4/40], Step [15/26], Loss: 5.709, Perp: 301.51, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [16/26], Loss: 5.709, Perp: 301.44, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [17/26], Loss: 5.708, Perp: 301.39, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [18/26], Loss: 5.708, Perp: 301.36, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [19/26], Loss: 5.708, Perp: 301.34, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [20/26], Loss: 5.708, Perp: 301.29, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [21/26], Loss: 5.708, Perp: 301.27, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [22/26], Loss: 5.708, Perp: 301.22, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [23/26], Loss: 5.708, Perp: 301.22, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [24/26], Loss: 5.708, Perp: 301.19, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [25/26], Loss: 5.708, Perp: 301.16, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [4/40], Step [26/26], Loss: 5.708, Perp: 301.14, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [1/105], Loss: 5.889, Perp: 361.17, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [2/105], Loss: 5.887, Perp: 360.48, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [3/105], Loss: 5.887, Perp: 360.24, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [4/105], Loss: 5.886, Perp: 360.05, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [5/105], Loss: 5.886, Perp: 359.91, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [6/105], Loss: 5.886, Perp: 359.84, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [7/105], Loss: 5.885, Perp: 359.77, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [8/105], Loss: 5.885, Perp: 359.68, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [9/105], Loss: 5.885, Perp: 359.66, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [10/105], Loss: 5.885, Perp: 359.61, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [11/105], Loss: 5.885, Perp: 359.57, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [12/105], Loss: 5.885, Perp: 359.52, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [13/105], Loss: 5.885, Perp: 359.50, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [14/105], Loss: 5.885, Perp: 359.45, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [15/105], Loss: 5.884, Perp: 359.41, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [16/105], Loss: 5.884, Perp: 359.37, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [17/105], Loss: 5.884, Perp: 359.35, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [18/105], Loss: 5.884, Perp: 359.35, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [19/105], Loss: 5.884, Perp: 359.33, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [20/105], Loss: 5.884, Perp: 359.29, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [21/105], Loss: 5.884, Perp: 359.29, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [22/105], Loss: 5.884, Perp: 359.28, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [23/105], Loss: 5.884, Perp: 359.26, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [24/105], Loss: 5.884, Perp: 359.23, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [25/105], Loss: 5.884, Perp: 359.20, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [26/105], Loss: 5.884, Perp: 359.19, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [27/105], Loss: 5.884, Perp: 359.16, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [28/105], Loss: 5.884, Perp: 359.13, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [29/105], Loss: 5.884, Perp: 359.11, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [30/105], Loss: 5.884, Perp: 359.09, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [31/105], Loss: 5.884, Perp: 359.07, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [32/105], Loss: 5.883, Perp: 359.04, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [33/105], Loss: 5.883, Perp: 359.01, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [34/105], Loss: 5.883, Perp: 358.99, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [35/105], Loss: 5.883, Perp: 358.96, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [36/105], Loss: 5.883, Perp: 358.94, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [37/105], Loss: 5.883, Perp: 358.91, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [38/105], Loss: 5.883, Perp: 358.88, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [39/105], Loss: 5.883, Perp: 358.85, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [40/105], Loss: 5.883, Perp: 358.83, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [41/105], Loss: 5.883, Perp: 358.82, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [42/105], Loss: 5.883, Perp: 358.80, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [43/105], Loss: 5.883, Perp: 358.78, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [44/105], Loss: 5.883, Perp: 358.75, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [45/105], Loss: 5.883, Perp: 358.74, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [46/105], Loss: 5.883, Perp: 358.72, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [47/105], Loss: 5.882, Perp: 358.70, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [48/105], Loss: 5.882, Perp: 358.68, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [49/105], Loss: 5.882, Perp: 358.67, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [50/105], Loss: 5.882, Perp: 358.64, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [51/105], Loss: 5.882, Perp: 358.62, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [52/105], Loss: 5.882, Perp: 358.59, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [53/105], Loss: 5.882, Perp: 358.58, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [54/105], Loss: 5.882, Perp: 358.56, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [55/105], Loss: 5.882, Perp: 358.54, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [56/105], Loss: 5.882, Perp: 358.52, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [57/105], Loss: 5.882, Perp: 358.51, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [58/105], Loss: 5.882, Perp: 358.49, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [59/105], Loss: 5.882, Perp: 358.47, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [60/105], Loss: 5.882, Perp: 358.45, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [61/105], Loss: 5.882, Perp: 358.44, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [62/105], Loss: 5.882, Perp: 358.42, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [63/105], Loss: 5.882, Perp: 358.40, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [64/105], Loss: 5.882, Perp: 358.39, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [65/105], Loss: 5.882, Perp: 358.38, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [66/105], Loss: 5.882, Perp: 358.36, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [67/105], Loss: 5.882, Perp: 358.35, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [68/105], Loss: 5.881, Perp: 358.33, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [69/105], Loss: 5.881, Perp: 358.32, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [70/105], Loss: 5.881, Perp: 358.30, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [71/105], Loss: 5.881, Perp: 358.29, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [72/105], Loss: 5.881, Perp: 358.27, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [73/105], Loss: 5.881, Perp: 358.26, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [74/105], Loss: 5.881, Perp: 358.25, Acc: 0.19           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [5/40], Step [75/105], Loss: 5.881, Perp: 358.23, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [76/105], Loss: 5.881, Perp: 358.21, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [77/105], Loss: 5.881, Perp: 358.19, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [78/105], Loss: 5.881, Perp: 358.17, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [79/105], Loss: 5.881, Perp: 358.15, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [80/105], Loss: 5.881, Perp: 358.13, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [81/105], Loss: 5.881, Perp: 358.12, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [82/105], Loss: 5.881, Perp: 358.10, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [83/105], Loss: 5.881, Perp: 358.08, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [84/105], Loss: 5.881, Perp: 358.07, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [85/105], Loss: 5.881, Perp: 358.06, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [86/105], Loss: 5.881, Perp: 358.04, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [87/105], Loss: 5.881, Perp: 358.02, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [88/105], Loss: 5.881, Perp: 358.00, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [89/105], Loss: 5.881, Perp: 357.99, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [90/105], Loss: 5.880, Perp: 357.97, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [91/105], Loss: 5.880, Perp: 357.96, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [92/105], Loss: 5.880, Perp: 357.94, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [93/105], Loss: 5.880, Perp: 357.93, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [94/105], Loss: 5.880, Perp: 357.91, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [95/105], Loss: 5.880, Perp: 357.90, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [96/105], Loss: 5.880, Perp: 357.89, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [97/105], Loss: 5.880, Perp: 357.88, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [98/105], Loss: 5.880, Perp: 357.86, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [99/105], Loss: 5.880, Perp: 357.84, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [100/105], Loss: 5.880, Perp: 357.83, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [101/105], Loss: 5.880, Perp: 357.81, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [102/105], Loss: 5.880, Perp: 357.80, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [103/105], Loss: 5.880, Perp: 357.79, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [104/105], Loss: 5.880, Perp: 357.77, Acc: 0.19           here\n",
      "here\n",
      "Training: Epoch [5/40], Step [105/105], Loss: 5.880, Perp: 357.76, Acc: 0.19           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [1/26], Loss: 5.473, Perp: 238.10, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [2/26], Loss: 5.470, Perp: 237.51, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [3/26], Loss: 5.469, Perp: 237.19, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [4/26], Loss: 5.468, Perp: 237.05, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [5/26], Loss: 5.468, Perp: 236.91, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [6/26], Loss: 5.467, Perp: 236.80, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [7/26], Loss: 5.467, Perp: 236.70, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [8/26], Loss: 5.467, Perp: 236.64, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [9/26], Loss: 5.466, Perp: 236.58, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [10/26], Loss: 5.466, Perp: 236.53, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [11/26], Loss: 5.466, Perp: 236.50, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [12/26], Loss: 5.466, Perp: 236.46, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [13/26], Loss: 5.466, Perp: 236.43, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [14/26], Loss: 5.465, Perp: 236.39, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [15/26], Loss: 5.465, Perp: 236.38, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [16/26], Loss: 5.465, Perp: 236.33, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [17/26], Loss: 5.465, Perp: 236.29, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [18/26], Loss: 5.465, Perp: 236.27, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [19/26], Loss: 5.465, Perp: 236.26, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [20/26], Loss: 5.465, Perp: 236.23, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [21/26], Loss: 5.465, Perp: 236.21, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [22/26], Loss: 5.465, Perp: 236.18, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [23/26], Loss: 5.465, Perp: 236.18, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [24/26], Loss: 5.465, Perp: 236.16, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [25/26], Loss: 5.464, Perp: 236.14, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [5/40], Step [26/26], Loss: 5.464, Perp: 236.13, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [1/105], Loss: 5.730, Perp: 307.99, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [2/105], Loss: 5.728, Perp: 307.32, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [3/105], Loss: 5.727, Perp: 307.05, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [4/105], Loss: 5.727, Perp: 306.90, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [5/105], Loss: 5.726, Perp: 306.76, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [6/105], Loss: 5.726, Perp: 306.64, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [7/105], Loss: 5.725, Perp: 306.57, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [8/105], Loss: 5.725, Perp: 306.50, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [9/105], Loss: 5.725, Perp: 306.53, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [10/105], Loss: 5.725, Perp: 306.52, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [11/105], Loss: 5.725, Perp: 306.50, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [12/105], Loss: 5.725, Perp: 306.48, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [13/105], Loss: 5.725, Perp: 306.46, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [14/105], Loss: 5.725, Perp: 306.44, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [15/105], Loss: 5.725, Perp: 306.41, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [16/105], Loss: 5.725, Perp: 306.39, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [17/105], Loss: 5.725, Perp: 306.37, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [18/105], Loss: 5.725, Perp: 306.37, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [19/105], Loss: 5.725, Perp: 306.36, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [20/105], Loss: 5.725, Perp: 306.33, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [21/105], Loss: 5.725, Perp: 306.33, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [22/105], Loss: 5.725, Perp: 306.33, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [23/105], Loss: 5.725, Perp: 306.31, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [24/105], Loss: 5.725, Perp: 306.28, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [25/105], Loss: 5.724, Perp: 306.25, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [26/105], Loss: 5.724, Perp: 306.24, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [27/105], Loss: 5.724, Perp: 306.21, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [28/105], Loss: 5.724, Perp: 306.18, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [29/105], Loss: 5.724, Perp: 306.17, Acc: 0.20           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [6/40], Step [30/105], Loss: 5.724, Perp: 306.15, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [31/105], Loss: 5.724, Perp: 306.14, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [32/105], Loss: 5.724, Perp: 306.11, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [33/105], Loss: 5.724, Perp: 306.09, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [34/105], Loss: 5.724, Perp: 306.07, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [35/105], Loss: 5.724, Perp: 306.04, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [36/105], Loss: 5.724, Perp: 306.03, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [37/105], Loss: 5.724, Perp: 306.00, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [38/105], Loss: 5.724, Perp: 305.98, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [39/105], Loss: 5.723, Perp: 305.96, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [40/105], Loss: 5.723, Perp: 305.94, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [41/105], Loss: 5.723, Perp: 305.93, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [42/105], Loss: 5.723, Perp: 305.91, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [43/105], Loss: 5.723, Perp: 305.89, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [44/105], Loss: 5.723, Perp: 305.87, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [45/105], Loss: 5.723, Perp: 305.86, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [46/105], Loss: 5.723, Perp: 305.84, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [47/105], Loss: 5.723, Perp: 305.82, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [48/105], Loss: 5.723, Perp: 305.81, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [49/105], Loss: 5.723, Perp: 305.80, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [50/105], Loss: 5.723, Perp: 305.77, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [51/105], Loss: 5.723, Perp: 305.75, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [52/105], Loss: 5.723, Perp: 305.73, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [53/105], Loss: 5.723, Perp: 305.72, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [54/105], Loss: 5.723, Perp: 305.70, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [55/105], Loss: 5.723, Perp: 305.68, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [56/105], Loss: 5.722, Perp: 305.67, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [57/105], Loss: 5.722, Perp: 305.65, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [58/105], Loss: 5.722, Perp: 305.64, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [59/105], Loss: 5.722, Perp: 305.62, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [60/105], Loss: 5.722, Perp: 305.60, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [61/105], Loss: 5.722, Perp: 305.59, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [62/105], Loss: 5.722, Perp: 305.57, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [63/105], Loss: 5.722, Perp: 305.56, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [64/105], Loss: 5.722, Perp: 305.54, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [65/105], Loss: 5.722, Perp: 305.53, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [66/105], Loss: 5.722, Perp: 305.52, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [67/105], Loss: 5.722, Perp: 305.50, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [68/105], Loss: 5.722, Perp: 305.49, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [69/105], Loss: 5.722, Perp: 305.48, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [70/105], Loss: 5.722, Perp: 305.46, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [71/105], Loss: 5.722, Perp: 305.45, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [72/105], Loss: 5.722, Perp: 305.44, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [73/105], Loss: 5.722, Perp: 305.42, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [74/105], Loss: 5.722, Perp: 305.41, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [75/105], Loss: 5.722, Perp: 305.40, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [76/105], Loss: 5.722, Perp: 305.38, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [77/105], Loss: 5.722, Perp: 305.37, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [78/105], Loss: 5.721, Perp: 305.35, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [79/105], Loss: 5.721, Perp: 305.33, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [80/105], Loss: 5.721, Perp: 305.31, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [81/105], Loss: 5.721, Perp: 305.30, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [82/105], Loss: 5.721, Perp: 305.28, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [83/105], Loss: 5.721, Perp: 305.27, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [84/105], Loss: 5.721, Perp: 305.25, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [85/105], Loss: 5.721, Perp: 305.24, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [86/105], Loss: 5.721, Perp: 305.23, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [87/105], Loss: 5.721, Perp: 305.21, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [88/105], Loss: 5.721, Perp: 305.20, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [89/105], Loss: 5.721, Perp: 305.19, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [90/105], Loss: 5.721, Perp: 305.17, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [91/105], Loss: 5.721, Perp: 305.15, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [92/105], Loss: 5.721, Perp: 305.14, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [93/105], Loss: 5.721, Perp: 305.13, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [94/105], Loss: 5.721, Perp: 305.11, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [95/105], Loss: 5.721, Perp: 305.10, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [96/105], Loss: 5.721, Perp: 305.09, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [97/105], Loss: 5.721, Perp: 305.08, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [98/105], Loss: 5.721, Perp: 305.06, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [99/105], Loss: 5.720, Perp: 305.05, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [100/105], Loss: 5.720, Perp: 305.03, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [101/105], Loss: 5.720, Perp: 305.02, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [102/105], Loss: 5.720, Perp: 305.01, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [103/105], Loss: 5.720, Perp: 305.00, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [104/105], Loss: 5.720, Perp: 304.98, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [6/40], Step [105/105], Loss: 5.720, Perp: 304.98, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [1/26], Loss: 5.311, Perp: 202.63, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [2/26], Loss: 5.308, Perp: 202.02, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [3/26], Loss: 5.307, Perp: 201.74, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [4/26], Loss: 5.306, Perp: 201.60, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [5/26], Loss: 5.306, Perp: 201.45, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [6/26], Loss: 5.305, Perp: 201.33, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [7/26], Loss: 5.305, Perp: 201.24, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [8/26], Loss: 5.304, Perp: 201.18, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [9/26], Loss: 5.304, Perp: 201.12, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [10/26], Loss: 5.304, Perp: 201.08, Acc: 0.22           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [6/40], Step [11/26], Loss: 5.304, Perp: 201.05, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [12/26], Loss: 5.303, Perp: 201.00, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [13/26], Loss: 5.303, Perp: 200.97, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [14/26], Loss: 5.303, Perp: 200.92, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [15/26], Loss: 5.303, Perp: 200.91, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [16/26], Loss: 5.303, Perp: 200.86, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [17/26], Loss: 5.302, Perp: 200.82, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [18/26], Loss: 5.302, Perp: 200.80, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [19/26], Loss: 5.302, Perp: 200.78, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [20/26], Loss: 5.302, Perp: 200.75, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [21/26], Loss: 5.302, Perp: 200.73, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [22/26], Loss: 5.302, Perp: 200.70, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [23/26], Loss: 5.302, Perp: 200.70, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [24/26], Loss: 5.302, Perp: 200.67, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [25/26], Loss: 5.302, Perp: 200.65, Acc: 0.22           here\n",
      "here\n",
      "Validation: Epoch [6/40], Step [26/26], Loss: 5.302, Perp: 200.64, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [1/105], Loss: 5.562, Perp: 260.25, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [2/105], Loss: 5.559, Perp: 259.69, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [3/105], Loss: 5.559, Perp: 259.53, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [4/105], Loss: 5.559, Perp: 259.44, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [5/105], Loss: 5.558, Perp: 259.31, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [6/105], Loss: 5.558, Perp: 259.24, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [7/105], Loss: 5.557, Perp: 259.17, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [8/105], Loss: 5.557, Perp: 259.10, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [9/105], Loss: 5.557, Perp: 259.08, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [10/105], Loss: 5.557, Perp: 259.02, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [11/105], Loss: 5.557, Perp: 258.98, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [12/105], Loss: 5.557, Perp: 258.94, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [13/105], Loss: 5.557, Perp: 258.92, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [14/105], Loss: 5.556, Perp: 258.89, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [15/105], Loss: 5.556, Perp: 258.87, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [16/105], Loss: 5.556, Perp: 258.84, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [17/105], Loss: 5.556, Perp: 258.83, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [18/105], Loss: 5.556, Perp: 258.83, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [19/105], Loss: 5.556, Perp: 258.81, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [20/105], Loss: 5.556, Perp: 258.79, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [21/105], Loss: 5.556, Perp: 258.79, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [22/105], Loss: 5.556, Perp: 258.78, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [23/105], Loss: 5.556, Perp: 258.76, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [24/105], Loss: 5.556, Perp: 258.75, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [25/105], Loss: 5.556, Perp: 258.72, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [26/105], Loss: 5.556, Perp: 258.70, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [27/105], Loss: 5.556, Perp: 258.68, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [28/105], Loss: 5.555, Perp: 258.65, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [29/105], Loss: 5.555, Perp: 258.64, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [30/105], Loss: 5.555, Perp: 258.62, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [31/105], Loss: 5.555, Perp: 258.60, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [32/105], Loss: 5.555, Perp: 258.58, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [33/105], Loss: 5.555, Perp: 258.55, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [34/105], Loss: 5.555, Perp: 258.53, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [35/105], Loss: 5.555, Perp: 258.51, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [36/105], Loss: 5.555, Perp: 258.50, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [37/105], Loss: 5.555, Perp: 258.47, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [38/105], Loss: 5.555, Perp: 258.45, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [39/105], Loss: 5.555, Perp: 258.43, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [40/105], Loss: 5.555, Perp: 258.41, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [41/105], Loss: 5.555, Perp: 258.41, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [42/105], Loss: 5.554, Perp: 258.40, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [43/105], Loss: 5.554, Perp: 258.38, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [44/105], Loss: 5.554, Perp: 258.36, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [45/105], Loss: 5.554, Perp: 258.35, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [46/105], Loss: 5.554, Perp: 258.33, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [47/105], Loss: 5.554, Perp: 258.31, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [48/105], Loss: 5.554, Perp: 258.30, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [49/105], Loss: 5.554, Perp: 258.28, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [50/105], Loss: 5.554, Perp: 258.27, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [51/105], Loss: 5.554, Perp: 258.25, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [52/105], Loss: 5.554, Perp: 258.23, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [53/105], Loss: 5.554, Perp: 258.22, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [54/105], Loss: 5.554, Perp: 258.21, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [55/105], Loss: 5.554, Perp: 258.19, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [56/105], Loss: 5.554, Perp: 258.18, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [57/105], Loss: 5.554, Perp: 258.17, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [58/105], Loss: 5.554, Perp: 258.15, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [59/105], Loss: 5.554, Perp: 258.14, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [60/105], Loss: 5.553, Perp: 258.12, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [61/105], Loss: 5.553, Perp: 258.11, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [62/105], Loss: 5.553, Perp: 258.09, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [63/105], Loss: 5.553, Perp: 258.09, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [64/105], Loss: 5.553, Perp: 258.07, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [65/105], Loss: 5.553, Perp: 258.06, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [66/105], Loss: 5.553, Perp: 258.05, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [67/105], Loss: 5.553, Perp: 258.04, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [68/105], Loss: 5.553, Perp: 258.03, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [69/105], Loss: 5.553, Perp: 258.02, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [70/105], Loss: 5.553, Perp: 258.01, Acc: 0.20           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [7/40], Step [71/105], Loss: 5.553, Perp: 258.00, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [72/105], Loss: 5.553, Perp: 257.98, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [73/105], Loss: 5.553, Perp: 257.97, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [74/105], Loss: 5.553, Perp: 257.96, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [75/105], Loss: 5.553, Perp: 257.95, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [76/105], Loss: 5.553, Perp: 257.94, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [77/105], Loss: 5.553, Perp: 257.92, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [78/105], Loss: 5.553, Perp: 257.91, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [79/105], Loss: 5.553, Perp: 257.89, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [80/105], Loss: 5.552, Perp: 257.88, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [81/105], Loss: 5.552, Perp: 257.86, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [82/105], Loss: 5.552, Perp: 257.85, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [83/105], Loss: 5.552, Perp: 257.83, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [84/105], Loss: 5.552, Perp: 257.82, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [85/105], Loss: 5.552, Perp: 257.81, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [86/105], Loss: 5.552, Perp: 257.80, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [87/105], Loss: 5.552, Perp: 257.79, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [88/105], Loss: 5.552, Perp: 257.78, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [89/105], Loss: 5.552, Perp: 257.77, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [90/105], Loss: 5.552, Perp: 257.75, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [91/105], Loss: 5.552, Perp: 257.74, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [92/105], Loss: 5.552, Perp: 257.73, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [93/105], Loss: 5.552, Perp: 257.72, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [94/105], Loss: 5.552, Perp: 257.71, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [95/105], Loss: 5.552, Perp: 257.70, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [96/105], Loss: 5.552, Perp: 257.69, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [97/105], Loss: 5.552, Perp: 257.68, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [98/105], Loss: 5.552, Perp: 257.67, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [99/105], Loss: 5.552, Perp: 257.66, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [100/105], Loss: 5.552, Perp: 257.65, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [101/105], Loss: 5.552, Perp: 257.64, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [102/105], Loss: 5.552, Perp: 257.63, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [103/105], Loss: 5.551, Perp: 257.62, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [104/105], Loss: 5.551, Perp: 257.61, Acc: 0.20           here\n",
      "here\n",
      "Training: Epoch [7/40], Step [105/105], Loss: 5.551, Perp: 257.60, Acc: 0.20           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [1/26], Loss: 5.114, Perp: 166.26, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [2/26], Loss: 5.111, Perp: 165.77, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [3/26], Loss: 5.109, Perp: 165.52, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [4/26], Loss: 5.108, Perp: 165.38, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [5/26], Loss: 5.107, Perp: 165.25, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [6/26], Loss: 5.107, Perp: 165.15, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [7/26], Loss: 5.106, Perp: 165.07, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [8/26], Loss: 5.106, Perp: 165.01, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [9/26], Loss: 5.106, Perp: 164.96, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [10/26], Loss: 5.106, Perp: 164.93, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [11/26], Loss: 5.105, Perp: 164.90, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [12/26], Loss: 5.105, Perp: 164.86, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [13/26], Loss: 5.105, Perp: 164.83, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [14/26], Loss: 5.105, Perp: 164.79, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [15/26], Loss: 5.105, Perp: 164.77, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [16/26], Loss: 5.104, Perp: 164.73, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [17/26], Loss: 5.104, Perp: 164.70, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [18/26], Loss: 5.104, Perp: 164.68, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [19/26], Loss: 5.104, Perp: 164.66, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [20/26], Loss: 5.104, Perp: 164.63, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [21/26], Loss: 5.104, Perp: 164.61, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [22/26], Loss: 5.103, Perp: 164.58, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [23/26], Loss: 5.103, Perp: 164.58, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [24/26], Loss: 5.103, Perp: 164.56, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [25/26], Loss: 5.103, Perp: 164.54, Acc: 0.23           here\n",
      "here\n",
      "Validation: Epoch [7/40], Step [26/26], Loss: 5.103, Perp: 164.52, Acc: 0.23           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [1/105], Loss: 5.330, Perp: 206.44, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [2/105], Loss: 5.328, Perp: 206.04, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [3/105], Loss: 5.328, Perp: 205.97, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [4/105], Loss: 5.328, Perp: 205.95, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [5/105], Loss: 5.328, Perp: 205.92, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [6/105], Loss: 5.327, Perp: 205.90, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [7/105], Loss: 5.327, Perp: 205.87, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [8/105], Loss: 5.327, Perp: 205.86, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [9/105], Loss: 5.327, Perp: 205.87, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [10/105], Loss: 5.327, Perp: 205.86, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [11/105], Loss: 5.327, Perp: 205.85, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [12/105], Loss: 5.327, Perp: 205.84, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [13/105], Loss: 5.327, Perp: 205.84, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [14/105], Loss: 5.327, Perp: 205.84, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [15/105], Loss: 5.327, Perp: 205.83, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [16/105], Loss: 5.327, Perp: 205.82, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [17/105], Loss: 5.327, Perp: 205.83, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [18/105], Loss: 5.327, Perp: 205.83, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [19/105], Loss: 5.327, Perp: 205.83, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [20/105], Loss: 5.327, Perp: 205.82, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [21/105], Loss: 5.327, Perp: 205.83, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [22/105], Loss: 5.327, Perp: 205.83, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [23/105], Loss: 5.327, Perp: 205.83, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [24/105], Loss: 5.327, Perp: 205.82, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [25/105], Loss: 5.327, Perp: 205.82, Acc: 0.21           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [8/40], Step [26/105], Loss: 5.327, Perp: 205.81, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [27/105], Loss: 5.327, Perp: 205.80, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [28/105], Loss: 5.327, Perp: 205.79, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [29/105], Loss: 5.327, Perp: 205.79, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [30/105], Loss: 5.327, Perp: 205.78, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [31/105], Loss: 5.327, Perp: 205.78, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [32/105], Loss: 5.327, Perp: 205.76, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [33/105], Loss: 5.327, Perp: 205.75, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [34/105], Loss: 5.327, Perp: 205.74, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [35/105], Loss: 5.327, Perp: 205.72, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [36/105], Loss: 5.327, Perp: 205.72, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [37/105], Loss: 5.326, Perp: 205.70, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [38/105], Loss: 5.326, Perp: 205.69, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [39/105], Loss: 5.326, Perp: 205.68, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [40/105], Loss: 5.326, Perp: 205.67, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [41/105], Loss: 5.326, Perp: 205.66, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [42/105], Loss: 5.326, Perp: 205.66, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [43/105], Loss: 5.326, Perp: 205.65, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [44/105], Loss: 5.326, Perp: 205.64, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [45/105], Loss: 5.326, Perp: 205.63, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [46/105], Loss: 5.326, Perp: 205.62, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [47/105], Loss: 5.326, Perp: 205.61, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [48/105], Loss: 5.326, Perp: 205.60, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [49/105], Loss: 5.326, Perp: 205.59, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [50/105], Loss: 5.326, Perp: 205.59, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [51/105], Loss: 5.326, Perp: 205.57, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [52/105], Loss: 5.326, Perp: 205.57, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [53/105], Loss: 5.326, Perp: 205.56, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [54/105], Loss: 5.326, Perp: 205.55, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [55/105], Loss: 5.326, Perp: 205.55, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [56/105], Loss: 5.326, Perp: 205.54, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [57/105], Loss: 5.326, Perp: 205.54, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [58/105], Loss: 5.326, Perp: 205.53, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [59/105], Loss: 5.326, Perp: 205.52, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [60/105], Loss: 5.325, Perp: 205.51, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [61/105], Loss: 5.325, Perp: 205.50, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [62/105], Loss: 5.325, Perp: 205.49, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [63/105], Loss: 5.325, Perp: 205.49, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [64/105], Loss: 5.325, Perp: 205.48, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [65/105], Loss: 5.325, Perp: 205.47, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [66/105], Loss: 5.325, Perp: 205.47, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [67/105], Loss: 5.325, Perp: 205.46, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [68/105], Loss: 5.325, Perp: 205.45, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [69/105], Loss: 5.325, Perp: 205.45, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [70/105], Loss: 5.325, Perp: 205.44, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [71/105], Loss: 5.325, Perp: 205.44, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [72/105], Loss: 5.325, Perp: 205.43, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [73/105], Loss: 5.325, Perp: 205.42, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [74/105], Loss: 5.325, Perp: 205.41, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [75/105], Loss: 5.325, Perp: 205.41, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [76/105], Loss: 5.325, Perp: 205.40, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [77/105], Loss: 5.325, Perp: 205.39, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [78/105], Loss: 5.325, Perp: 205.38, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [79/105], Loss: 5.325, Perp: 205.37, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [80/105], Loss: 5.325, Perp: 205.36, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [81/105], Loss: 5.325, Perp: 205.35, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [82/105], Loss: 5.325, Perp: 205.34, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [83/105], Loss: 5.325, Perp: 205.34, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [84/105], Loss: 5.325, Perp: 205.33, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [85/105], Loss: 5.325, Perp: 205.33, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [86/105], Loss: 5.325, Perp: 205.32, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [87/105], Loss: 5.325, Perp: 205.31, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [88/105], Loss: 5.324, Perp: 205.30, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [89/105], Loss: 5.324, Perp: 205.30, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [90/105], Loss: 5.324, Perp: 205.29, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [91/105], Loss: 5.324, Perp: 205.28, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [92/105], Loss: 5.324, Perp: 205.28, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [93/105], Loss: 5.324, Perp: 205.27, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [94/105], Loss: 5.324, Perp: 205.26, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [95/105], Loss: 5.324, Perp: 205.26, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [96/105], Loss: 5.324, Perp: 205.25, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [97/105], Loss: 5.324, Perp: 205.25, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [98/105], Loss: 5.324, Perp: 205.24, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [99/105], Loss: 5.324, Perp: 205.23, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [100/105], Loss: 5.324, Perp: 205.22, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [101/105], Loss: 5.324, Perp: 205.21, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [102/105], Loss: 5.324, Perp: 205.21, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [103/105], Loss: 5.324, Perp: 205.20, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [104/105], Loss: 5.324, Perp: 205.20, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [8/40], Step [105/105], Loss: 5.324, Perp: 205.19, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [1/26], Loss: 4.934, Perp: 138.97, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [2/26], Loss: 4.932, Perp: 138.60, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [3/26], Loss: 4.930, Perp: 138.40, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [4/26], Loss: 4.929, Perp: 138.29, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [5/26], Loss: 4.928, Perp: 138.17, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [6/26], Loss: 4.928, Perp: 138.07, Acc: 0.24           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [8/40], Step [7/26], Loss: 4.927, Perp: 138.00, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [8/26], Loss: 4.927, Perp: 137.94, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [9/26], Loss: 4.927, Perp: 137.90, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [10/26], Loss: 4.926, Perp: 137.87, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [11/26], Loss: 4.926, Perp: 137.84, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [12/26], Loss: 4.926, Perp: 137.81, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [13/26], Loss: 4.926, Perp: 137.78, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [14/26], Loss: 4.925, Perp: 137.74, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [15/26], Loss: 4.925, Perp: 137.72, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [16/26], Loss: 4.925, Perp: 137.68, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [17/26], Loss: 4.925, Perp: 137.65, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [18/26], Loss: 4.925, Perp: 137.62, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [19/26], Loss: 4.924, Perp: 137.60, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [20/26], Loss: 4.924, Perp: 137.58, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [21/26], Loss: 4.924, Perp: 137.56, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [22/26], Loss: 4.924, Perp: 137.53, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [23/26], Loss: 4.924, Perp: 137.52, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [24/26], Loss: 4.924, Perp: 137.50, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [25/26], Loss: 4.924, Perp: 137.49, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [8/40], Step [26/26], Loss: 4.923, Perp: 137.47, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [1/105], Loss: 5.171, Perp: 176.17, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [2/105], Loss: 5.170, Perp: 175.83, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [3/105], Loss: 5.169, Perp: 175.76, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [4/105], Loss: 5.169, Perp: 175.76, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [5/105], Loss: 5.169, Perp: 175.73, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [6/105], Loss: 5.169, Perp: 175.70, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [7/105], Loss: 5.169, Perp: 175.66, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [8/105], Loss: 5.168, Perp: 175.65, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [9/105], Loss: 5.169, Perp: 175.65, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [10/105], Loss: 5.168, Perp: 175.65, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [11/105], Loss: 5.168, Perp: 175.64, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [12/105], Loss: 5.168, Perp: 175.62, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [13/105], Loss: 5.168, Perp: 175.61, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [14/105], Loss: 5.168, Perp: 175.60, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [15/105], Loss: 5.168, Perp: 175.59, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [16/105], Loss: 5.168, Perp: 175.58, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [17/105], Loss: 5.168, Perp: 175.58, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [18/105], Loss: 5.168, Perp: 175.59, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [19/105], Loss: 5.168, Perp: 175.59, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [20/105], Loss: 5.168, Perp: 175.59, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [21/105], Loss: 5.168, Perp: 175.59, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [22/105], Loss: 5.168, Perp: 175.59, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [23/105], Loss: 5.168, Perp: 175.59, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [24/105], Loss: 5.168, Perp: 175.59, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [25/105], Loss: 5.168, Perp: 175.58, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [26/105], Loss: 5.168, Perp: 175.58, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [27/105], Loss: 5.168, Perp: 175.57, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [28/105], Loss: 5.168, Perp: 175.55, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [29/105], Loss: 5.168, Perp: 175.55, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [30/105], Loss: 5.168, Perp: 175.54, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [31/105], Loss: 5.168, Perp: 175.53, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [32/105], Loss: 5.168, Perp: 175.52, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [33/105], Loss: 5.168, Perp: 175.51, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [34/105], Loss: 5.168, Perp: 175.50, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [35/105], Loss: 5.168, Perp: 175.48, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [36/105], Loss: 5.168, Perp: 175.48, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [37/105], Loss: 5.167, Perp: 175.46, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [38/105], Loss: 5.167, Perp: 175.45, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [39/105], Loss: 5.167, Perp: 175.44, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [40/105], Loss: 5.167, Perp: 175.43, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [41/105], Loss: 5.167, Perp: 175.43, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [42/105], Loss: 5.167, Perp: 175.42, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [43/105], Loss: 5.167, Perp: 175.41, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [44/105], Loss: 5.167, Perp: 175.40, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [45/105], Loss: 5.167, Perp: 175.39, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [46/105], Loss: 5.167, Perp: 175.38, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [47/105], Loss: 5.167, Perp: 175.38, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [48/105], Loss: 5.167, Perp: 175.37, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [49/105], Loss: 5.167, Perp: 175.36, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [50/105], Loss: 5.167, Perp: 175.35, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [51/105], Loss: 5.167, Perp: 175.34, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [52/105], Loss: 5.167, Perp: 175.33, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [53/105], Loss: 5.167, Perp: 175.33, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [54/105], Loss: 5.167, Perp: 175.32, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [55/105], Loss: 5.167, Perp: 175.31, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [56/105], Loss: 5.167, Perp: 175.31, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [57/105], Loss: 5.167, Perp: 175.30, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [58/105], Loss: 5.166, Perp: 175.29, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [59/105], Loss: 5.166, Perp: 175.29, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [60/105], Loss: 5.166, Perp: 175.28, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [61/105], Loss: 5.166, Perp: 175.27, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [62/105], Loss: 5.166, Perp: 175.26, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [63/105], Loss: 5.166, Perp: 175.26, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [64/105], Loss: 5.166, Perp: 175.25, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [65/105], Loss: 5.166, Perp: 175.25, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [66/105], Loss: 5.166, Perp: 175.24, Acc: 0.21           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [9/40], Step [67/105], Loss: 5.166, Perp: 175.23, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [68/105], Loss: 5.166, Perp: 175.23, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [69/105], Loss: 5.166, Perp: 175.22, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [70/105], Loss: 5.166, Perp: 175.22, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [71/105], Loss: 5.166, Perp: 175.21, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [72/105], Loss: 5.166, Perp: 175.20, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [73/105], Loss: 5.166, Perp: 175.19, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [74/105], Loss: 5.166, Perp: 175.19, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [75/105], Loss: 5.166, Perp: 175.18, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [76/105], Loss: 5.166, Perp: 175.17, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [77/105], Loss: 5.166, Perp: 175.16, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [78/105], Loss: 5.166, Perp: 175.15, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [79/105], Loss: 5.166, Perp: 175.14, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [80/105], Loss: 5.166, Perp: 175.13, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [81/105], Loss: 5.165, Perp: 175.12, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [82/105], Loss: 5.165, Perp: 175.11, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [83/105], Loss: 5.165, Perp: 175.11, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [84/105], Loss: 5.165, Perp: 175.10, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [85/105], Loss: 5.165, Perp: 175.09, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [86/105], Loss: 5.165, Perp: 175.09, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [87/105], Loss: 5.165, Perp: 175.08, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [88/105], Loss: 5.165, Perp: 175.08, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [89/105], Loss: 5.165, Perp: 175.07, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [90/105], Loss: 5.165, Perp: 175.06, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [91/105], Loss: 5.165, Perp: 175.06, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [92/105], Loss: 5.165, Perp: 175.05, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [93/105], Loss: 5.165, Perp: 175.04, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [94/105], Loss: 5.165, Perp: 175.04, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [95/105], Loss: 5.165, Perp: 175.03, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [96/105], Loss: 5.165, Perp: 175.03, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [97/105], Loss: 5.165, Perp: 175.02, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [98/105], Loss: 5.165, Perp: 175.02, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [99/105], Loss: 5.165, Perp: 175.01, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [100/105], Loss: 5.165, Perp: 175.00, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [101/105], Loss: 5.165, Perp: 175.00, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [102/105], Loss: 5.165, Perp: 174.99, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [103/105], Loss: 5.165, Perp: 174.99, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [104/105], Loss: 5.165, Perp: 174.98, Acc: 0.21           here\n",
      "here\n",
      "Training: Epoch [9/40], Step [105/105], Loss: 5.165, Perp: 174.97, Acc: 0.21           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [1/26], Loss: 4.709, Perp: 110.92, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [2/26], Loss: 4.706, Perp: 110.60, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [3/26], Loss: 4.705, Perp: 110.45, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [4/26], Loss: 4.704, Perp: 110.35, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [5/26], Loss: 4.703, Perp: 110.27, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [6/26], Loss: 4.702, Perp: 110.20, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [7/26], Loss: 4.702, Perp: 110.15, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [8/26], Loss: 4.701, Perp: 110.11, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [9/26], Loss: 4.701, Perp: 110.08, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [10/26], Loss: 4.701, Perp: 110.06, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [11/26], Loss: 4.701, Perp: 110.04, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [12/26], Loss: 4.701, Perp: 110.01, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [13/26], Loss: 4.700, Perp: 109.99, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [14/26], Loss: 4.700, Perp: 109.96, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [15/26], Loss: 4.700, Perp: 109.94, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [16/26], Loss: 4.700, Perp: 109.92, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [17/26], Loss: 4.699, Perp: 109.89, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [18/26], Loss: 4.699, Perp: 109.87, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [19/26], Loss: 4.699, Perp: 109.86, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [20/26], Loss: 4.699, Perp: 109.84, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [21/26], Loss: 4.699, Perp: 109.82, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [22/26], Loss: 4.699, Perp: 109.80, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [23/26], Loss: 4.699, Perp: 109.80, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [24/26], Loss: 4.698, Perp: 109.78, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [25/26], Loss: 4.698, Perp: 109.77, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [9/40], Step [26/26], Loss: 4.698, Perp: 109.76, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [1/105], Loss: 4.999, Perp: 148.25, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [2/105], Loss: 4.997, Perp: 148.01, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [3/105], Loss: 4.997, Perp: 147.97, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [4/105], Loss: 4.997, Perp: 147.95, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [5/105], Loss: 4.997, Perp: 147.91, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [6/105], Loss: 4.996, Perp: 147.87, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [7/105], Loss: 4.996, Perp: 147.83, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [8/105], Loss: 4.996, Perp: 147.80, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [9/105], Loss: 4.996, Perp: 147.79, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [10/105], Loss: 4.996, Perp: 147.78, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [11/105], Loss: 4.996, Perp: 147.77, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [12/105], Loss: 4.996, Perp: 147.75, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [13/105], Loss: 4.995, Perp: 147.74, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [14/105], Loss: 4.995, Perp: 147.74, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [15/105], Loss: 4.995, Perp: 147.72, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [16/105], Loss: 4.995, Perp: 147.72, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [17/105], Loss: 4.995, Perp: 147.71, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [18/105], Loss: 4.995, Perp: 147.72, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [19/105], Loss: 4.995, Perp: 147.72, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [20/105], Loss: 4.995, Perp: 147.72, Acc: 0.22           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [10/40], Step [21/105], Loss: 4.995, Perp: 147.72, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [22/105], Loss: 4.995, Perp: 147.72, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [23/105], Loss: 4.995, Perp: 147.71, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [24/105], Loss: 4.995, Perp: 147.71, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [25/105], Loss: 4.995, Perp: 147.70, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [26/105], Loss: 4.995, Perp: 147.70, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [27/105], Loss: 4.995, Perp: 147.69, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [28/105], Loss: 4.995, Perp: 147.68, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [29/105], Loss: 4.995, Perp: 147.68, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [30/105], Loss: 4.995, Perp: 147.67, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [31/105], Loss: 4.995, Perp: 147.65, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [32/105], Loss: 4.995, Perp: 147.65, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [33/105], Loss: 4.995, Perp: 147.63, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [34/105], Loss: 4.995, Perp: 147.62, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [35/105], Loss: 4.995, Perp: 147.61, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [36/105], Loss: 4.995, Perp: 147.61, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [37/105], Loss: 4.994, Perp: 147.59, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [38/105], Loss: 4.994, Perp: 147.59, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [39/105], Loss: 4.994, Perp: 147.58, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [40/105], Loss: 4.994, Perp: 147.57, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [41/105], Loss: 4.994, Perp: 147.57, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [42/105], Loss: 4.994, Perp: 147.56, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [43/105], Loss: 4.994, Perp: 147.55, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [44/105], Loss: 4.994, Perp: 147.54, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [45/105], Loss: 4.994, Perp: 147.54, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [46/105], Loss: 4.994, Perp: 147.53, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [47/105], Loss: 4.994, Perp: 147.52, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [48/105], Loss: 4.994, Perp: 147.51, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [49/105], Loss: 4.994, Perp: 147.51, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [50/105], Loss: 4.994, Perp: 147.50, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [51/105], Loss: 4.994, Perp: 147.49, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [52/105], Loss: 4.994, Perp: 147.49, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [53/105], Loss: 4.994, Perp: 147.48, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [54/105], Loss: 4.994, Perp: 147.47, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [55/105], Loss: 4.994, Perp: 147.47, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [56/105], Loss: 4.994, Perp: 147.46, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [57/105], Loss: 4.994, Perp: 147.46, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [58/105], Loss: 4.993, Perp: 147.45, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [59/105], Loss: 4.993, Perp: 147.45, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [60/105], Loss: 4.993, Perp: 147.44, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [61/105], Loss: 4.993, Perp: 147.43, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [62/105], Loss: 4.993, Perp: 147.43, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [63/105], Loss: 4.993, Perp: 147.42, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [64/105], Loss: 4.993, Perp: 147.42, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [65/105], Loss: 4.993, Perp: 147.42, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [66/105], Loss: 4.993, Perp: 147.41, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [67/105], Loss: 4.993, Perp: 147.41, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [68/105], Loss: 4.993, Perp: 147.40, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [69/105], Loss: 4.993, Perp: 147.39, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [70/105], Loss: 4.993, Perp: 147.39, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [71/105], Loss: 4.993, Perp: 147.38, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [72/105], Loss: 4.993, Perp: 147.38, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [73/105], Loss: 4.993, Perp: 147.37, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [74/105], Loss: 4.993, Perp: 147.37, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [75/105], Loss: 4.993, Perp: 147.36, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [76/105], Loss: 4.993, Perp: 147.35, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [77/105], Loss: 4.993, Perp: 147.34, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [78/105], Loss: 4.993, Perp: 147.34, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [79/105], Loss: 4.993, Perp: 147.33, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [80/105], Loss: 4.993, Perp: 147.32, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [81/105], Loss: 4.993, Perp: 147.31, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [82/105], Loss: 4.993, Perp: 147.30, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [83/105], Loss: 4.992, Perp: 147.30, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [84/105], Loss: 4.992, Perp: 147.29, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [85/105], Loss: 4.992, Perp: 147.29, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [86/105], Loss: 4.992, Perp: 147.28, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [87/105], Loss: 4.992, Perp: 147.27, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [88/105], Loss: 4.992, Perp: 147.27, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [89/105], Loss: 4.992, Perp: 147.26, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [90/105], Loss: 4.992, Perp: 147.26, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [91/105], Loss: 4.992, Perp: 147.25, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [92/105], Loss: 4.992, Perp: 147.25, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [93/105], Loss: 4.992, Perp: 147.24, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [94/105], Loss: 4.992, Perp: 147.24, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [95/105], Loss: 4.992, Perp: 147.23, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [96/105], Loss: 4.992, Perp: 147.23, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [97/105], Loss: 4.992, Perp: 147.22, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [98/105], Loss: 4.992, Perp: 147.22, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [99/105], Loss: 4.992, Perp: 147.21, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [100/105], Loss: 4.992, Perp: 147.20, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [101/105], Loss: 4.992, Perp: 147.20, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [102/105], Loss: 4.992, Perp: 147.19, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [103/105], Loss: 4.992, Perp: 147.19, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [104/105], Loss: 4.992, Perp: 147.18, Acc: 0.22           here\n",
      "here\n",
      "Training: Epoch [10/40], Step [105/105], Loss: 4.992, Perp: 147.18, Acc: 0.22           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [10/40], Step [1/26], Loss: 4.564, Perp: 95.97, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [2/26], Loss: 4.561, Perp: 95.67, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [3/26], Loss: 4.559, Perp: 95.51, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [4/26], Loss: 4.558, Perp: 95.41, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [5/26], Loss: 4.557, Perp: 95.32, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [6/26], Loss: 4.556, Perp: 95.24, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [7/26], Loss: 4.556, Perp: 95.19, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [8/26], Loss: 4.556, Perp: 95.15, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [9/26], Loss: 4.555, Perp: 95.12, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [10/26], Loss: 4.555, Perp: 95.10, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [11/26], Loss: 4.555, Perp: 95.08, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [12/26], Loss: 4.554, Perp: 95.05, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [13/26], Loss: 4.554, Perp: 95.02, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [14/26], Loss: 4.554, Perp: 94.99, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [15/26], Loss: 4.554, Perp: 94.97, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [16/26], Loss: 4.553, Perp: 94.95, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [17/26], Loss: 4.553, Perp: 94.92, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [18/26], Loss: 4.553, Perp: 94.90, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [19/26], Loss: 4.553, Perp: 94.89, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [20/26], Loss: 4.552, Perp: 94.87, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [21/26], Loss: 4.552, Perp: 94.85, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [22/26], Loss: 4.552, Perp: 94.83, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [23/26], Loss: 4.552, Perp: 94.82, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [24/26], Loss: 4.552, Perp: 94.81, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [25/26], Loss: 4.552, Perp: 94.79, Acc: 0.26           here\n",
      "here\n",
      "Validation: Epoch [10/40], Step [26/26], Loss: 4.552, Perp: 94.78, Acc: 0.26           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [1/105], Loss: 4.790, Perp: 120.26, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [2/105], Loss: 4.788, Perp: 120.07, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [3/105], Loss: 4.788, Perp: 120.03, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [4/105], Loss: 4.788, Perp: 120.01, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [5/105], Loss: 4.787, Perp: 119.99, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [6/105], Loss: 4.787, Perp: 119.98, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [7/105], Loss: 4.787, Perp: 119.97, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [8/105], Loss: 4.787, Perp: 119.94, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [9/105], Loss: 4.787, Perp: 119.93, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [10/105], Loss: 4.787, Perp: 119.93, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [11/105], Loss: 4.787, Perp: 119.92, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [12/105], Loss: 4.787, Perp: 119.91, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [13/105], Loss: 4.787, Perp: 119.91, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [14/105], Loss: 4.787, Perp: 119.90, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [15/105], Loss: 4.787, Perp: 119.89, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [16/105], Loss: 4.787, Perp: 119.89, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [17/105], Loss: 4.787, Perp: 119.89, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [18/105], Loss: 4.787, Perp: 119.90, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [19/105], Loss: 4.787, Perp: 119.90, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [20/105], Loss: 4.787, Perp: 119.89, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [21/105], Loss: 4.787, Perp: 119.89, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [22/105], Loss: 4.787, Perp: 119.90, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [23/105], Loss: 4.787, Perp: 119.90, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [24/105], Loss: 4.787, Perp: 119.90, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [25/105], Loss: 4.787, Perp: 119.89, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [26/105], Loss: 4.787, Perp: 119.89, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [27/105], Loss: 4.787, Perp: 119.89, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [28/105], Loss: 4.786, Perp: 119.88, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [29/105], Loss: 4.786, Perp: 119.88, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [30/105], Loss: 4.786, Perp: 119.87, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [31/105], Loss: 4.786, Perp: 119.87, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [32/105], Loss: 4.786, Perp: 119.86, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [33/105], Loss: 4.786, Perp: 119.85, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [34/105], Loss: 4.786, Perp: 119.84, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [35/105], Loss: 4.786, Perp: 119.83, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [36/105], Loss: 4.786, Perp: 119.83, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [37/105], Loss: 4.786, Perp: 119.82, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [38/105], Loss: 4.786, Perp: 119.82, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [39/105], Loss: 4.786, Perp: 119.81, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [40/105], Loss: 4.786, Perp: 119.81, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [41/105], Loss: 4.786, Perp: 119.81, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [42/105], Loss: 4.786, Perp: 119.80, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [43/105], Loss: 4.786, Perp: 119.80, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [44/105], Loss: 4.786, Perp: 119.79, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [45/105], Loss: 4.786, Perp: 119.79, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [46/105], Loss: 4.786, Perp: 119.78, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [47/105], Loss: 4.786, Perp: 119.77, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [48/105], Loss: 4.786, Perp: 119.76, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [49/105], Loss: 4.786, Perp: 119.76, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [50/105], Loss: 4.785, Perp: 119.76, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [51/105], Loss: 4.785, Perp: 119.75, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [52/105], Loss: 4.785, Perp: 119.75, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [53/105], Loss: 4.785, Perp: 119.74, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [54/105], Loss: 4.785, Perp: 119.74, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [55/105], Loss: 4.785, Perp: 119.73, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [56/105], Loss: 4.785, Perp: 119.73, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [57/105], Loss: 4.785, Perp: 119.73, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [58/105], Loss: 4.785, Perp: 119.72, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [59/105], Loss: 4.785, Perp: 119.72, Acc: 0.24           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [11/40], Step [60/105], Loss: 4.785, Perp: 119.71, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [61/105], Loss: 4.785, Perp: 119.71, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [62/105], Loss: 4.785, Perp: 119.70, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [63/105], Loss: 4.785, Perp: 119.70, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [64/105], Loss: 4.785, Perp: 119.70, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [65/105], Loss: 4.785, Perp: 119.69, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [66/105], Loss: 4.785, Perp: 119.69, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [67/105], Loss: 4.785, Perp: 119.69, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [68/105], Loss: 4.785, Perp: 119.68, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [69/105], Loss: 4.785, Perp: 119.68, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [70/105], Loss: 4.785, Perp: 119.68, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [71/105], Loss: 4.785, Perp: 119.67, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [72/105], Loss: 4.785, Perp: 119.67, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [73/105], Loss: 4.785, Perp: 119.66, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [74/105], Loss: 4.785, Perp: 119.66, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [75/105], Loss: 4.785, Perp: 119.65, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [76/105], Loss: 4.785, Perp: 119.65, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [77/105], Loss: 4.784, Perp: 119.64, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [78/105], Loss: 4.784, Perp: 119.64, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [79/105], Loss: 4.784, Perp: 119.63, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [80/105], Loss: 4.784, Perp: 119.62, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [81/105], Loss: 4.784, Perp: 119.62, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [82/105], Loss: 4.784, Perp: 119.61, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [83/105], Loss: 4.784, Perp: 119.60, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [84/105], Loss: 4.784, Perp: 119.60, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [85/105], Loss: 4.784, Perp: 119.59, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [86/105], Loss: 4.784, Perp: 119.59, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [87/105], Loss: 4.784, Perp: 119.59, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [88/105], Loss: 4.784, Perp: 119.58, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [89/105], Loss: 4.784, Perp: 119.58, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [90/105], Loss: 4.784, Perp: 119.58, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [91/105], Loss: 4.784, Perp: 119.57, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [92/105], Loss: 4.784, Perp: 119.57, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [93/105], Loss: 4.784, Perp: 119.56, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [94/105], Loss: 4.784, Perp: 119.56, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [95/105], Loss: 4.784, Perp: 119.56, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [96/105], Loss: 4.784, Perp: 119.55, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [97/105], Loss: 4.784, Perp: 119.55, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [98/105], Loss: 4.784, Perp: 119.55, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [99/105], Loss: 4.784, Perp: 119.54, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [100/105], Loss: 4.784, Perp: 119.54, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [101/105], Loss: 4.784, Perp: 119.53, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [102/105], Loss: 4.784, Perp: 119.53, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [103/105], Loss: 4.784, Perp: 119.52, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [104/105], Loss: 4.783, Perp: 119.52, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [11/40], Step [105/105], Loss: 4.783, Perp: 119.51, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [1/26], Loss: 4.373, Perp: 79.30, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [2/26], Loss: 4.370, Perp: 79.07, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [3/26], Loss: 4.369, Perp: 78.95, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [4/26], Loss: 4.368, Perp: 78.85, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [5/26], Loss: 4.367, Perp: 78.77, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [6/26], Loss: 4.366, Perp: 78.71, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [7/26], Loss: 4.365, Perp: 78.66, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [8/26], Loss: 4.365, Perp: 78.62, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [9/26], Loss: 4.364, Perp: 78.59, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [10/26], Loss: 4.364, Perp: 78.57, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [11/26], Loss: 4.364, Perp: 78.55, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [12/26], Loss: 4.363, Perp: 78.52, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [13/26], Loss: 4.363, Perp: 78.50, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [14/26], Loss: 4.363, Perp: 78.47, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [15/26], Loss: 4.362, Perp: 78.45, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [16/26], Loss: 4.362, Perp: 78.42, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [17/26], Loss: 4.362, Perp: 78.40, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [18/26], Loss: 4.362, Perp: 78.38, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [19/26], Loss: 4.361, Perp: 78.37, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [20/26], Loss: 4.361, Perp: 78.35, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [21/26], Loss: 4.361, Perp: 78.33, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [22/26], Loss: 4.361, Perp: 78.32, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [23/26], Loss: 4.361, Perp: 78.31, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [24/26], Loss: 4.360, Perp: 78.29, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [25/26], Loss: 4.360, Perp: 78.28, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [11/40], Step [26/26], Loss: 4.360, Perp: 78.27, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [1/105], Loss: 4.611, Perp: 100.60, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [2/105], Loss: 4.610, Perp: 100.50, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [3/105], Loss: 4.610, Perp: 100.52, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [4/105], Loss: 4.611, Perp: 100.54, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [5/105], Loss: 4.610, Perp: 100.53, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [6/105], Loss: 4.610, Perp: 100.51, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [7/105], Loss: 4.610, Perp: 100.50, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [8/105], Loss: 4.610, Perp: 100.49, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [9/105], Loss: 4.610, Perp: 100.49, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [10/105], Loss: 4.610, Perp: 100.48, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [11/105], Loss: 4.610, Perp: 100.47, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [12/105], Loss: 4.610, Perp: 100.46, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [13/105], Loss: 4.610, Perp: 100.46, Acc: 0.24           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [12/40], Step [14/105], Loss: 4.610, Perp: 100.46, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [15/105], Loss: 4.610, Perp: 100.45, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [16/105], Loss: 4.610, Perp: 100.45, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [17/105], Loss: 4.610, Perp: 100.45, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [18/105], Loss: 4.610, Perp: 100.45, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [19/105], Loss: 4.610, Perp: 100.45, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [20/105], Loss: 4.610, Perp: 100.45, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [21/105], Loss: 4.610, Perp: 100.45, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [22/105], Loss: 4.610, Perp: 100.45, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [23/105], Loss: 4.610, Perp: 100.45, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [24/105], Loss: 4.610, Perp: 100.45, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [25/105], Loss: 4.610, Perp: 100.44, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [26/105], Loss: 4.610, Perp: 100.44, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [27/105], Loss: 4.610, Perp: 100.44, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [28/105], Loss: 4.609, Perp: 100.43, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [29/105], Loss: 4.609, Perp: 100.43, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [30/105], Loss: 4.609, Perp: 100.42, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [31/105], Loss: 4.609, Perp: 100.42, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [32/105], Loss: 4.609, Perp: 100.41, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [33/105], Loss: 4.609, Perp: 100.41, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [34/105], Loss: 4.609, Perp: 100.40, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [35/105], Loss: 4.609, Perp: 100.39, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [36/105], Loss: 4.609, Perp: 100.39, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [37/105], Loss: 4.609, Perp: 100.38, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [38/105], Loss: 4.609, Perp: 100.38, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [39/105], Loss: 4.609, Perp: 100.38, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [40/105], Loss: 4.609, Perp: 100.37, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [41/105], Loss: 4.609, Perp: 100.37, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [42/105], Loss: 4.609, Perp: 100.37, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [43/105], Loss: 4.609, Perp: 100.36, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [44/105], Loss: 4.609, Perp: 100.35, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [45/105], Loss: 4.609, Perp: 100.35, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [46/105], Loss: 4.609, Perp: 100.34, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [47/105], Loss: 4.609, Perp: 100.34, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [48/105], Loss: 4.609, Perp: 100.33, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [49/105], Loss: 4.608, Perp: 100.33, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [50/105], Loss: 4.608, Perp: 100.33, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [51/105], Loss: 4.608, Perp: 100.32, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [52/105], Loss: 4.608, Perp: 100.32, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [53/105], Loss: 4.608, Perp: 100.31, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [54/105], Loss: 4.608, Perp: 100.31, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [55/105], Loss: 4.608, Perp: 100.30, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [56/105], Loss: 4.608, Perp: 100.30, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [57/105], Loss: 4.608, Perp: 100.29, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [58/105], Loss: 4.608, Perp: 100.29, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [59/105], Loss: 4.608, Perp: 100.28, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [60/105], Loss: 4.608, Perp: 100.28, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [61/105], Loss: 4.608, Perp: 100.28, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [62/105], Loss: 4.608, Perp: 100.27, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [63/105], Loss: 4.608, Perp: 100.27, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [64/105], Loss: 4.608, Perp: 100.26, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [65/105], Loss: 4.608, Perp: 100.26, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [66/105], Loss: 4.608, Perp: 100.26, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [67/105], Loss: 4.608, Perp: 100.25, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [68/105], Loss: 4.608, Perp: 100.25, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [69/105], Loss: 4.608, Perp: 100.25, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [70/105], Loss: 4.608, Perp: 100.24, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [71/105], Loss: 4.608, Perp: 100.24, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [72/105], Loss: 4.608, Perp: 100.24, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [73/105], Loss: 4.607, Perp: 100.23, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [74/105], Loss: 4.607, Perp: 100.23, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [75/105], Loss: 4.607, Perp: 100.22, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [76/105], Loss: 4.607, Perp: 100.22, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [77/105], Loss: 4.607, Perp: 100.21, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [78/105], Loss: 4.607, Perp: 100.21, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [79/105], Loss: 4.607, Perp: 100.20, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [80/105], Loss: 4.607, Perp: 100.20, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [81/105], Loss: 4.607, Perp: 100.19, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [82/105], Loss: 4.607, Perp: 100.19, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [83/105], Loss: 4.607, Perp: 100.18, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [84/105], Loss: 4.607, Perp: 100.18, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [85/105], Loss: 4.607, Perp: 100.17, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [86/105], Loss: 4.607, Perp: 100.17, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [87/105], Loss: 4.607, Perp: 100.17, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [88/105], Loss: 4.607, Perp: 100.16, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [89/105], Loss: 4.607, Perp: 100.16, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [90/105], Loss: 4.607, Perp: 100.16, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [91/105], Loss: 4.607, Perp: 100.16, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [92/105], Loss: 4.607, Perp: 100.15, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [93/105], Loss: 4.607, Perp: 100.15, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [94/105], Loss: 4.607, Perp: 100.15, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [95/105], Loss: 4.607, Perp: 100.15, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [96/105], Loss: 4.607, Perp: 100.14, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [97/105], Loss: 4.607, Perp: 100.14, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [98/105], Loss: 4.607, Perp: 100.14, Acc: 0.24           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [12/40], Step [99/105], Loss: 4.607, Perp: 100.13, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [100/105], Loss: 4.606, Perp: 100.13, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [101/105], Loss: 4.606, Perp: 100.13, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [102/105], Loss: 4.606, Perp: 100.12, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [103/105], Loss: 4.606, Perp: 100.12, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [104/105], Loss: 4.606, Perp: 100.12, Acc: 0.24           here\n",
      "here\n",
      "Training: Epoch [12/40], Step [105/105], Loss: 4.606, Perp: 100.11, Acc: 0.24           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [1/26], Loss: 4.330, Perp: 75.95, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [2/26], Loss: 4.327, Perp: 75.72, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [3/26], Loss: 4.325, Perp: 75.59, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [4/26], Loss: 4.324, Perp: 75.48, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [5/26], Loss: 4.323, Perp: 75.40, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [6/26], Loss: 4.322, Perp: 75.33, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [7/26], Loss: 4.321, Perp: 75.26, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [8/26], Loss: 4.320, Perp: 75.21, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [9/26], Loss: 4.320, Perp: 75.18, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [10/26], Loss: 4.319, Perp: 75.14, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [11/26], Loss: 4.319, Perp: 75.11, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [12/26], Loss: 4.319, Perp: 75.08, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [13/26], Loss: 4.318, Perp: 75.05, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [14/26], Loss: 4.318, Perp: 75.01, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [15/26], Loss: 4.317, Perp: 74.99, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [16/26], Loss: 4.317, Perp: 74.96, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [17/26], Loss: 4.317, Perp: 74.93, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [18/26], Loss: 4.316, Perp: 74.91, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [19/26], Loss: 4.316, Perp: 74.88, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [20/26], Loss: 4.316, Perp: 74.86, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [21/26], Loss: 4.315, Perp: 74.84, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [22/26], Loss: 4.315, Perp: 74.82, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [23/26], Loss: 4.315, Perp: 74.81, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [24/26], Loss: 4.315, Perp: 74.79, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [25/26], Loss: 4.314, Perp: 74.77, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [12/40], Step [26/26], Loss: 4.314, Perp: 74.76, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [1/105], Loss: 4.467, Perp: 87.07, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [2/105], Loss: 4.465, Perp: 86.96, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [3/105], Loss: 4.465, Perp: 86.96, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [4/105], Loss: 4.466, Perp: 86.98, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [5/105], Loss: 4.465, Perp: 86.96, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [6/105], Loss: 4.465, Perp: 86.95, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [7/105], Loss: 4.465, Perp: 86.94, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [8/105], Loss: 4.465, Perp: 86.93, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [9/105], Loss: 4.465, Perp: 86.93, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [10/105], Loss: 4.465, Perp: 86.92, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [11/105], Loss: 4.465, Perp: 86.91, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [12/105], Loss: 4.465, Perp: 86.90, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [13/105], Loss: 4.465, Perp: 86.89, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [14/105], Loss: 4.465, Perp: 86.89, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [15/105], Loss: 4.464, Perp: 86.88, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [16/105], Loss: 4.464, Perp: 86.87, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [17/105], Loss: 4.464, Perp: 86.87, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [18/105], Loss: 4.464, Perp: 86.87, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [19/105], Loss: 4.464, Perp: 86.87, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [20/105], Loss: 4.464, Perp: 86.87, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [21/105], Loss: 4.464, Perp: 86.87, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [22/105], Loss: 4.464, Perp: 86.86, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [23/105], Loss: 4.464, Perp: 86.86, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [24/105], Loss: 4.464, Perp: 86.86, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [25/105], Loss: 4.464, Perp: 86.86, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [26/105], Loss: 4.464, Perp: 86.85, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [27/105], Loss: 4.464, Perp: 86.85, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [28/105], Loss: 4.464, Perp: 86.84, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [29/105], Loss: 4.464, Perp: 86.84, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [30/105], Loss: 4.464, Perp: 86.83, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [31/105], Loss: 4.464, Perp: 86.83, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [32/105], Loss: 4.464, Perp: 86.83, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [33/105], Loss: 4.464, Perp: 86.82, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [34/105], Loss: 4.464, Perp: 86.82, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [35/105], Loss: 4.464, Perp: 86.81, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [36/105], Loss: 4.464, Perp: 86.81, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [37/105], Loss: 4.464, Perp: 86.80, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [38/105], Loss: 4.464, Perp: 86.80, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [39/105], Loss: 4.464, Perp: 86.79, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [40/105], Loss: 4.463, Perp: 86.79, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [41/105], Loss: 4.463, Perp: 86.79, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [42/105], Loss: 4.463, Perp: 86.78, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [43/105], Loss: 4.463, Perp: 86.78, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [44/105], Loss: 4.463, Perp: 86.77, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [45/105], Loss: 4.463, Perp: 86.76, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [46/105], Loss: 4.463, Perp: 86.76, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [47/105], Loss: 4.463, Perp: 86.75, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [48/105], Loss: 4.463, Perp: 86.75, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [49/105], Loss: 4.463, Perp: 86.74, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [50/105], Loss: 4.463, Perp: 86.74, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [51/105], Loss: 4.463, Perp: 86.73, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [52/105], Loss: 4.463, Perp: 86.73, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [53/105], Loss: 4.463, Perp: 86.72, Acc: 0.25           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [13/40], Step [54/105], Loss: 4.463, Perp: 86.72, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [55/105], Loss: 4.463, Perp: 86.71, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [56/105], Loss: 4.463, Perp: 86.71, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [57/105], Loss: 4.463, Perp: 86.70, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [58/105], Loss: 4.462, Perp: 86.70, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [59/105], Loss: 4.462, Perp: 86.69, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [60/105], Loss: 4.462, Perp: 86.69, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [61/105], Loss: 4.462, Perp: 86.69, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [62/105], Loss: 4.462, Perp: 86.68, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [63/105], Loss: 4.462, Perp: 86.68, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [64/105], Loss: 4.462, Perp: 86.68, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [65/105], Loss: 4.462, Perp: 86.67, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [66/105], Loss: 4.462, Perp: 86.67, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [67/105], Loss: 4.462, Perp: 86.67, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [68/105], Loss: 4.462, Perp: 86.66, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [69/105], Loss: 4.462, Perp: 86.66, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [70/105], Loss: 4.462, Perp: 86.66, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [71/105], Loss: 4.462, Perp: 86.65, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [72/105], Loss: 4.462, Perp: 86.65, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [73/105], Loss: 4.462, Perp: 86.64, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [74/105], Loss: 4.462, Perp: 86.64, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [75/105], Loss: 4.462, Perp: 86.64, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [76/105], Loss: 4.462, Perp: 86.63, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [77/105], Loss: 4.462, Perp: 86.63, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [78/105], Loss: 4.462, Perp: 86.62, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [79/105], Loss: 4.462, Perp: 86.62, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [80/105], Loss: 4.461, Perp: 86.62, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [81/105], Loss: 4.461, Perp: 86.61, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [82/105], Loss: 4.461, Perp: 86.61, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [83/105], Loss: 4.461, Perp: 86.60, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [84/105], Loss: 4.461, Perp: 86.60, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [85/105], Loss: 4.461, Perp: 86.60, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [86/105], Loss: 4.461, Perp: 86.59, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [87/105], Loss: 4.461, Perp: 86.59, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [88/105], Loss: 4.461, Perp: 86.59, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [89/105], Loss: 4.461, Perp: 86.58, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [90/105], Loss: 4.461, Perp: 86.58, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [91/105], Loss: 4.461, Perp: 86.58, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [92/105], Loss: 4.461, Perp: 86.58, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [93/105], Loss: 4.461, Perp: 86.57, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [94/105], Loss: 4.461, Perp: 86.57, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [95/105], Loss: 4.461, Perp: 86.57, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [96/105], Loss: 4.461, Perp: 86.56, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [97/105], Loss: 4.461, Perp: 86.56, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [98/105], Loss: 4.461, Perp: 86.56, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [99/105], Loss: 4.461, Perp: 86.55, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [100/105], Loss: 4.461, Perp: 86.55, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [101/105], Loss: 4.461, Perp: 86.55, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [102/105], Loss: 4.461, Perp: 86.54, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [103/105], Loss: 4.461, Perp: 86.54, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [104/105], Loss: 4.461, Perp: 86.54, Acc: 0.25           here\n",
      "here\n",
      "Training: Epoch [13/40], Step [105/105], Loss: 4.461, Perp: 86.54, Acc: 0.25           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [1/26], Loss: 4.170, Perp: 64.73, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [2/26], Loss: 4.166, Perp: 64.47, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [3/26], Loss: 4.164, Perp: 64.33, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [4/26], Loss: 4.162, Perp: 64.22, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [5/26], Loss: 4.161, Perp: 64.14, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [6/26], Loss: 4.160, Perp: 64.07, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [7/26], Loss: 4.159, Perp: 64.01, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [8/26], Loss: 4.158, Perp: 63.97, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [9/26], Loss: 4.158, Perp: 63.94, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [10/26], Loss: 4.157, Perp: 63.91, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [11/26], Loss: 4.157, Perp: 63.88, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [12/26], Loss: 4.157, Perp: 63.85, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [13/26], Loss: 4.156, Perp: 63.82, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [14/26], Loss: 4.156, Perp: 63.79, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [15/26], Loss: 4.155, Perp: 63.77, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [16/26], Loss: 4.155, Perp: 63.74, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [17/26], Loss: 4.155, Perp: 63.72, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [18/26], Loss: 4.154, Perp: 63.70, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [19/26], Loss: 4.154, Perp: 63.68, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [20/26], Loss: 4.154, Perp: 63.66, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [21/26], Loss: 4.153, Perp: 63.65, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [22/26], Loss: 4.153, Perp: 63.63, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [23/26], Loss: 4.153, Perp: 63.62, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [24/26], Loss: 4.153, Perp: 63.60, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [25/26], Loss: 4.152, Perp: 63.59, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [13/40], Step [26/26], Loss: 4.152, Perp: 63.57, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [1/105], Loss: 4.281, Perp: 72.33, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [2/105], Loss: 4.280, Perp: 72.22, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [3/105], Loss: 4.280, Perp: 72.21, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [4/105], Loss: 4.280, Perp: 72.21, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [5/105], Loss: 4.279, Perp: 72.20, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [6/105], Loss: 4.279, Perp: 72.19, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [7/105], Loss: 4.279, Perp: 72.17, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [8/105], Loss: 4.279, Perp: 72.16, Acc: 0.27           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [14/40], Step [9/105], Loss: 4.279, Perp: 72.16, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [10/105], Loss: 4.279, Perp: 72.15, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [11/105], Loss: 4.279, Perp: 72.15, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [12/105], Loss: 4.279, Perp: 72.14, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [13/105], Loss: 4.279, Perp: 72.14, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [14/105], Loss: 4.279, Perp: 72.13, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [15/105], Loss: 4.278, Perp: 72.13, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [16/105], Loss: 4.278, Perp: 72.12, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [17/105], Loss: 4.278, Perp: 72.11, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [18/105], Loss: 4.278, Perp: 72.11, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [19/105], Loss: 4.278, Perp: 72.11, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [20/105], Loss: 4.278, Perp: 72.10, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [21/105], Loss: 4.278, Perp: 72.10, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [22/105], Loss: 4.278, Perp: 72.10, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [23/105], Loss: 4.278, Perp: 72.10, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [24/105], Loss: 4.278, Perp: 72.10, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [25/105], Loss: 4.278, Perp: 72.09, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [26/105], Loss: 4.278, Perp: 72.09, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [27/105], Loss: 4.278, Perp: 72.09, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [28/105], Loss: 4.278, Perp: 72.08, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [29/105], Loss: 4.278, Perp: 72.08, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [30/105], Loss: 4.278, Perp: 72.07, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [31/105], Loss: 4.278, Perp: 72.07, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [32/105], Loss: 4.278, Perp: 72.07, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [33/105], Loss: 4.278, Perp: 72.07, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [34/105], Loss: 4.277, Perp: 72.06, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [35/105], Loss: 4.277, Perp: 72.05, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [36/105], Loss: 4.277, Perp: 72.05, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [37/105], Loss: 4.277, Perp: 72.05, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [38/105], Loss: 4.277, Perp: 72.04, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [39/105], Loss: 4.277, Perp: 72.04, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [40/105], Loss: 4.277, Perp: 72.04, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [41/105], Loss: 4.277, Perp: 72.04, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [42/105], Loss: 4.277, Perp: 72.03, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [43/105], Loss: 4.277, Perp: 72.03, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [44/105], Loss: 4.277, Perp: 72.02, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [45/105], Loss: 4.277, Perp: 72.02, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [46/105], Loss: 4.277, Perp: 72.02, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [47/105], Loss: 4.277, Perp: 72.01, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [48/105], Loss: 4.277, Perp: 72.01, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [49/105], Loss: 4.277, Perp: 72.01, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [50/105], Loss: 4.277, Perp: 72.01, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [51/105], Loss: 4.277, Perp: 72.00, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [52/105], Loss: 4.277, Perp: 72.00, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [53/105], Loss: 4.277, Perp: 72.00, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [54/105], Loss: 4.277, Perp: 71.99, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [55/105], Loss: 4.276, Perp: 71.99, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [56/105], Loss: 4.276, Perp: 71.98, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [57/105], Loss: 4.276, Perp: 71.98, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [58/105], Loss: 4.276, Perp: 71.98, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [59/105], Loss: 4.276, Perp: 71.97, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [60/105], Loss: 4.276, Perp: 71.97, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [61/105], Loss: 4.276, Perp: 71.97, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [62/105], Loss: 4.276, Perp: 71.96, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [63/105], Loss: 4.276, Perp: 71.96, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [64/105], Loss: 4.276, Perp: 71.96, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [65/105], Loss: 4.276, Perp: 71.96, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [66/105], Loss: 4.276, Perp: 71.96, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [67/105], Loss: 4.276, Perp: 71.95, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [68/105], Loss: 4.276, Perp: 71.95, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [69/105], Loss: 4.276, Perp: 71.95, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [70/105], Loss: 4.276, Perp: 71.95, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [71/105], Loss: 4.276, Perp: 71.94, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [72/105], Loss: 4.276, Perp: 71.94, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [73/105], Loss: 4.276, Perp: 71.94, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [74/105], Loss: 4.276, Perp: 71.94, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [75/105], Loss: 4.276, Perp: 71.93, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [76/105], Loss: 4.276, Perp: 71.93, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [77/105], Loss: 4.276, Perp: 71.93, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [78/105], Loss: 4.276, Perp: 71.93, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [79/105], Loss: 4.276, Perp: 71.92, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [80/105], Loss: 4.276, Perp: 71.92, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [81/105], Loss: 4.275, Perp: 71.91, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [82/105], Loss: 4.275, Perp: 71.91, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [83/105], Loss: 4.275, Perp: 71.91, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [84/105], Loss: 4.275, Perp: 71.90, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [85/105], Loss: 4.275, Perp: 71.90, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [86/105], Loss: 4.275, Perp: 71.90, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [87/105], Loss: 4.275, Perp: 71.90, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [88/105], Loss: 4.275, Perp: 71.90, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [89/105], Loss: 4.275, Perp: 71.89, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [90/105], Loss: 4.275, Perp: 71.89, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [91/105], Loss: 4.275, Perp: 71.89, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [92/105], Loss: 4.275, Perp: 71.89, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [93/105], Loss: 4.275, Perp: 71.88, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [94/105], Loss: 4.275, Perp: 71.88, Acc: 0.27           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [14/40], Step [95/105], Loss: 4.275, Perp: 71.88, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [96/105], Loss: 4.275, Perp: 71.88, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [97/105], Loss: 4.275, Perp: 71.88, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [98/105], Loss: 4.275, Perp: 71.87, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [99/105], Loss: 4.275, Perp: 71.87, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [100/105], Loss: 4.275, Perp: 71.87, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [101/105], Loss: 4.275, Perp: 71.86, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [102/105], Loss: 4.275, Perp: 71.86, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [103/105], Loss: 4.275, Perp: 71.86, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [104/105], Loss: 4.275, Perp: 71.85, Acc: 0.27           here\n",
      "here\n",
      "Training: Epoch [14/40], Step [105/105], Loss: 4.275, Perp: 71.85, Acc: 0.27           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [1/26], Loss: 3.979, Perp: 53.48, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [2/26], Loss: 3.975, Perp: 53.27, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [3/26], Loss: 3.973, Perp: 53.15, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [4/26], Loss: 3.972, Perp: 53.07, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [5/26], Loss: 3.970, Perp: 53.01, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [6/26], Loss: 3.969, Perp: 52.96, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [7/26], Loss: 3.969, Perp: 52.92, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [8/26], Loss: 3.968, Perp: 52.89, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [9/26], Loss: 3.968, Perp: 52.86, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [10/26], Loss: 3.967, Perp: 52.84, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [11/26], Loss: 3.967, Perp: 52.82, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [12/26], Loss: 3.966, Perp: 52.80, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [13/26], Loss: 3.966, Perp: 52.78, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [14/26], Loss: 3.966, Perp: 52.75, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [15/26], Loss: 3.965, Perp: 52.73, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [16/26], Loss: 3.965, Perp: 52.72, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [17/26], Loss: 3.965, Perp: 52.70, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [18/26], Loss: 3.964, Perp: 52.69, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [19/26], Loss: 3.964, Perp: 52.67, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [20/26], Loss: 3.964, Perp: 52.66, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [21/26], Loss: 3.964, Perp: 52.64, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [22/26], Loss: 3.963, Perp: 52.63, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [23/26], Loss: 3.963, Perp: 52.62, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [24/26], Loss: 3.963, Perp: 52.61, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [25/26], Loss: 3.963, Perp: 52.60, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [14/40], Step [26/26], Loss: 3.963, Perp: 52.59, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [1/105], Loss: 4.109, Perp: 60.87, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [2/105], Loss: 4.107, Perp: 60.79, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [3/105], Loss: 4.107, Perp: 60.79, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [4/105], Loss: 4.108, Perp: 60.80, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [5/105], Loss: 4.107, Perp: 60.79, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [6/105], Loss: 4.107, Perp: 60.78, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [7/105], Loss: 4.107, Perp: 60.77, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [8/105], Loss: 4.107, Perp: 60.76, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [9/105], Loss: 4.107, Perp: 60.76, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [10/105], Loss: 4.107, Perp: 60.75, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [11/105], Loss: 4.107, Perp: 60.74, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [12/105], Loss: 4.107, Perp: 60.74, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [13/105], Loss: 4.107, Perp: 60.74, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [14/105], Loss: 4.106, Perp: 60.73, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [15/105], Loss: 4.106, Perp: 60.72, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [16/105], Loss: 4.106, Perp: 60.72, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [17/105], Loss: 4.106, Perp: 60.72, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [18/105], Loss: 4.106, Perp: 60.72, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [19/105], Loss: 4.106, Perp: 60.71, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [20/105], Loss: 4.106, Perp: 60.71, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [21/105], Loss: 4.106, Perp: 60.71, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [22/105], Loss: 4.106, Perp: 60.70, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [23/105], Loss: 4.106, Perp: 60.70, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [24/105], Loss: 4.106, Perp: 60.70, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [25/105], Loss: 4.106, Perp: 60.69, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [26/105], Loss: 4.106, Perp: 60.69, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [27/105], Loss: 4.106, Perp: 60.69, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [28/105], Loss: 4.106, Perp: 60.68, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [29/105], Loss: 4.106, Perp: 60.68, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [30/105], Loss: 4.106, Perp: 60.68, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [31/105], Loss: 4.106, Perp: 60.67, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [32/105], Loss: 4.105, Perp: 60.67, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [33/105], Loss: 4.105, Perp: 60.67, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [34/105], Loss: 4.105, Perp: 60.66, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [35/105], Loss: 4.105, Perp: 60.66, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [36/105], Loss: 4.105, Perp: 60.66, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [37/105], Loss: 4.105, Perp: 60.66, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [38/105], Loss: 4.105, Perp: 60.66, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [39/105], Loss: 4.105, Perp: 60.65, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [40/105], Loss: 4.105, Perp: 60.65, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [41/105], Loss: 4.105, Perp: 60.65, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [42/105], Loss: 4.105, Perp: 60.65, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [43/105], Loss: 4.105, Perp: 60.64, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [44/105], Loss: 4.105, Perp: 60.64, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [45/105], Loss: 4.105, Perp: 60.64, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [46/105], Loss: 4.105, Perp: 60.63, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [47/105], Loss: 4.105, Perp: 60.63, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [48/105], Loss: 4.105, Perp: 60.63, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [49/105], Loss: 4.105, Perp: 60.63, Acc: 0.28           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [15/40], Step [50/105], Loss: 4.105, Perp: 60.62, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [51/105], Loss: 4.105, Perp: 60.62, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [52/105], Loss: 4.105, Perp: 60.62, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [53/105], Loss: 4.105, Perp: 60.62, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [54/105], Loss: 4.105, Perp: 60.61, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [55/105], Loss: 4.104, Perp: 60.61, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [56/105], Loss: 4.104, Perp: 60.61, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [57/105], Loss: 4.104, Perp: 60.60, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [58/105], Loss: 4.104, Perp: 60.60, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [59/105], Loss: 4.104, Perp: 60.60, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [60/105], Loss: 4.104, Perp: 60.60, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [61/105], Loss: 4.104, Perp: 60.59, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [62/105], Loss: 4.104, Perp: 60.59, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [63/105], Loss: 4.104, Perp: 60.59, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [64/105], Loss: 4.104, Perp: 60.59, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [65/105], Loss: 4.104, Perp: 60.58, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [66/105], Loss: 4.104, Perp: 60.58, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [67/105], Loss: 4.104, Perp: 60.58, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [68/105], Loss: 4.104, Perp: 60.58, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [69/105], Loss: 4.104, Perp: 60.58, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [70/105], Loss: 4.104, Perp: 60.57, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [71/105], Loss: 4.104, Perp: 60.57, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [72/105], Loss: 4.104, Perp: 60.57, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [73/105], Loss: 4.104, Perp: 60.57, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [74/105], Loss: 4.104, Perp: 60.57, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [75/105], Loss: 4.104, Perp: 60.56, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [76/105], Loss: 4.104, Perp: 60.56, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [77/105], Loss: 4.104, Perp: 60.56, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [78/105], Loss: 4.104, Perp: 60.56, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [79/105], Loss: 4.104, Perp: 60.55, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [80/105], Loss: 4.104, Perp: 60.55, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [81/105], Loss: 4.103, Perp: 60.55, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [82/105], Loss: 4.103, Perp: 60.55, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [83/105], Loss: 4.103, Perp: 60.54, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [84/105], Loss: 4.103, Perp: 60.54, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [85/105], Loss: 4.103, Perp: 60.54, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [86/105], Loss: 4.103, Perp: 60.54, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [87/105], Loss: 4.103, Perp: 60.54, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [88/105], Loss: 4.103, Perp: 60.53, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [89/105], Loss: 4.103, Perp: 60.53, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [90/105], Loss: 4.103, Perp: 60.53, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [91/105], Loss: 4.103, Perp: 60.53, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [92/105], Loss: 4.103, Perp: 60.53, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [93/105], Loss: 4.103, Perp: 60.53, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [94/105], Loss: 4.103, Perp: 60.52, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [95/105], Loss: 4.103, Perp: 60.52, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [96/105], Loss: 4.103, Perp: 60.52, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [97/105], Loss: 4.103, Perp: 60.52, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [98/105], Loss: 4.103, Perp: 60.52, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [99/105], Loss: 4.103, Perp: 60.52, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [100/105], Loss: 4.103, Perp: 60.51, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [101/105], Loss: 4.103, Perp: 60.51, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [102/105], Loss: 4.103, Perp: 60.51, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [103/105], Loss: 4.103, Perp: 60.51, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [104/105], Loss: 4.103, Perp: 60.50, Acc: 0.28           here\n",
      "here\n",
      "Training: Epoch [15/40], Step [105/105], Loss: 4.103, Perp: 60.50, Acc: 0.28           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [1/26], Loss: 3.874, Perp: 48.12, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [2/26], Loss: 3.870, Perp: 47.93, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [3/26], Loss: 3.867, Perp: 47.82, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [4/26], Loss: 3.866, Perp: 47.74, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [5/26], Loss: 3.865, Perp: 47.68, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [6/26], Loss: 3.864, Perp: 47.63, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [7/26], Loss: 3.863, Perp: 47.60, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [8/26], Loss: 3.862, Perp: 47.57, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [9/26], Loss: 3.862, Perp: 47.54, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [10/26], Loss: 3.861, Perp: 47.52, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [11/26], Loss: 3.861, Perp: 47.50, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [12/26], Loss: 3.860, Perp: 47.48, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [13/26], Loss: 3.860, Perp: 47.46, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [14/26], Loss: 3.859, Perp: 47.44, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [15/26], Loss: 3.859, Perp: 47.42, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [16/26], Loss: 3.859, Perp: 47.41, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [17/26], Loss: 3.858, Perp: 47.39, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [18/26], Loss: 3.858, Perp: 47.38, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [19/26], Loss: 3.858, Perp: 47.36, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [20/26], Loss: 3.858, Perp: 47.35, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [21/26], Loss: 3.857, Perp: 47.34, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [22/26], Loss: 3.857, Perp: 47.32, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [23/26], Loss: 3.857, Perp: 47.32, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [24/26], Loss: 3.857, Perp: 47.30, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [25/26], Loss: 3.856, Perp: 47.29, Acc: 0.32           here\n",
      "here\n",
      "Validation: Epoch [15/40], Step [26/26], Loss: 3.856, Perp: 47.28, Acc: 0.32           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [1/105], Loss: 4.015, Perp: 55.44, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [2/105], Loss: 4.013, Perp: 55.32, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [3/105], Loss: 4.013, Perp: 55.29, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [4/105], Loss: 4.012, Perp: 55.28, Acc: 0.29           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [16/40], Step [5/105], Loss: 4.012, Perp: 55.25, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [6/105], Loss: 4.011, Perp: 55.22, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [7/105], Loss: 4.011, Perp: 55.20, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [8/105], Loss: 4.011, Perp: 55.18, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [9/105], Loss: 4.010, Perp: 55.17, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [10/105], Loss: 4.010, Perp: 55.16, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [11/105], Loss: 4.010, Perp: 55.15, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [12/105], Loss: 4.010, Perp: 55.14, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [13/105], Loss: 4.010, Perp: 55.13, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [14/105], Loss: 4.010, Perp: 55.13, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [15/105], Loss: 4.009, Perp: 55.11, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [16/105], Loss: 4.009, Perp: 55.10, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [17/105], Loss: 4.009, Perp: 55.10, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [18/105], Loss: 4.009, Perp: 55.09, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [19/105], Loss: 4.009, Perp: 55.08, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [20/105], Loss: 4.009, Perp: 55.08, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [21/105], Loss: 4.009, Perp: 55.08, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [22/105], Loss: 4.009, Perp: 55.07, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [23/105], Loss: 4.009, Perp: 55.07, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [24/105], Loss: 4.008, Perp: 55.06, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [25/105], Loss: 4.008, Perp: 55.06, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [26/105], Loss: 4.008, Perp: 55.05, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [27/105], Loss: 4.008, Perp: 55.04, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [28/105], Loss: 4.008, Perp: 55.04, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [29/105], Loss: 4.008, Perp: 55.04, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [30/105], Loss: 4.008, Perp: 55.03, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [31/105], Loss: 4.008, Perp: 55.02, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [32/105], Loss: 4.008, Perp: 55.02, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [33/105], Loss: 4.008, Perp: 55.01, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [34/105], Loss: 4.007, Perp: 55.01, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [35/105], Loss: 4.007, Perp: 55.00, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [36/105], Loss: 4.007, Perp: 55.00, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [37/105], Loss: 4.007, Perp: 54.99, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [38/105], Loss: 4.007, Perp: 54.99, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [39/105], Loss: 4.007, Perp: 54.99, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [40/105], Loss: 4.007, Perp: 54.98, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [41/105], Loss: 4.007, Perp: 54.98, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [42/105], Loss: 4.007, Perp: 54.98, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [43/105], Loss: 4.007, Perp: 54.97, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [44/105], Loss: 4.007, Perp: 54.97, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [45/105], Loss: 4.007, Perp: 54.96, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [46/105], Loss: 4.007, Perp: 54.96, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [47/105], Loss: 4.006, Perp: 54.95, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [48/105], Loss: 4.006, Perp: 54.95, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [49/105], Loss: 4.006, Perp: 54.95, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [50/105], Loss: 4.006, Perp: 54.95, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [51/105], Loss: 4.006, Perp: 54.94, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [52/105], Loss: 4.006, Perp: 54.94, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [53/105], Loss: 4.006, Perp: 54.94, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [54/105], Loss: 4.006, Perp: 54.93, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [55/105], Loss: 4.006, Perp: 54.93, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [56/105], Loss: 4.006, Perp: 54.92, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [57/105], Loss: 4.006, Perp: 54.92, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [58/105], Loss: 4.006, Perp: 54.92, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [59/105], Loss: 4.006, Perp: 54.91, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [60/105], Loss: 4.006, Perp: 54.91, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [61/105], Loss: 4.006, Perp: 54.91, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [62/105], Loss: 4.006, Perp: 54.91, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [63/105], Loss: 4.006, Perp: 54.90, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [64/105], Loss: 4.006, Perp: 54.90, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [65/105], Loss: 4.005, Perp: 54.90, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [66/105], Loss: 4.005, Perp: 54.90, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [67/105], Loss: 4.005, Perp: 54.89, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [68/105], Loss: 4.005, Perp: 54.89, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [69/105], Loss: 4.005, Perp: 54.89, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [70/105], Loss: 4.005, Perp: 54.89, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [71/105], Loss: 4.005, Perp: 54.88, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [72/105], Loss: 4.005, Perp: 54.88, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [73/105], Loss: 4.005, Perp: 54.88, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [74/105], Loss: 4.005, Perp: 54.88, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [75/105], Loss: 4.005, Perp: 54.87, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [76/105], Loss: 4.005, Perp: 54.87, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [77/105], Loss: 4.005, Perp: 54.87, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [78/105], Loss: 4.005, Perp: 54.87, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [79/105], Loss: 4.005, Perp: 54.87, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [80/105], Loss: 4.005, Perp: 54.86, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [81/105], Loss: 4.005, Perp: 54.86, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [82/105], Loss: 4.005, Perp: 54.86, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [83/105], Loss: 4.005, Perp: 54.85, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [84/105], Loss: 4.005, Perp: 54.85, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [85/105], Loss: 4.005, Perp: 54.85, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [86/105], Loss: 4.005, Perp: 54.85, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [87/105], Loss: 4.004, Perp: 54.84, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [88/105], Loss: 4.004, Perp: 54.84, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [89/105], Loss: 4.004, Perp: 54.84, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [90/105], Loss: 4.004, Perp: 54.84, Acc: 0.29           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [16/40], Step [91/105], Loss: 4.004, Perp: 54.83, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [92/105], Loss: 4.004, Perp: 54.83, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [93/105], Loss: 4.004, Perp: 54.83, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [94/105], Loss: 4.004, Perp: 54.83, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [95/105], Loss: 4.004, Perp: 54.83, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [96/105], Loss: 4.004, Perp: 54.82, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [97/105], Loss: 4.004, Perp: 54.82, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [98/105], Loss: 4.004, Perp: 54.82, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [99/105], Loss: 4.004, Perp: 54.82, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [100/105], Loss: 4.004, Perp: 54.82, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [101/105], Loss: 4.004, Perp: 54.82, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [102/105], Loss: 4.004, Perp: 54.81, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [103/105], Loss: 4.004, Perp: 54.81, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [104/105], Loss: 4.004, Perp: 54.81, Acc: 0.29           here\n",
      "here\n",
      "Training: Epoch [16/40], Step [105/105], Loss: 4.004, Perp: 54.80, Acc: 0.29           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [1/26], Loss: 3.750, Perp: 42.53, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [2/26], Loss: 3.746, Perp: 42.37, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [3/26], Loss: 3.744, Perp: 42.26, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [4/26], Loss: 3.742, Perp: 42.18, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [5/26], Loss: 3.740, Perp: 42.12, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [6/26], Loss: 3.739, Perp: 42.06, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [7/26], Loss: 3.738, Perp: 42.02, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [8/26], Loss: 3.737, Perp: 41.99, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [9/26], Loss: 3.737, Perp: 41.96, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [10/26], Loss: 3.736, Perp: 41.93, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [11/26], Loss: 3.736, Perp: 41.91, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [12/26], Loss: 3.735, Perp: 41.89, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [13/26], Loss: 3.734, Perp: 41.86, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [14/26], Loss: 3.734, Perp: 41.83, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [15/26], Loss: 3.733, Perp: 41.81, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [16/26], Loss: 3.733, Perp: 41.79, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [17/26], Loss: 3.732, Perp: 41.78, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [18/26], Loss: 3.732, Perp: 41.76, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [19/26], Loss: 3.732, Perp: 41.74, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [20/26], Loss: 3.731, Perp: 41.73, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [21/26], Loss: 3.731, Perp: 41.71, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [22/26], Loss: 3.731, Perp: 41.70, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [23/26], Loss: 3.730, Perp: 41.69, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [24/26], Loss: 3.730, Perp: 41.68, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [25/26], Loss: 3.730, Perp: 41.66, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [16/40], Step [26/26], Loss: 3.729, Perp: 41.65, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [1/105], Loss: 3.910, Perp: 49.89, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [2/105], Loss: 3.908, Perp: 49.78, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [3/105], Loss: 3.907, Perp: 49.73, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [4/105], Loss: 3.906, Perp: 49.71, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [5/105], Loss: 3.906, Perp: 49.68, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [6/105], Loss: 3.905, Perp: 49.65, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [7/105], Loss: 3.905, Perp: 49.63, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [8/105], Loss: 3.904, Perp: 49.61, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [9/105], Loss: 3.904, Perp: 49.60, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [10/105], Loss: 3.904, Perp: 49.59, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [11/105], Loss: 3.903, Perp: 49.58, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [12/105], Loss: 3.903, Perp: 49.56, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [13/105], Loss: 3.903, Perp: 49.55, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [14/105], Loss: 3.903, Perp: 49.54, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [15/105], Loss: 3.903, Perp: 49.53, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [16/105], Loss: 3.902, Perp: 49.52, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [17/105], Loss: 3.902, Perp: 49.51, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [18/105], Loss: 3.902, Perp: 49.50, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [19/105], Loss: 3.902, Perp: 49.50, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [20/105], Loss: 3.902, Perp: 49.49, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [21/105], Loss: 3.902, Perp: 49.48, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [22/105], Loss: 3.902, Perp: 49.48, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [23/105], Loss: 3.901, Perp: 49.47, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [24/105], Loss: 3.901, Perp: 49.46, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [25/105], Loss: 3.901, Perp: 49.46, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [26/105], Loss: 3.901, Perp: 49.45, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [27/105], Loss: 3.901, Perp: 49.44, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [28/105], Loss: 3.901, Perp: 49.43, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [29/105], Loss: 3.901, Perp: 49.43, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [30/105], Loss: 3.900, Perp: 49.43, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [31/105], Loss: 3.900, Perp: 49.42, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [32/105], Loss: 3.900, Perp: 49.41, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [33/105], Loss: 3.900, Perp: 49.41, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [34/105], Loss: 3.900, Perp: 49.40, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [35/105], Loss: 3.900, Perp: 49.39, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [36/105], Loss: 3.900, Perp: 49.39, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [37/105], Loss: 3.900, Perp: 49.39, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [38/105], Loss: 3.900, Perp: 49.38, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [39/105], Loss: 3.899, Perp: 49.38, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [40/105], Loss: 3.899, Perp: 49.37, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [41/105], Loss: 3.899, Perp: 49.37, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [42/105], Loss: 3.899, Perp: 49.36, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [43/105], Loss: 3.899, Perp: 49.36, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [44/105], Loss: 3.899, Perp: 49.35, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [45/105], Loss: 3.899, Perp: 49.35, Acc: 0.30           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [17/40], Step [46/105], Loss: 3.899, Perp: 49.34, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [47/105], Loss: 3.899, Perp: 49.34, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [48/105], Loss: 3.899, Perp: 49.34, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [49/105], Loss: 3.899, Perp: 49.33, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [50/105], Loss: 3.899, Perp: 49.33, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [51/105], Loss: 3.898, Perp: 49.33, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [52/105], Loss: 3.898, Perp: 49.32, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [53/105], Loss: 3.898, Perp: 49.32, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [54/105], Loss: 3.898, Perp: 49.32, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [55/105], Loss: 3.898, Perp: 49.31, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [56/105], Loss: 3.898, Perp: 49.31, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [57/105], Loss: 3.898, Perp: 49.31, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [58/105], Loss: 3.898, Perp: 49.30, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [59/105], Loss: 3.898, Perp: 49.30, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [60/105], Loss: 3.898, Perp: 49.29, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [61/105], Loss: 3.898, Perp: 49.29, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [62/105], Loss: 3.898, Perp: 49.29, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [63/105], Loss: 3.898, Perp: 49.29, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [64/105], Loss: 3.898, Perp: 49.28, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [65/105], Loss: 3.898, Perp: 49.28, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [66/105], Loss: 3.897, Perp: 49.28, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [67/105], Loss: 3.897, Perp: 49.27, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [68/105], Loss: 3.897, Perp: 49.27, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [69/105], Loss: 3.897, Perp: 49.27, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [70/105], Loss: 3.897, Perp: 49.27, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [71/105], Loss: 3.897, Perp: 49.26, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [72/105], Loss: 3.897, Perp: 49.26, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [73/105], Loss: 3.897, Perp: 49.26, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [74/105], Loss: 3.897, Perp: 49.26, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [75/105], Loss: 3.897, Perp: 49.25, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [76/105], Loss: 3.897, Perp: 49.25, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [77/105], Loss: 3.897, Perp: 49.25, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [78/105], Loss: 3.897, Perp: 49.25, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [79/105], Loss: 3.897, Perp: 49.24, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [80/105], Loss: 3.897, Perp: 49.24, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [81/105], Loss: 3.897, Perp: 49.24, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [82/105], Loss: 3.897, Perp: 49.24, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [83/105], Loss: 3.897, Perp: 49.23, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [84/105], Loss: 3.896, Perp: 49.23, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [85/105], Loss: 3.896, Perp: 49.23, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [86/105], Loss: 3.896, Perp: 49.22, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [87/105], Loss: 3.896, Perp: 49.22, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [88/105], Loss: 3.896, Perp: 49.22, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [89/105], Loss: 3.896, Perp: 49.22, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [90/105], Loss: 3.896, Perp: 49.21, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [91/105], Loss: 3.896, Perp: 49.21, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [92/105], Loss: 3.896, Perp: 49.21, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [93/105], Loss: 3.896, Perp: 49.21, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [94/105], Loss: 3.896, Perp: 49.21, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [95/105], Loss: 3.896, Perp: 49.20, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [96/105], Loss: 3.896, Perp: 49.20, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [97/105], Loss: 3.896, Perp: 49.20, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [98/105], Loss: 3.896, Perp: 49.20, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [99/105], Loss: 3.896, Perp: 49.20, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [100/105], Loss: 3.896, Perp: 49.19, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [101/105], Loss: 3.896, Perp: 49.19, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [102/105], Loss: 3.896, Perp: 49.19, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [103/105], Loss: 3.896, Perp: 49.19, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [104/105], Loss: 3.896, Perp: 49.18, Acc: 0.30           here\n",
      "here\n",
      "Training: Epoch [17/40], Step [105/105], Loss: 3.896, Perp: 49.18, Acc: 0.30           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [1/26], Loss: 3.661, Perp: 38.89, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [2/26], Loss: 3.656, Perp: 38.70, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [3/26], Loss: 3.653, Perp: 38.57, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [4/26], Loss: 3.650, Perp: 38.49, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [5/26], Loss: 3.649, Perp: 38.42, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [6/26], Loss: 3.647, Perp: 38.37, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [7/26], Loss: 3.646, Perp: 38.32, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [8/26], Loss: 3.645, Perp: 38.29, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [9/26], Loss: 3.644, Perp: 38.26, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [10/26], Loss: 3.644, Perp: 38.23, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [11/26], Loss: 3.643, Perp: 38.21, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [12/26], Loss: 3.642, Perp: 38.18, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [13/26], Loss: 3.642, Perp: 38.16, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [14/26], Loss: 3.641, Perp: 38.13, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [15/26], Loss: 3.640, Perp: 38.11, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [16/26], Loss: 3.640, Perp: 38.09, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [17/26], Loss: 3.640, Perp: 38.07, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [18/26], Loss: 3.639, Perp: 38.06, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [19/26], Loss: 3.639, Perp: 38.04, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [20/26], Loss: 3.638, Perp: 38.03, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [21/26], Loss: 3.638, Perp: 38.01, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [22/26], Loss: 3.638, Perp: 38.00, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [23/26], Loss: 3.637, Perp: 37.99, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [24/26], Loss: 3.637, Perp: 37.97, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [17/40], Step [25/26], Loss: 3.637, Perp: 37.96, Acc: 0.35           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [17/40], Step [26/26], Loss: 3.636, Perp: 37.95, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [1/105], Loss: 3.770, Perp: 43.36, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [2/105], Loss: 3.767, Perp: 43.23, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [3/105], Loss: 3.766, Perp: 43.19, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [4/105], Loss: 3.765, Perp: 43.16, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [5/105], Loss: 3.764, Perp: 43.14, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [6/105], Loss: 3.764, Perp: 43.11, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [7/105], Loss: 3.763, Perp: 43.09, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [8/105], Loss: 3.763, Perp: 43.07, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [9/105], Loss: 3.762, Perp: 43.05, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [10/105], Loss: 3.762, Perp: 43.04, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [11/105], Loss: 3.762, Perp: 43.03, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [12/105], Loss: 3.762, Perp: 43.02, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [13/105], Loss: 3.761, Perp: 43.01, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [14/105], Loss: 3.761, Perp: 43.00, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [15/105], Loss: 3.761, Perp: 42.99, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [16/105], Loss: 3.761, Perp: 42.98, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [17/105], Loss: 3.761, Perp: 42.97, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [18/105], Loss: 3.760, Perp: 42.96, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [19/105], Loss: 3.760, Perp: 42.96, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [20/105], Loss: 3.760, Perp: 42.95, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [21/105], Loss: 3.760, Perp: 42.94, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [22/105], Loss: 3.760, Perp: 42.94, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [23/105], Loss: 3.760, Perp: 42.93, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [24/105], Loss: 3.759, Perp: 42.93, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [25/105], Loss: 3.759, Perp: 42.92, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [26/105], Loss: 3.759, Perp: 42.92, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [27/105], Loss: 3.759, Perp: 42.91, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [28/105], Loss: 3.759, Perp: 42.90, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [29/105], Loss: 3.759, Perp: 42.90, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [30/105], Loss: 3.759, Perp: 42.89, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [31/105], Loss: 3.759, Perp: 42.89, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [32/105], Loss: 3.758, Perp: 42.88, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [33/105], Loss: 3.758, Perp: 42.88, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [34/105], Loss: 3.758, Perp: 42.87, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [35/105], Loss: 3.758, Perp: 42.87, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [36/105], Loss: 3.758, Perp: 42.87, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [37/105], Loss: 3.758, Perp: 42.86, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [38/105], Loss: 3.758, Perp: 42.86, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [39/105], Loss: 3.758, Perp: 42.85, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [40/105], Loss: 3.758, Perp: 42.85, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [41/105], Loss: 3.758, Perp: 42.85, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [42/105], Loss: 3.758, Perp: 42.84, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [43/105], Loss: 3.757, Perp: 42.84, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [44/105], Loss: 3.757, Perp: 42.83, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [45/105], Loss: 3.757, Perp: 42.83, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [46/105], Loss: 3.757, Perp: 42.83, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [47/105], Loss: 3.757, Perp: 42.82, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [48/105], Loss: 3.757, Perp: 42.82, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [49/105], Loss: 3.757, Perp: 42.82, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [50/105], Loss: 3.757, Perp: 42.82, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [51/105], Loss: 3.757, Perp: 42.81, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [52/105], Loss: 3.757, Perp: 42.81, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [53/105], Loss: 3.757, Perp: 42.81, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [54/105], Loss: 3.757, Perp: 42.80, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [55/105], Loss: 3.757, Perp: 42.80, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [56/105], Loss: 3.757, Perp: 42.80, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [57/105], Loss: 3.756, Perp: 42.80, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [58/105], Loss: 3.756, Perp: 42.79, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [59/105], Loss: 3.756, Perp: 42.79, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [60/105], Loss: 3.756, Perp: 42.79, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [61/105], Loss: 3.756, Perp: 42.78, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [62/105], Loss: 3.756, Perp: 42.78, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [63/105], Loss: 3.756, Perp: 42.78, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [64/105], Loss: 3.756, Perp: 42.78, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [65/105], Loss: 3.756, Perp: 42.77, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [66/105], Loss: 3.756, Perp: 42.77, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [67/105], Loss: 3.756, Perp: 42.77, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [68/105], Loss: 3.756, Perp: 42.77, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [69/105], Loss: 3.756, Perp: 42.76, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [70/105], Loss: 3.756, Perp: 42.76, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [71/105], Loss: 3.756, Perp: 42.76, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [72/105], Loss: 3.756, Perp: 42.76, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [73/105], Loss: 3.755, Perp: 42.75, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [74/105], Loss: 3.755, Perp: 42.75, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [75/105], Loss: 3.755, Perp: 42.75, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [76/105], Loss: 3.755, Perp: 42.75, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [77/105], Loss: 3.755, Perp: 42.75, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [78/105], Loss: 3.755, Perp: 42.75, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [79/105], Loss: 3.755, Perp: 42.74, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [80/105], Loss: 3.755, Perp: 42.74, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [81/105], Loss: 3.755, Perp: 42.74, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [82/105], Loss: 3.755, Perp: 42.74, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [83/105], Loss: 3.755, Perp: 42.73, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [84/105], Loss: 3.755, Perp: 42.73, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [85/105], Loss: 3.755, Perp: 42.73, Acc: 0.31           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [18/40], Step [86/105], Loss: 3.755, Perp: 42.73, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [87/105], Loss: 3.755, Perp: 42.72, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [88/105], Loss: 3.755, Perp: 42.72, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [89/105], Loss: 3.755, Perp: 42.72, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [90/105], Loss: 3.755, Perp: 42.72, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [91/105], Loss: 3.755, Perp: 42.72, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [92/105], Loss: 3.755, Perp: 42.71, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [93/105], Loss: 3.754, Perp: 42.71, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [94/105], Loss: 3.754, Perp: 42.71, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [95/105], Loss: 3.754, Perp: 42.71, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [96/105], Loss: 3.754, Perp: 42.71, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [97/105], Loss: 3.754, Perp: 42.71, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [98/105], Loss: 3.754, Perp: 42.70, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [99/105], Loss: 3.754, Perp: 42.70, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [100/105], Loss: 3.754, Perp: 42.70, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [101/105], Loss: 3.754, Perp: 42.70, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [102/105], Loss: 3.754, Perp: 42.70, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [103/105], Loss: 3.754, Perp: 42.69, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [104/105], Loss: 3.754, Perp: 42.69, Acc: 0.31           here\n",
      "here\n",
      "Training: Epoch [18/40], Step [105/105], Loss: 3.754, Perp: 42.69, Acc: 0.31           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [1/26], Loss: 3.407, Perp: 30.16, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [2/26], Loss: 3.402, Perp: 30.02, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [3/26], Loss: 3.399, Perp: 29.94, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [4/26], Loss: 3.397, Perp: 29.88, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [5/26], Loss: 3.395, Perp: 29.83, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [6/26], Loss: 3.394, Perp: 29.79, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [7/26], Loss: 3.393, Perp: 29.76, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [8/26], Loss: 3.392, Perp: 29.73, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [9/26], Loss: 3.391, Perp: 29.71, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [10/26], Loss: 3.391, Perp: 29.69, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [11/26], Loss: 3.390, Perp: 29.67, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [12/26], Loss: 3.390, Perp: 29.65, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [13/26], Loss: 3.389, Perp: 29.63, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [14/26], Loss: 3.388, Perp: 29.61, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [15/26], Loss: 3.388, Perp: 29.59, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [16/26], Loss: 3.387, Perp: 29.58, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [17/26], Loss: 3.387, Perp: 29.57, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [18/26], Loss: 3.386, Perp: 29.55, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [19/26], Loss: 3.386, Perp: 29.54, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [20/26], Loss: 3.385, Perp: 29.53, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [21/26], Loss: 3.385, Perp: 29.52, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [22/26], Loss: 3.385, Perp: 29.51, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [23/26], Loss: 3.384, Perp: 29.49, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [24/26], Loss: 3.384, Perp: 29.48, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [25/26], Loss: 3.384, Perp: 29.47, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [18/40], Step [26/26], Loss: 3.383, Perp: 29.46, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [1/105], Loss: 3.625, Perp: 37.51, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [2/105], Loss: 3.622, Perp: 37.41, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [3/105], Loss: 3.621, Perp: 37.37, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [4/105], Loss: 3.620, Perp: 37.35, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [5/105], Loss: 3.620, Perp: 37.32, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [6/105], Loss: 3.619, Perp: 37.30, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [7/105], Loss: 3.618, Perp: 37.28, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [8/105], Loss: 3.618, Perp: 37.26, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [9/105], Loss: 3.618, Perp: 37.25, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [10/105], Loss: 3.617, Perp: 37.24, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [11/105], Loss: 3.617, Perp: 37.23, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [12/105], Loss: 3.617, Perp: 37.23, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [13/105], Loss: 3.617, Perp: 37.22, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [14/105], Loss: 3.617, Perp: 37.21, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [15/105], Loss: 3.616, Perp: 37.20, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [16/105], Loss: 3.616, Perp: 37.20, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [17/105], Loss: 3.616, Perp: 37.19, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [18/105], Loss: 3.616, Perp: 37.18, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [19/105], Loss: 3.616, Perp: 37.18, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [20/105], Loss: 3.616, Perp: 37.17, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [21/105], Loss: 3.615, Perp: 37.17, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [22/105], Loss: 3.615, Perp: 37.16, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [23/105], Loss: 3.615, Perp: 37.15, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [24/105], Loss: 3.615, Perp: 37.15, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [25/105], Loss: 3.615, Perp: 37.15, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [26/105], Loss: 3.615, Perp: 37.14, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [27/105], Loss: 3.615, Perp: 37.14, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [28/105], Loss: 3.614, Perp: 37.13, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [29/105], Loss: 3.614, Perp: 37.13, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [30/105], Loss: 3.614, Perp: 37.12, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [31/105], Loss: 3.614, Perp: 37.12, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [32/105], Loss: 3.614, Perp: 37.12, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [33/105], Loss: 3.614, Perp: 37.11, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [34/105], Loss: 3.614, Perp: 37.11, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [35/105], Loss: 3.614, Perp: 37.10, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [36/105], Loss: 3.614, Perp: 37.10, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [37/105], Loss: 3.614, Perp: 37.10, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [38/105], Loss: 3.613, Perp: 37.09, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [39/105], Loss: 3.613, Perp: 37.09, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [40/105], Loss: 3.613, Perp: 37.09, Acc: 0.33           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [19/40], Step [41/105], Loss: 3.613, Perp: 37.09, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [42/105], Loss: 3.613, Perp: 37.08, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [43/105], Loss: 3.613, Perp: 37.08, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [44/105], Loss: 3.613, Perp: 37.07, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [45/105], Loss: 3.613, Perp: 37.07, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [46/105], Loss: 3.613, Perp: 37.07, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [47/105], Loss: 3.613, Perp: 37.06, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [48/105], Loss: 3.613, Perp: 37.06, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [49/105], Loss: 3.613, Perp: 37.06, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [50/105], Loss: 3.613, Perp: 37.06, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [51/105], Loss: 3.612, Perp: 37.06, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [52/105], Loss: 3.612, Perp: 37.05, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [53/105], Loss: 3.612, Perp: 37.05, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [54/105], Loss: 3.612, Perp: 37.05, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [55/105], Loss: 3.612, Perp: 37.05, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [56/105], Loss: 3.612, Perp: 37.04, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [57/105], Loss: 3.612, Perp: 37.04, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [58/105], Loss: 3.612, Perp: 37.04, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [59/105], Loss: 3.612, Perp: 37.04, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [60/105], Loss: 3.612, Perp: 37.03, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [61/105], Loss: 3.612, Perp: 37.03, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [62/105], Loss: 3.612, Perp: 37.03, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [63/105], Loss: 3.612, Perp: 37.03, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [64/105], Loss: 3.612, Perp: 37.03, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [65/105], Loss: 3.612, Perp: 37.02, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [66/105], Loss: 3.612, Perp: 37.02, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [67/105], Loss: 3.611, Perp: 37.02, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [68/105], Loss: 3.611, Perp: 37.02, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [69/105], Loss: 3.611, Perp: 37.02, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [70/105], Loss: 3.611, Perp: 37.02, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [71/105], Loss: 3.611, Perp: 37.01, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [72/105], Loss: 3.611, Perp: 37.01, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [73/105], Loss: 3.611, Perp: 37.01, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [74/105], Loss: 3.611, Perp: 37.01, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [75/105], Loss: 3.611, Perp: 37.00, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [76/105], Loss: 3.611, Perp: 37.00, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [77/105], Loss: 3.611, Perp: 37.00, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [78/105], Loss: 3.611, Perp: 37.00, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [79/105], Loss: 3.611, Perp: 37.00, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [80/105], Loss: 3.611, Perp: 36.99, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [81/105], Loss: 3.611, Perp: 36.99, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [82/105], Loss: 3.611, Perp: 36.99, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [83/105], Loss: 3.611, Perp: 36.99, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [84/105], Loss: 3.611, Perp: 36.99, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [85/105], Loss: 3.611, Perp: 36.99, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [86/105], Loss: 3.611, Perp: 36.99, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [87/105], Loss: 3.611, Perp: 36.99, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [88/105], Loss: 3.610, Perp: 36.98, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [89/105], Loss: 3.610, Perp: 36.98, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [90/105], Loss: 3.610, Perp: 36.98, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [91/105], Loss: 3.610, Perp: 36.98, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [92/105], Loss: 3.610, Perp: 36.98, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [93/105], Loss: 3.610, Perp: 36.98, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [94/105], Loss: 3.610, Perp: 36.97, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [95/105], Loss: 3.610, Perp: 36.97, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [96/105], Loss: 3.610, Perp: 36.97, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [97/105], Loss: 3.610, Perp: 36.97, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [98/105], Loss: 3.610, Perp: 36.97, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [99/105], Loss: 3.610, Perp: 36.97, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [100/105], Loss: 3.610, Perp: 36.96, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [101/105], Loss: 3.610, Perp: 36.96, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [102/105], Loss: 3.610, Perp: 36.96, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [103/105], Loss: 3.610, Perp: 36.96, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [104/105], Loss: 3.610, Perp: 36.96, Acc: 0.33           here\n",
      "here\n",
      "Training: Epoch [19/40], Step [105/105], Loss: 3.610, Perp: 36.95, Acc: 0.33           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [1/26], Loss: 3.397, Perp: 29.86, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [2/26], Loss: 3.391, Perp: 29.70, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [3/26], Loss: 3.387, Perp: 29.59, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [4/26], Loss: 3.385, Perp: 29.51, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [5/26], Loss: 3.383, Perp: 29.45, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [6/26], Loss: 3.381, Perp: 29.40, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [7/26], Loss: 3.380, Perp: 29.36, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [8/26], Loss: 3.378, Perp: 29.32, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [9/26], Loss: 3.377, Perp: 29.30, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [10/26], Loss: 3.377, Perp: 29.27, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [11/26], Loss: 3.376, Perp: 29.25, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [12/26], Loss: 3.375, Perp: 29.23, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [13/26], Loss: 3.374, Perp: 29.20, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [14/26], Loss: 3.373, Perp: 29.18, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [15/26], Loss: 3.373, Perp: 29.16, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [16/26], Loss: 3.372, Perp: 29.14, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [17/26], Loss: 3.372, Perp: 29.13, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [18/26], Loss: 3.371, Perp: 29.11, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [19/26], Loss: 3.370, Perp: 29.09, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [20/26], Loss: 3.370, Perp: 29.08, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [21/26], Loss: 3.370, Perp: 29.07, Acc: 0.38           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [19/40], Step [22/26], Loss: 3.369, Perp: 29.05, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [23/26], Loss: 3.369, Perp: 29.04, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [24/26], Loss: 3.368, Perp: 29.03, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [25/26], Loss: 3.368, Perp: 29.02, Acc: 0.38           here\n",
      "here\n",
      "Validation: Epoch [19/40], Step [26/26], Loss: 3.367, Perp: 29.00, Acc: 0.38           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [1/105], Loss: 3.515, Perp: 33.62, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [2/105], Loss: 3.513, Perp: 33.55, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [3/105], Loss: 3.512, Perp: 33.51, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [4/105], Loss: 3.511, Perp: 33.49, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [5/105], Loss: 3.510, Perp: 33.46, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [6/105], Loss: 3.510, Perp: 33.45, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [7/105], Loss: 3.509, Perp: 33.43, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [8/105], Loss: 3.509, Perp: 33.42, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [9/105], Loss: 3.509, Perp: 33.41, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [10/105], Loss: 3.508, Perp: 33.39, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [11/105], Loss: 3.508, Perp: 33.38, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [12/105], Loss: 3.508, Perp: 33.38, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [13/105], Loss: 3.508, Perp: 33.37, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [14/105], Loss: 3.508, Perp: 33.37, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [15/105], Loss: 3.507, Perp: 33.36, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [16/105], Loss: 3.507, Perp: 33.35, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [17/105], Loss: 3.507, Perp: 33.34, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [18/105], Loss: 3.507, Perp: 33.34, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [19/105], Loss: 3.507, Perp: 33.33, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [20/105], Loss: 3.506, Perp: 33.33, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [21/105], Loss: 3.506, Perp: 33.32, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [22/105], Loss: 3.506, Perp: 33.32, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [23/105], Loss: 3.506, Perp: 33.31, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [24/105], Loss: 3.506, Perp: 33.30, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [25/105], Loss: 3.506, Perp: 33.30, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [26/105], Loss: 3.505, Perp: 33.30, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [27/105], Loss: 3.505, Perp: 33.29, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [28/105], Loss: 3.505, Perp: 33.28, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [29/105], Loss: 3.505, Perp: 33.28, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [30/105], Loss: 3.505, Perp: 33.28, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [31/105], Loss: 3.505, Perp: 33.27, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [32/105], Loss: 3.505, Perp: 33.27, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [33/105], Loss: 3.504, Perp: 33.26, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [34/105], Loss: 3.504, Perp: 33.26, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [35/105], Loss: 3.504, Perp: 33.25, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [36/105], Loss: 3.504, Perp: 33.25, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [37/105], Loss: 3.504, Perp: 33.25, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [38/105], Loss: 3.504, Perp: 33.24, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [39/105], Loss: 3.504, Perp: 33.24, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [40/105], Loss: 3.504, Perp: 33.24, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [41/105], Loss: 3.504, Perp: 33.23, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [42/105], Loss: 3.503, Perp: 33.23, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [43/105], Loss: 3.503, Perp: 33.23, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [44/105], Loss: 3.503, Perp: 33.23, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [45/105], Loss: 3.503, Perp: 33.22, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [46/105], Loss: 3.503, Perp: 33.22, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [47/105], Loss: 3.503, Perp: 33.22, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [48/105], Loss: 3.503, Perp: 33.21, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [49/105], Loss: 3.503, Perp: 33.21, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [50/105], Loss: 3.503, Perp: 33.21, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [51/105], Loss: 3.503, Perp: 33.21, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [52/105], Loss: 3.503, Perp: 33.21, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [53/105], Loss: 3.503, Perp: 33.20, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [54/105], Loss: 3.503, Perp: 33.20, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [55/105], Loss: 3.503, Perp: 33.20, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [56/105], Loss: 3.502, Perp: 33.20, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [57/105], Loss: 3.502, Perp: 33.19, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [58/105], Loss: 3.502, Perp: 33.19, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [59/105], Loss: 3.502, Perp: 33.19, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [60/105], Loss: 3.502, Perp: 33.18, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [61/105], Loss: 3.502, Perp: 33.18, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [62/105], Loss: 3.502, Perp: 33.18, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [63/105], Loss: 3.502, Perp: 33.18, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [64/105], Loss: 3.502, Perp: 33.18, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [65/105], Loss: 3.502, Perp: 33.17, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [66/105], Loss: 3.502, Perp: 33.17, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [67/105], Loss: 3.502, Perp: 33.17, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [68/105], Loss: 3.502, Perp: 33.17, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [69/105], Loss: 3.502, Perp: 33.17, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [70/105], Loss: 3.501, Perp: 33.16, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [71/105], Loss: 3.501, Perp: 33.16, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [72/105], Loss: 3.501, Perp: 33.16, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [73/105], Loss: 3.501, Perp: 33.16, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [74/105], Loss: 3.501, Perp: 33.16, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [75/105], Loss: 3.501, Perp: 33.15, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [76/105], Loss: 3.501, Perp: 33.15, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [77/105], Loss: 3.501, Perp: 33.15, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [78/105], Loss: 3.501, Perp: 33.15, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [79/105], Loss: 3.501, Perp: 33.15, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [80/105], Loss: 3.501, Perp: 33.14, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [81/105], Loss: 3.501, Perp: 33.14, Acc: 0.35           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [20/40], Step [82/105], Loss: 3.501, Perp: 33.14, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [83/105], Loss: 3.501, Perp: 33.14, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [84/105], Loss: 3.501, Perp: 33.14, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [85/105], Loss: 3.501, Perp: 33.14, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [86/105], Loss: 3.501, Perp: 33.14, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [87/105], Loss: 3.501, Perp: 33.13, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [88/105], Loss: 3.501, Perp: 33.13, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [89/105], Loss: 3.500, Perp: 33.13, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [90/105], Loss: 3.500, Perp: 33.13, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [91/105], Loss: 3.500, Perp: 33.13, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [92/105], Loss: 3.500, Perp: 33.13, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [93/105], Loss: 3.500, Perp: 33.12, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [94/105], Loss: 3.500, Perp: 33.12, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [95/105], Loss: 3.500, Perp: 33.12, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [96/105], Loss: 3.500, Perp: 33.12, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [97/105], Loss: 3.500, Perp: 33.12, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [98/105], Loss: 3.500, Perp: 33.12, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [99/105], Loss: 3.500, Perp: 33.12, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [100/105], Loss: 3.500, Perp: 33.11, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [101/105], Loss: 3.500, Perp: 33.11, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [102/105], Loss: 3.500, Perp: 33.11, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [103/105], Loss: 3.500, Perp: 33.11, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [104/105], Loss: 3.500, Perp: 33.11, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [20/40], Step [105/105], Loss: 3.500, Perp: 33.11, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [1/26], Loss: 3.164, Perp: 23.67, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [2/26], Loss: 3.160, Perp: 23.58, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [3/26], Loss: 3.158, Perp: 23.52, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [4/26], Loss: 3.156, Perp: 23.47, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [5/26], Loss: 3.154, Perp: 23.43, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [6/26], Loss: 3.153, Perp: 23.40, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [7/26], Loss: 3.152, Perp: 23.38, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [8/26], Loss: 3.151, Perp: 23.35, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [9/26], Loss: 3.150, Perp: 23.34, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [10/26], Loss: 3.149, Perp: 23.32, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [11/26], Loss: 3.149, Perp: 23.31, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [12/26], Loss: 3.148, Perp: 23.29, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [13/26], Loss: 3.147, Perp: 23.27, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [14/26], Loss: 3.147, Perp: 23.26, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [15/26], Loss: 3.146, Perp: 23.24, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [16/26], Loss: 3.145, Perp: 23.23, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [17/26], Loss: 3.145, Perp: 23.22, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [18/26], Loss: 3.144, Perp: 23.21, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [19/26], Loss: 3.144, Perp: 23.19, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [20/26], Loss: 3.144, Perp: 23.19, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [21/26], Loss: 3.143, Perp: 23.18, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [22/26], Loss: 3.143, Perp: 23.17, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [23/26], Loss: 3.142, Perp: 23.16, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [24/26], Loss: 3.142, Perp: 23.15, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [25/26], Loss: 3.142, Perp: 23.14, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [20/40], Step [26/26], Loss: 3.141, Perp: 23.13, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [1/105], Loss: 3.449, Perp: 31.47, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [2/105], Loss: 3.446, Perp: 31.37, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [3/105], Loss: 3.444, Perp: 31.32, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [4/105], Loss: 3.443, Perp: 31.29, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [5/105], Loss: 3.442, Perp: 31.26, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [6/105], Loss: 3.441, Perp: 31.23, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [7/105], Loss: 3.441, Perp: 31.21, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [8/105], Loss: 3.440, Perp: 31.19, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [9/105], Loss: 3.440, Perp: 31.17, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [10/105], Loss: 3.439, Perp: 31.16, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [11/105], Loss: 3.439, Perp: 31.14, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [12/105], Loss: 3.438, Perp: 31.13, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [13/105], Loss: 3.438, Perp: 31.12, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [14/105], Loss: 3.438, Perp: 31.12, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [15/105], Loss: 3.437, Perp: 31.10, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [16/105], Loss: 3.437, Perp: 31.09, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [17/105], Loss: 3.437, Perp: 31.08, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [18/105], Loss: 3.436, Perp: 31.08, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [19/105], Loss: 3.436, Perp: 31.07, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [20/105], Loss: 3.436, Perp: 31.06, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [21/105], Loss: 3.436, Perp: 31.06, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [22/105], Loss: 3.436, Perp: 31.05, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [23/105], Loss: 3.435, Perp: 31.05, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [24/105], Loss: 3.435, Perp: 31.04, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [25/105], Loss: 3.435, Perp: 31.03, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [26/105], Loss: 3.435, Perp: 31.03, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [27/105], Loss: 3.435, Perp: 31.02, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [28/105], Loss: 3.434, Perp: 31.01, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [29/105], Loss: 3.434, Perp: 31.01, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [30/105], Loss: 3.434, Perp: 31.00, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [31/105], Loss: 3.434, Perp: 31.00, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [32/105], Loss: 3.434, Perp: 30.99, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [33/105], Loss: 3.434, Perp: 30.99, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [34/105], Loss: 3.433, Perp: 30.98, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [35/105], Loss: 3.433, Perp: 30.98, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [36/105], Loss: 3.433, Perp: 30.97, Acc: 0.35           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [21/40], Step [37/105], Loss: 3.433, Perp: 30.97, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [38/105], Loss: 3.433, Perp: 30.97, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [39/105], Loss: 3.433, Perp: 30.96, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [40/105], Loss: 3.433, Perp: 30.96, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [41/105], Loss: 3.433, Perp: 30.96, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [42/105], Loss: 3.432, Perp: 30.95, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [43/105], Loss: 3.432, Perp: 30.95, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [44/105], Loss: 3.432, Perp: 30.94, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [45/105], Loss: 3.432, Perp: 30.94, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [46/105], Loss: 3.432, Perp: 30.94, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [47/105], Loss: 3.432, Perp: 30.93, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [48/105], Loss: 3.432, Perp: 30.93, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [49/105], Loss: 3.432, Perp: 30.93, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [50/105], Loss: 3.432, Perp: 30.93, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [51/105], Loss: 3.432, Perp: 30.92, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [52/105], Loss: 3.431, Perp: 30.92, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [53/105], Loss: 3.431, Perp: 30.92, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [54/105], Loss: 3.431, Perp: 30.91, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [55/105], Loss: 3.431, Perp: 30.91, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [56/105], Loss: 3.431, Perp: 30.91, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [57/105], Loss: 3.431, Perp: 30.91, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [58/105], Loss: 3.431, Perp: 30.90, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [59/105], Loss: 3.431, Perp: 30.90, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [60/105], Loss: 3.431, Perp: 30.90, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [61/105], Loss: 3.431, Perp: 30.89, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [62/105], Loss: 3.430, Perp: 30.89, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [63/105], Loss: 3.430, Perp: 30.89, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [64/105], Loss: 3.430, Perp: 30.89, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [65/105], Loss: 3.430, Perp: 30.88, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [66/105], Loss: 3.430, Perp: 30.88, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [67/105], Loss: 3.430, Perp: 30.88, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [68/105], Loss: 3.430, Perp: 30.88, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [69/105], Loss: 3.430, Perp: 30.87, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [70/105], Loss: 3.430, Perp: 30.87, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [71/105], Loss: 3.430, Perp: 30.87, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [72/105], Loss: 3.430, Perp: 30.87, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [73/105], Loss: 3.430, Perp: 30.86, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [74/105], Loss: 3.430, Perp: 30.86, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [75/105], Loss: 3.429, Perp: 30.86, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [76/105], Loss: 3.429, Perp: 30.86, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [77/105], Loss: 3.429, Perp: 30.86, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [78/105], Loss: 3.429, Perp: 30.85, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [79/105], Loss: 3.429, Perp: 30.85, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [80/105], Loss: 3.429, Perp: 30.85, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [81/105], Loss: 3.429, Perp: 30.85, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [82/105], Loss: 3.429, Perp: 30.85, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [83/105], Loss: 3.429, Perp: 30.84, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [84/105], Loss: 3.429, Perp: 30.84, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [85/105], Loss: 3.429, Perp: 30.84, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [86/105], Loss: 3.429, Perp: 30.84, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [87/105], Loss: 3.429, Perp: 30.84, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [88/105], Loss: 3.429, Perp: 30.83, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [89/105], Loss: 3.429, Perp: 30.83, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [90/105], Loss: 3.428, Perp: 30.83, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [91/105], Loss: 3.428, Perp: 30.83, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [92/105], Loss: 3.428, Perp: 30.83, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [93/105], Loss: 3.428, Perp: 30.82, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [94/105], Loss: 3.428, Perp: 30.82, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [95/105], Loss: 3.428, Perp: 30.82, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [96/105], Loss: 3.428, Perp: 30.82, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [97/105], Loss: 3.428, Perp: 30.82, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [98/105], Loss: 3.428, Perp: 30.82, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [99/105], Loss: 3.428, Perp: 30.81, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [100/105], Loss: 3.428, Perp: 30.81, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [101/105], Loss: 3.428, Perp: 30.81, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [102/105], Loss: 3.428, Perp: 30.81, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [103/105], Loss: 3.428, Perp: 30.80, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [104/105], Loss: 3.428, Perp: 30.80, Acc: 0.35           here\n",
      "here\n",
      "Training: Epoch [21/40], Step [105/105], Loss: 3.428, Perp: 30.80, Acc: 0.35           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [1/26], Loss: 3.020, Perp: 20.50, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [2/26], Loss: 3.016, Perp: 20.41, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [3/26], Loss: 3.014, Perp: 20.36, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [4/26], Loss: 3.012, Perp: 20.32, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [5/26], Loss: 3.010, Perp: 20.29, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [6/26], Loss: 3.009, Perp: 20.27, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [7/26], Loss: 3.008, Perp: 20.24, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [8/26], Loss: 3.007, Perp: 20.23, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [9/26], Loss: 3.006, Perp: 20.21, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [10/26], Loss: 3.006, Perp: 20.20, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [11/26], Loss: 3.005, Perp: 20.19, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [12/26], Loss: 3.004, Perp: 20.17, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [13/26], Loss: 3.003, Perp: 20.15, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [14/26], Loss: 3.003, Perp: 20.14, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [15/26], Loss: 3.002, Perp: 20.13, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [16/26], Loss: 3.002, Perp: 20.12, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [17/26], Loss: 3.001, Perp: 20.11, Acc: 0.42           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [21/40], Step [18/26], Loss: 3.001, Perp: 20.10, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [19/26], Loss: 3.000, Perp: 20.09, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [20/26], Loss: 3.000, Perp: 20.08, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [21/26], Loss: 2.999, Perp: 20.07, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [22/26], Loss: 2.999, Perp: 20.06, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [23/26], Loss: 2.998, Perp: 20.05, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [24/26], Loss: 2.998, Perp: 20.05, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [25/26], Loss: 2.998, Perp: 20.04, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [21/40], Step [26/26], Loss: 2.997, Perp: 20.03, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [1/105], Loss: 3.288, Perp: 26.78, Acc: 0.36           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [2/105], Loss: 3.285, Perp: 26.72, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [3/105], Loss: 3.284, Perp: 26.68, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [4/105], Loss: 3.283, Perp: 26.67, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [5/105], Loss: 3.283, Perp: 26.65, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [6/105], Loss: 3.282, Perp: 26.63, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [7/105], Loss: 3.281, Perp: 26.61, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [8/105], Loss: 3.281, Perp: 26.60, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [9/105], Loss: 3.280, Perp: 26.59, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [10/105], Loss: 3.280, Perp: 26.58, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [11/105], Loss: 3.280, Perp: 26.57, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [12/105], Loss: 3.279, Perp: 26.56, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [13/105], Loss: 3.279, Perp: 26.55, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [14/105], Loss: 3.279, Perp: 26.55, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [15/105], Loss: 3.279, Perp: 26.54, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [16/105], Loss: 3.278, Perp: 26.53, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [17/105], Loss: 3.278, Perp: 26.52, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [18/105], Loss: 3.278, Perp: 26.52, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [19/105], Loss: 3.278, Perp: 26.51, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [20/105], Loss: 3.277, Perp: 26.51, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [21/105], Loss: 3.277, Perp: 26.50, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [22/105], Loss: 3.277, Perp: 26.50, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [23/105], Loss: 3.277, Perp: 26.49, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [24/105], Loss: 3.277, Perp: 26.49, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [25/105], Loss: 3.277, Perp: 26.49, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [26/105], Loss: 3.276, Perp: 26.48, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [27/105], Loss: 3.276, Perp: 26.48, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [28/105], Loss: 3.276, Perp: 26.47, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [29/105], Loss: 3.276, Perp: 26.47, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [30/105], Loss: 3.276, Perp: 26.46, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [31/105], Loss: 3.276, Perp: 26.46, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [32/105], Loss: 3.275, Perp: 26.45, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [33/105], Loss: 3.275, Perp: 26.45, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [34/105], Loss: 3.275, Perp: 26.45, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [35/105], Loss: 3.275, Perp: 26.44, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [36/105], Loss: 3.275, Perp: 26.44, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [37/105], Loss: 3.275, Perp: 26.44, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [38/105], Loss: 3.275, Perp: 26.43, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [39/105], Loss: 3.275, Perp: 26.43, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [40/105], Loss: 3.274, Perp: 26.43, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [41/105], Loss: 3.274, Perp: 26.42, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [42/105], Loss: 3.274, Perp: 26.42, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [43/105], Loss: 3.274, Perp: 26.42, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [44/105], Loss: 3.274, Perp: 26.42, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [45/105], Loss: 3.274, Perp: 26.41, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [46/105], Loss: 3.274, Perp: 26.41, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [47/105], Loss: 3.274, Perp: 26.41, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [48/105], Loss: 3.274, Perp: 26.40, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [49/105], Loss: 3.274, Perp: 26.40, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [50/105], Loss: 3.273, Perp: 26.40, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [51/105], Loss: 3.273, Perp: 26.40, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [52/105], Loss: 3.273, Perp: 26.40, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [53/105], Loss: 3.273, Perp: 26.40, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [54/105], Loss: 3.273, Perp: 26.40, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [55/105], Loss: 3.273, Perp: 26.39, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [56/105], Loss: 3.273, Perp: 26.39, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [57/105], Loss: 3.273, Perp: 26.39, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [58/105], Loss: 3.273, Perp: 26.39, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [59/105], Loss: 3.273, Perp: 26.38, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [60/105], Loss: 3.273, Perp: 26.38, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [61/105], Loss: 3.273, Perp: 26.38, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [62/105], Loss: 3.273, Perp: 26.38, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [63/105], Loss: 3.273, Perp: 26.38, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [64/105], Loss: 3.272, Perp: 26.38, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [65/105], Loss: 3.272, Perp: 26.37, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [66/105], Loss: 3.272, Perp: 26.37, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [67/105], Loss: 3.272, Perp: 26.37, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [68/105], Loss: 3.272, Perp: 26.37, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [69/105], Loss: 3.272, Perp: 26.37, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [70/105], Loss: 3.272, Perp: 26.37, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [71/105], Loss: 3.272, Perp: 26.36, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [72/105], Loss: 3.272, Perp: 26.36, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [73/105], Loss: 3.272, Perp: 26.36, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [74/105], Loss: 3.272, Perp: 26.36, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [75/105], Loss: 3.272, Perp: 26.36, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [76/105], Loss: 3.272, Perp: 26.36, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [77/105], Loss: 3.272, Perp: 26.35, Acc: 0.37           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [22/40], Step [78/105], Loss: 3.272, Perp: 26.35, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [79/105], Loss: 3.271, Perp: 26.35, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [80/105], Loss: 3.271, Perp: 26.35, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [81/105], Loss: 3.271, Perp: 26.35, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [82/105], Loss: 3.271, Perp: 26.34, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [83/105], Loss: 3.271, Perp: 26.34, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [84/105], Loss: 3.271, Perp: 26.34, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [85/105], Loss: 3.271, Perp: 26.34, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [86/105], Loss: 3.271, Perp: 26.34, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [87/105], Loss: 3.271, Perp: 26.34, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [88/105], Loss: 3.271, Perp: 26.34, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [89/105], Loss: 3.271, Perp: 26.33, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [90/105], Loss: 3.271, Perp: 26.33, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [91/105], Loss: 3.271, Perp: 26.33, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [92/105], Loss: 3.271, Perp: 26.33, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [93/105], Loss: 3.271, Perp: 26.33, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [94/105], Loss: 3.271, Perp: 26.33, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [95/105], Loss: 3.271, Perp: 26.33, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [96/105], Loss: 3.271, Perp: 26.33, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [97/105], Loss: 3.271, Perp: 26.32, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [98/105], Loss: 3.270, Perp: 26.32, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [99/105], Loss: 3.270, Perp: 26.32, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [100/105], Loss: 3.270, Perp: 26.32, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [101/105], Loss: 3.270, Perp: 26.32, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [102/105], Loss: 3.270, Perp: 26.32, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [103/105], Loss: 3.270, Perp: 26.32, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [104/105], Loss: 3.270, Perp: 26.31, Acc: 0.37           here\n",
      "here\n",
      "Training: Epoch [22/40], Step [105/105], Loss: 3.270, Perp: 26.31, Acc: 0.37           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [1/26], Loss: 2.881, Perp: 17.83, Acc: 0.44           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [2/26], Loss: 2.877, Perp: 17.76, Acc: 0.44           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [3/26], Loss: 2.875, Perp: 17.72, Acc: 0.44           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [4/26], Loss: 2.873, Perp: 17.68, Acc: 0.44           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [5/26], Loss: 2.871, Perp: 17.66, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [6/26], Loss: 2.870, Perp: 17.64, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [7/26], Loss: 2.869, Perp: 17.62, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [8/26], Loss: 2.868, Perp: 17.60, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [9/26], Loss: 2.867, Perp: 17.59, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [10/26], Loss: 2.867, Perp: 17.58, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [11/26], Loss: 2.866, Perp: 17.57, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [12/26], Loss: 2.866, Perp: 17.56, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [13/26], Loss: 2.865, Perp: 17.54, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [14/26], Loss: 2.864, Perp: 17.53, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [15/26], Loss: 2.863, Perp: 17.52, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [16/26], Loss: 2.863, Perp: 17.51, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [17/26], Loss: 2.863, Perp: 17.51, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [18/26], Loss: 2.862, Perp: 17.50, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [19/26], Loss: 2.862, Perp: 17.49, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [20/26], Loss: 2.861, Perp: 17.48, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [21/26], Loss: 2.861, Perp: 17.48, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [22/26], Loss: 2.860, Perp: 17.47, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [23/26], Loss: 2.860, Perp: 17.46, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [24/26], Loss: 2.860, Perp: 17.45, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [25/26], Loss: 2.859, Perp: 17.45, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [22/40], Step [26/26], Loss: 2.859, Perp: 17.44, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [1/105], Loss: 3.071, Perp: 21.56, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [2/105], Loss: 3.069, Perp: 21.52, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [3/105], Loss: 3.069, Perp: 21.51, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [4/105], Loss: 3.069, Perp: 21.51, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [5/105], Loss: 3.068, Perp: 21.51, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [6/105], Loss: 3.068, Perp: 21.50, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [7/105], Loss: 3.068, Perp: 21.50, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [8/105], Loss: 3.068, Perp: 21.49, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [9/105], Loss: 3.068, Perp: 21.49, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [10/105], Loss: 3.067, Perp: 21.48, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [11/105], Loss: 3.067, Perp: 21.48, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [12/105], Loss: 3.067, Perp: 21.48, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [13/105], Loss: 3.067, Perp: 21.47, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [14/105], Loss: 3.067, Perp: 21.47, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [15/105], Loss: 3.066, Perp: 21.47, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [16/105], Loss: 3.066, Perp: 21.46, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [17/105], Loss: 3.066, Perp: 21.46, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [18/105], Loss: 3.066, Perp: 21.46, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [19/105], Loss: 3.066, Perp: 21.45, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [20/105], Loss: 3.066, Perp: 21.45, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [21/105], Loss: 3.066, Perp: 21.45, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [22/105], Loss: 3.065, Perp: 21.44, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [23/105], Loss: 3.065, Perp: 21.44, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [24/105], Loss: 3.065, Perp: 21.44, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [25/105], Loss: 3.065, Perp: 21.44, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [26/105], Loss: 3.065, Perp: 21.44, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [27/105], Loss: 3.065, Perp: 21.43, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [28/105], Loss: 3.065, Perp: 21.43, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [29/105], Loss: 3.065, Perp: 21.43, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [30/105], Loss: 3.065, Perp: 21.43, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [31/105], Loss: 3.064, Perp: 21.42, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [32/105], Loss: 3.064, Perp: 21.42, Acc: 0.39           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [23/40], Step [33/105], Loss: 3.064, Perp: 21.42, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [34/105], Loss: 3.064, Perp: 21.42, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [35/105], Loss: 3.064, Perp: 21.41, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [36/105], Loss: 3.064, Perp: 21.41, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [37/105], Loss: 3.064, Perp: 21.41, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [38/105], Loss: 3.064, Perp: 21.41, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [39/105], Loss: 3.064, Perp: 21.41, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [40/105], Loss: 3.064, Perp: 21.41, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [41/105], Loss: 3.064, Perp: 21.41, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [42/105], Loss: 3.064, Perp: 21.40, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [43/105], Loss: 3.063, Perp: 21.40, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [44/105], Loss: 3.063, Perp: 21.40, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [45/105], Loss: 3.063, Perp: 21.40, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [46/105], Loss: 3.063, Perp: 21.40, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [47/105], Loss: 3.063, Perp: 21.40, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [48/105], Loss: 3.063, Perp: 21.40, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [49/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [50/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [51/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [52/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [53/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [54/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [55/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [56/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [57/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [58/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [59/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [60/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [61/105], Loss: 3.063, Perp: 21.39, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [62/105], Loss: 3.063, Perp: 21.38, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [63/105], Loss: 3.063, Perp: 21.38, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [64/105], Loss: 3.063, Perp: 21.38, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [65/105], Loss: 3.063, Perp: 21.38, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [66/105], Loss: 3.063, Perp: 21.38, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [67/105], Loss: 3.062, Perp: 21.38, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [68/105], Loss: 3.062, Perp: 21.38, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [69/105], Loss: 3.062, Perp: 21.38, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [70/105], Loss: 3.062, Perp: 21.38, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [71/105], Loss: 3.062, Perp: 21.38, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [72/105], Loss: 3.062, Perp: 21.37, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [73/105], Loss: 3.062, Perp: 21.37, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [74/105], Loss: 3.062, Perp: 21.37, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [75/105], Loss: 3.062, Perp: 21.37, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [76/105], Loss: 3.062, Perp: 21.37, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [77/105], Loss: 3.062, Perp: 21.37, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [78/105], Loss: 3.062, Perp: 21.37, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [79/105], Loss: 3.062, Perp: 21.37, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [80/105], Loss: 3.062, Perp: 21.37, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [81/105], Loss: 3.062, Perp: 21.37, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [82/105], Loss: 3.062, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [83/105], Loss: 3.062, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [84/105], Loss: 3.062, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [85/105], Loss: 3.062, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [86/105], Loss: 3.062, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [87/105], Loss: 3.062, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [88/105], Loss: 3.062, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [89/105], Loss: 3.061, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [90/105], Loss: 3.061, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [91/105], Loss: 3.061, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [92/105], Loss: 3.061, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [93/105], Loss: 3.061, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [94/105], Loss: 3.061, Perp: 21.36, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [95/105], Loss: 3.061, Perp: 21.35, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [96/105], Loss: 3.061, Perp: 21.35, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [97/105], Loss: 3.061, Perp: 21.35, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [98/105], Loss: 3.061, Perp: 21.35, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [99/105], Loss: 3.061, Perp: 21.35, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [100/105], Loss: 3.061, Perp: 21.35, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [101/105], Loss: 3.061, Perp: 21.35, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [102/105], Loss: 3.061, Perp: 21.35, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [103/105], Loss: 3.061, Perp: 21.35, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [104/105], Loss: 3.061, Perp: 21.35, Acc: 0.39           here\n",
      "here\n",
      "Training: Epoch [23/40], Step [105/105], Loss: 3.061, Perp: 21.35, Acc: 0.39           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [1/26], Loss: 2.712, Perp: 15.06, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [2/26], Loss: 2.708, Perp: 15.00, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [3/26], Loss: 2.705, Perp: 14.96, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [4/26], Loss: 2.704, Perp: 14.93, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [5/26], Loss: 2.702, Perp: 14.91, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [6/26], Loss: 2.701, Perp: 14.89, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [7/26], Loss: 2.700, Perp: 14.88, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [8/26], Loss: 2.699, Perp: 14.87, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [9/26], Loss: 2.699, Perp: 14.86, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [10/26], Loss: 2.698, Perp: 14.85, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [11/26], Loss: 2.697, Perp: 14.84, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [12/26], Loss: 2.697, Perp: 14.83, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [13/26], Loss: 2.696, Perp: 14.82, Acc: 0.47           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [23/40], Step [14/26], Loss: 2.695, Perp: 14.81, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [15/26], Loss: 2.695, Perp: 14.80, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [16/26], Loss: 2.694, Perp: 14.80, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [17/26], Loss: 2.694, Perp: 14.79, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [18/26], Loss: 2.693, Perp: 14.78, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [19/26], Loss: 2.693, Perp: 14.78, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [20/26], Loss: 2.693, Perp: 14.77, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [21/26], Loss: 2.692, Perp: 14.76, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [22/26], Loss: 2.692, Perp: 14.76, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [23/26], Loss: 2.692, Perp: 14.75, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [24/26], Loss: 2.691, Perp: 14.75, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [25/26], Loss: 2.691, Perp: 14.74, Acc: 0.47           here\n",
      "here\n",
      "Validation: Epoch [23/40], Step [26/26], Loss: 2.690, Perp: 14.74, Acc: 0.47           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [1/105], Loss: 3.006, Perp: 20.20, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [2/105], Loss: 3.005, Perp: 20.18, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [3/105], Loss: 3.004, Perp: 20.16, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [4/105], Loss: 3.003, Perp: 20.15, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [5/105], Loss: 3.003, Perp: 20.14, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [6/105], Loss: 3.002, Perp: 20.13, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [7/105], Loss: 3.002, Perp: 20.12, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [8/105], Loss: 3.002, Perp: 20.12, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [9/105], Loss: 3.001, Perp: 20.11, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [10/105], Loss: 3.001, Perp: 20.11, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [11/105], Loss: 3.001, Perp: 20.10, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [12/105], Loss: 3.001, Perp: 20.10, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [13/105], Loss: 3.000, Perp: 20.09, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [14/105], Loss: 3.000, Perp: 20.09, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [15/105], Loss: 3.000, Perp: 20.08, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [16/105], Loss: 3.000, Perp: 20.08, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [17/105], Loss: 3.000, Perp: 20.08, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [18/105], Loss: 2.999, Perp: 20.07, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [19/105], Loss: 2.999, Perp: 20.07, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [20/105], Loss: 2.999, Perp: 20.07, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [21/105], Loss: 2.999, Perp: 20.06, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [22/105], Loss: 2.999, Perp: 20.06, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [23/105], Loss: 2.999, Perp: 20.06, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [24/105], Loss: 2.998, Perp: 20.06, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [25/105], Loss: 2.998, Perp: 20.05, Acc: 0.40           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [26/105], Loss: 2.998, Perp: 20.05, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [27/105], Loss: 2.998, Perp: 20.05, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [28/105], Loss: 2.998, Perp: 20.04, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [29/105], Loss: 2.998, Perp: 20.04, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [30/105], Loss: 2.998, Perp: 20.04, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [31/105], Loss: 2.998, Perp: 20.04, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [32/105], Loss: 2.998, Perp: 20.04, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [33/105], Loss: 2.997, Perp: 20.03, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [34/105], Loss: 2.997, Perp: 20.03, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [35/105], Loss: 2.997, Perp: 20.03, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [36/105], Loss: 2.997, Perp: 20.03, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [37/105], Loss: 2.997, Perp: 20.02, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [38/105], Loss: 2.997, Perp: 20.02, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [39/105], Loss: 2.997, Perp: 20.02, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [40/105], Loss: 2.997, Perp: 20.02, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [41/105], Loss: 2.997, Perp: 20.02, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [42/105], Loss: 2.997, Perp: 20.02, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [43/105], Loss: 2.996, Perp: 20.01, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [44/105], Loss: 2.996, Perp: 20.01, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [45/105], Loss: 2.996, Perp: 20.01, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [46/105], Loss: 2.996, Perp: 20.01, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [47/105], Loss: 2.996, Perp: 20.01, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [48/105], Loss: 2.996, Perp: 20.01, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [49/105], Loss: 2.996, Perp: 20.00, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [50/105], Loss: 2.996, Perp: 20.00, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [51/105], Loss: 2.996, Perp: 20.00, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [52/105], Loss: 2.996, Perp: 20.00, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [53/105], Loss: 2.996, Perp: 20.00, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [54/105], Loss: 2.996, Perp: 20.00, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [55/105], Loss: 2.996, Perp: 20.00, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [56/105], Loss: 2.996, Perp: 20.00, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [57/105], Loss: 2.996, Perp: 20.00, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [58/105], Loss: 2.995, Perp: 19.99, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [59/105], Loss: 2.995, Perp: 19.99, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [60/105], Loss: 2.995, Perp: 19.99, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [61/105], Loss: 2.995, Perp: 19.99, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [62/105], Loss: 2.995, Perp: 19.99, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [63/105], Loss: 2.995, Perp: 19.99, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [64/105], Loss: 2.995, Perp: 19.99, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [65/105], Loss: 2.995, Perp: 19.99, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [66/105], Loss: 2.995, Perp: 19.99, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [67/105], Loss: 2.995, Perp: 19.99, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [68/105], Loss: 2.995, Perp: 19.99, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [69/105], Loss: 2.995, Perp: 19.98, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [70/105], Loss: 2.995, Perp: 19.98, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [71/105], Loss: 2.995, Perp: 19.98, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [72/105], Loss: 2.995, Perp: 19.98, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [73/105], Loss: 2.995, Perp: 19.98, Acc: 0.41           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [24/40], Step [74/105], Loss: 2.995, Perp: 19.98, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [75/105], Loss: 2.995, Perp: 19.98, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [76/105], Loss: 2.994, Perp: 19.97, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [77/105], Loss: 2.994, Perp: 19.97, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [78/105], Loss: 2.994, Perp: 19.97, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [79/105], Loss: 2.994, Perp: 19.97, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [80/105], Loss: 2.994, Perp: 19.97, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [81/105], Loss: 2.994, Perp: 19.97, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [82/105], Loss: 2.994, Perp: 19.97, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [83/105], Loss: 2.994, Perp: 19.97, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [84/105], Loss: 2.994, Perp: 19.97, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [85/105], Loss: 2.994, Perp: 19.97, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [86/105], Loss: 2.994, Perp: 19.97, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [87/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [88/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [89/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [90/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [91/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [92/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [93/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [94/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [95/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [96/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [97/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [98/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [99/105], Loss: 2.994, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [100/105], Loss: 2.993, Perp: 19.96, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [101/105], Loss: 2.993, Perp: 19.95, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [102/105], Loss: 2.993, Perp: 19.95, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [103/105], Loss: 2.993, Perp: 19.95, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [104/105], Loss: 2.993, Perp: 19.95, Acc: 0.41           here\n",
      "here\n",
      "Training: Epoch [24/40], Step [105/105], Loss: 2.993, Perp: 19.95, Acc: 0.41           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [1/26], Loss: 2.612, Perp: 13.62, Acc: 0.48           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [2/26], Loss: 2.608, Perp: 13.57, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [3/26], Loss: 2.606, Perp: 13.54, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [4/26], Loss: 2.604, Perp: 13.52, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [5/26], Loss: 2.603, Perp: 13.50, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [6/26], Loss: 2.602, Perp: 13.49, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [7/26], Loss: 2.601, Perp: 13.48, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [8/26], Loss: 2.600, Perp: 13.47, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [9/26], Loss: 2.600, Perp: 13.46, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [10/26], Loss: 2.599, Perp: 13.45, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [11/26], Loss: 2.599, Perp: 13.45, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [12/26], Loss: 2.598, Perp: 13.44, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [13/26], Loss: 2.597, Perp: 13.43, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [14/26], Loss: 2.597, Perp: 13.42, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [15/26], Loss: 2.596, Perp: 13.41, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [16/26], Loss: 2.596, Perp: 13.41, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [17/26], Loss: 2.595, Perp: 13.40, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [18/26], Loss: 2.595, Perp: 13.40, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [19/26], Loss: 2.595, Perp: 13.39, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [20/26], Loss: 2.594, Perp: 13.39, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [21/26], Loss: 2.594, Perp: 13.38, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [22/26], Loss: 2.594, Perp: 13.38, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [23/26], Loss: 2.593, Perp: 13.37, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [24/26], Loss: 2.593, Perp: 13.37, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [25/26], Loss: 2.593, Perp: 13.36, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [24/40], Step [26/26], Loss: 2.592, Perp: 13.36, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [1/105], Loss: 2.868, Perp: 17.61, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [2/105], Loss: 2.867, Perp: 17.58, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [3/105], Loss: 2.867, Perp: 17.58, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [4/105], Loss: 2.866, Perp: 17.57, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [5/105], Loss: 2.866, Perp: 17.56, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [6/105], Loss: 2.866, Perp: 17.56, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [7/105], Loss: 2.865, Perp: 17.55, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [8/105], Loss: 2.865, Perp: 17.54, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [9/105], Loss: 2.865, Perp: 17.54, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [10/105], Loss: 2.864, Perp: 17.54, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [11/105], Loss: 2.864, Perp: 17.54, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [12/105], Loss: 2.864, Perp: 17.53, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [13/105], Loss: 2.864, Perp: 17.53, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [14/105], Loss: 2.864, Perp: 17.53, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [15/105], Loss: 2.864, Perp: 17.53, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [16/105], Loss: 2.864, Perp: 17.53, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [17/105], Loss: 2.864, Perp: 17.52, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [18/105], Loss: 2.863, Perp: 17.52, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [19/105], Loss: 2.863, Perp: 17.52, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [20/105], Loss: 2.863, Perp: 17.52, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [21/105], Loss: 2.863, Perp: 17.52, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [22/105], Loss: 2.863, Perp: 17.51, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [23/105], Loss: 2.863, Perp: 17.51, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [24/105], Loss: 2.863, Perp: 17.51, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [25/105], Loss: 2.863, Perp: 17.51, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [26/105], Loss: 2.863, Perp: 17.51, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [27/105], Loss: 2.863, Perp: 17.51, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [28/105], Loss: 2.862, Perp: 17.50, Acc: 0.42           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [25/40], Step [29/105], Loss: 2.862, Perp: 17.50, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [30/105], Loss: 2.862, Perp: 17.50, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [31/105], Loss: 2.862, Perp: 17.50, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [32/105], Loss: 2.862, Perp: 17.50, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [33/105], Loss: 2.862, Perp: 17.50, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [34/105], Loss: 2.862, Perp: 17.49, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [35/105], Loss: 2.862, Perp: 17.49, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [36/105], Loss: 2.862, Perp: 17.49, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [37/105], Loss: 2.862, Perp: 17.49, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [38/105], Loss: 2.862, Perp: 17.49, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [39/105], Loss: 2.862, Perp: 17.49, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [40/105], Loss: 2.861, Perp: 17.49, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [41/105], Loss: 2.861, Perp: 17.49, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [42/105], Loss: 2.861, Perp: 17.49, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [43/105], Loss: 2.861, Perp: 17.48, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [44/105], Loss: 2.861, Perp: 17.48, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [45/105], Loss: 2.861, Perp: 17.48, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [46/105], Loss: 2.861, Perp: 17.48, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [47/105], Loss: 2.861, Perp: 17.48, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [48/105], Loss: 2.861, Perp: 17.48, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [49/105], Loss: 2.861, Perp: 17.48, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [50/105], Loss: 2.861, Perp: 17.48, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [51/105], Loss: 2.861, Perp: 17.48, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [52/105], Loss: 2.861, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [53/105], Loss: 2.861, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [54/105], Loss: 2.861, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [55/105], Loss: 2.861, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [56/105], Loss: 2.861, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [57/105], Loss: 2.861, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [58/105], Loss: 2.861, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [59/105], Loss: 2.860, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [60/105], Loss: 2.860, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [61/105], Loss: 2.860, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [62/105], Loss: 2.860, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [63/105], Loss: 2.860, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [64/105], Loss: 2.860, Perp: 17.47, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [65/105], Loss: 2.860, Perp: 17.46, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [66/105], Loss: 2.860, Perp: 17.46, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [67/105], Loss: 2.860, Perp: 17.46, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [68/105], Loss: 2.860, Perp: 17.46, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [69/105], Loss: 2.860, Perp: 17.46, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [70/105], Loss: 2.860, Perp: 17.46, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [71/105], Loss: 2.860, Perp: 17.46, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [72/105], Loss: 2.860, Perp: 17.46, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [73/105], Loss: 2.860, Perp: 17.46, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [74/105], Loss: 2.860, Perp: 17.46, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [75/105], Loss: 2.860, Perp: 17.46, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [76/105], Loss: 2.860, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [77/105], Loss: 2.860, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [78/105], Loss: 2.860, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [79/105], Loss: 2.859, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [80/105], Loss: 2.859, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [81/105], Loss: 2.859, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [82/105], Loss: 2.859, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [83/105], Loss: 2.859, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [84/105], Loss: 2.859, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [85/105], Loss: 2.859, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [86/105], Loss: 2.859, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [87/105], Loss: 2.859, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [88/105], Loss: 2.859, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [89/105], Loss: 2.859, Perp: 17.45, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [90/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [91/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [92/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [93/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [94/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [95/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [96/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [97/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [98/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [99/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [100/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [101/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [102/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [103/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [104/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Training: Epoch [25/40], Step [105/105], Loss: 2.859, Perp: 17.44, Acc: 0.42           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [1/26], Loss: 2.563, Perp: 12.97, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [2/26], Loss: 2.559, Perp: 12.92, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [3/26], Loss: 2.556, Perp: 12.89, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [4/26], Loss: 2.554, Perp: 12.86, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [5/26], Loss: 2.553, Perp: 12.85, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [6/26], Loss: 2.552, Perp: 12.83, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [7/26], Loss: 2.551, Perp: 12.82, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [8/26], Loss: 2.551, Perp: 12.81, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [9/26], Loss: 2.550, Perp: 12.81, Acc: 0.50           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [25/40], Step [10/26], Loss: 2.549, Perp: 12.80, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [11/26], Loss: 2.549, Perp: 12.79, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [12/26], Loss: 2.548, Perp: 12.79, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [13/26], Loss: 2.548, Perp: 12.78, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [14/26], Loss: 2.547, Perp: 12.77, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [15/26], Loss: 2.547, Perp: 12.76, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [16/26], Loss: 2.546, Perp: 12.76, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [17/26], Loss: 2.546, Perp: 12.75, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [18/26], Loss: 2.545, Perp: 12.75, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [19/26], Loss: 2.545, Perp: 12.74, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [20/26], Loss: 2.545, Perp: 12.74, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [21/26], Loss: 2.544, Perp: 12.73, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [22/26], Loss: 2.544, Perp: 12.73, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [23/26], Loss: 2.543, Perp: 12.72, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [24/26], Loss: 2.543, Perp: 12.72, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [25/26], Loss: 2.543, Perp: 12.71, Acc: 0.50           here\n",
      "here\n",
      "Validation: Epoch [25/40], Step [26/26], Loss: 2.542, Perp: 12.71, Acc: 0.50           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [1/105], Loss: 2.730, Perp: 15.33, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [2/105], Loss: 2.728, Perp: 15.30, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [3/105], Loss: 2.728, Perp: 15.30, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [4/105], Loss: 2.728, Perp: 15.30, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [5/105], Loss: 2.728, Perp: 15.30, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [6/105], Loss: 2.728, Perp: 15.30, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [7/105], Loss: 2.727, Perp: 15.29, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [8/105], Loss: 2.727, Perp: 15.29, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [9/105], Loss: 2.727, Perp: 15.29, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [10/105], Loss: 2.727, Perp: 15.29, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [11/105], Loss: 2.727, Perp: 15.29, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [12/105], Loss: 2.727, Perp: 15.29, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [13/105], Loss: 2.727, Perp: 15.29, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [14/105], Loss: 2.727, Perp: 15.29, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [15/105], Loss: 2.727, Perp: 15.29, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [16/105], Loss: 2.727, Perp: 15.28, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [17/105], Loss: 2.727, Perp: 15.28, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [18/105], Loss: 2.727, Perp: 15.28, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [19/105], Loss: 2.727, Perp: 15.28, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [20/105], Loss: 2.727, Perp: 15.28, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [21/105], Loss: 2.726, Perp: 15.28, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [22/105], Loss: 2.726, Perp: 15.28, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [23/105], Loss: 2.726, Perp: 15.28, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [24/105], Loss: 2.726, Perp: 15.27, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [25/105], Loss: 2.726, Perp: 15.27, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [26/105], Loss: 2.726, Perp: 15.27, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [27/105], Loss: 2.726, Perp: 15.27, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [28/105], Loss: 2.726, Perp: 15.27, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [29/105], Loss: 2.726, Perp: 15.27, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [30/105], Loss: 2.726, Perp: 15.27, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [31/105], Loss: 2.726, Perp: 15.27, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [32/105], Loss: 2.726, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [33/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [34/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [35/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [36/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [37/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [38/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [39/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [40/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [41/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [42/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [43/105], Loss: 2.725, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [44/105], Loss: 2.725, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [45/105], Loss: 2.725, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [46/105], Loss: 2.725, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [47/105], Loss: 2.725, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [48/105], Loss: 2.725, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [49/105], Loss: 2.725, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [50/105], Loss: 2.725, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [51/105], Loss: 2.725, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [52/105], Loss: 2.724, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [53/105], Loss: 2.724, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [54/105], Loss: 2.724, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [55/105], Loss: 2.724, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [56/105], Loss: 2.724, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [57/105], Loss: 2.724, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [58/105], Loss: 2.724, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [59/105], Loss: 2.724, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [60/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [61/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [62/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [63/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [64/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [65/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [66/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [67/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [68/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [69/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [26/40], Step [70/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [71/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [72/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [73/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [74/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [75/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [76/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [77/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [78/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [79/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [80/105], Loss: 2.724, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [81/105], Loss: 2.724, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [82/105], Loss: 2.724, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [83/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [84/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [85/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [86/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [87/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [88/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [89/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [90/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [91/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [92/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [93/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [94/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [95/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [96/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [97/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [98/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [99/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [100/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [101/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [102/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [103/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [104/105], Loss: 2.723, Perp: 15.22, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [26/40], Step [105/105], Loss: 2.723, Perp: 15.22, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [1/26], Loss: 2.344, Perp: 10.42, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [2/26], Loss: 2.340, Perp: 10.38, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [3/26], Loss: 2.337, Perp: 10.35, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [4/26], Loss: 2.336, Perp: 10.33, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [5/26], Loss: 2.334, Perp: 10.32, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [6/26], Loss: 2.333, Perp: 10.31, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [7/26], Loss: 2.333, Perp: 10.30, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [8/26], Loss: 2.332, Perp: 10.30, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [9/26], Loss: 2.331, Perp: 10.29, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [10/26], Loss: 2.331, Perp: 10.29, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [11/26], Loss: 2.330, Perp: 10.28, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [12/26], Loss: 2.330, Perp: 10.28, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [13/26], Loss: 2.329, Perp: 10.27, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [14/26], Loss: 2.329, Perp: 10.27, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [15/26], Loss: 2.328, Perp: 10.26, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [16/26], Loss: 2.328, Perp: 10.26, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [17/26], Loss: 2.328, Perp: 10.25, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [18/26], Loss: 2.327, Perp: 10.25, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [19/26], Loss: 2.327, Perp: 10.25, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [20/26], Loss: 2.327, Perp: 10.24, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [21/26], Loss: 2.326, Perp: 10.24, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [22/26], Loss: 2.326, Perp: 10.24, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [23/26], Loss: 2.326, Perp: 10.23, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [24/26], Loss: 2.326, Perp: 10.23, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [25/26], Loss: 2.325, Perp: 10.23, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [26/40], Step [26/26], Loss: 2.325, Perp: 10.23, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [1/105], Loss: 2.721, Perp: 15.19, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [2/105], Loss: 2.719, Perp: 15.17, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [3/105], Loss: 2.718, Perp: 15.15, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [4/105], Loss: 2.718, Perp: 15.15, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [5/105], Loss: 2.717, Perp: 15.14, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [6/105], Loss: 2.717, Perp: 15.13, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [7/105], Loss: 2.716, Perp: 15.12, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [8/105], Loss: 2.716, Perp: 15.12, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [9/105], Loss: 2.715, Perp: 15.11, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [10/105], Loss: 2.715, Perp: 15.11, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [11/105], Loss: 2.715, Perp: 15.10, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [12/105], Loss: 2.715, Perp: 15.10, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [13/105], Loss: 2.714, Perp: 15.09, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [14/105], Loss: 2.714, Perp: 15.09, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [15/105], Loss: 2.714, Perp: 15.09, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [16/105], Loss: 2.714, Perp: 15.09, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [17/105], Loss: 2.714, Perp: 15.08, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [18/105], Loss: 2.713, Perp: 15.08, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [19/105], Loss: 2.713, Perp: 15.08, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [20/105], Loss: 2.713, Perp: 15.08, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [21/105], Loss: 2.713, Perp: 15.07, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [22/105], Loss: 2.713, Perp: 15.07, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [23/105], Loss: 2.713, Perp: 15.07, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [24/105], Loss: 2.713, Perp: 15.07, Acc: 0.44           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [27/40], Step [25/105], Loss: 2.713, Perp: 15.07, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [26/105], Loss: 2.712, Perp: 15.06, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [27/105], Loss: 2.712, Perp: 15.06, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [28/105], Loss: 2.712, Perp: 15.06, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [29/105], Loss: 2.712, Perp: 15.06, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [30/105], Loss: 2.712, Perp: 15.06, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [31/105], Loss: 2.712, Perp: 15.06, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [32/105], Loss: 2.712, Perp: 15.05, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [33/105], Loss: 2.711, Perp: 15.05, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [34/105], Loss: 2.711, Perp: 15.05, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [35/105], Loss: 2.711, Perp: 15.05, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [36/105], Loss: 2.711, Perp: 15.05, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [37/105], Loss: 2.711, Perp: 15.04, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [38/105], Loss: 2.711, Perp: 15.04, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [39/105], Loss: 2.711, Perp: 15.04, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [40/105], Loss: 2.711, Perp: 15.04, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [41/105], Loss: 2.711, Perp: 15.04, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [42/105], Loss: 2.711, Perp: 15.04, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [43/105], Loss: 2.711, Perp: 15.04, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [44/105], Loss: 2.710, Perp: 15.04, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [45/105], Loss: 2.710, Perp: 15.03, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [46/105], Loss: 2.710, Perp: 15.03, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [47/105], Loss: 2.710, Perp: 15.03, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [48/105], Loss: 2.710, Perp: 15.03, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [49/105], Loss: 2.710, Perp: 15.03, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [50/105], Loss: 2.710, Perp: 15.03, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [51/105], Loss: 2.710, Perp: 15.03, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [52/105], Loss: 2.710, Perp: 15.03, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [53/105], Loss: 2.710, Perp: 15.03, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [54/105], Loss: 2.710, Perp: 15.03, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [55/105], Loss: 2.710, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [56/105], Loss: 2.710, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [57/105], Loss: 2.710, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [58/105], Loss: 2.710, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [59/105], Loss: 2.709, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [60/105], Loss: 2.709, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [61/105], Loss: 2.709, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [62/105], Loss: 2.709, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [63/105], Loss: 2.709, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [64/105], Loss: 2.709, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [65/105], Loss: 2.709, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [66/105], Loss: 2.709, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [67/105], Loss: 2.709, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [68/105], Loss: 2.709, Perp: 15.02, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [69/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [70/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [71/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [72/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [73/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [74/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [75/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [76/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [77/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [78/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [79/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [80/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [81/105], Loss: 2.709, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [82/105], Loss: 2.708, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [83/105], Loss: 2.708, Perp: 15.01, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [84/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [85/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [86/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [87/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [88/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [89/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [90/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [91/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [92/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [93/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [94/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [95/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [96/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [97/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [98/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [99/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [100/105], Loss: 2.708, Perp: 15.00, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [101/105], Loss: 2.708, Perp: 14.99, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [102/105], Loss: 2.708, Perp: 14.99, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [103/105], Loss: 2.708, Perp: 14.99, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [104/105], Loss: 2.708, Perp: 14.99, Acc: 0.44           here\n",
      "here\n",
      "Training: Epoch [27/40], Step [105/105], Loss: 2.707, Perp: 14.99, Acc: 0.44           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [1/26], Loss: 2.269, Perp: 9.67, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [2/26], Loss: 2.265, Perp: 9.63, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [3/26], Loss: 2.262, Perp: 9.61, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [4/26], Loss: 2.260, Perp: 9.59, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [5/26], Loss: 2.259, Perp: 9.57, Acc: 0.55           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [27/40], Step [6/26], Loss: 2.258, Perp: 9.56, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [7/26], Loss: 2.257, Perp: 9.55, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [8/26], Loss: 2.256, Perp: 9.55, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [9/26], Loss: 2.256, Perp: 9.54, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [10/26], Loss: 2.255, Perp: 9.53, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [11/26], Loss: 2.254, Perp: 9.53, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [12/26], Loss: 2.254, Perp: 9.52, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [13/26], Loss: 2.253, Perp: 9.52, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [14/26], Loss: 2.253, Perp: 9.51, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [15/26], Loss: 2.252, Perp: 9.51, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [16/26], Loss: 2.252, Perp: 9.50, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [17/26], Loss: 2.251, Perp: 9.50, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [18/26], Loss: 2.251, Perp: 9.49, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [19/26], Loss: 2.250, Perp: 9.49, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [20/26], Loss: 2.250, Perp: 9.49, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [21/26], Loss: 2.249, Perp: 9.48, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [22/26], Loss: 2.249, Perp: 9.48, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [23/26], Loss: 2.249, Perp: 9.48, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [24/26], Loss: 2.248, Perp: 9.47, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [25/26], Loss: 2.248, Perp: 9.47, Acc: 0.55           here\n",
      "here\n",
      "Validation: Epoch [27/40], Step [26/26], Loss: 2.248, Perp: 9.47, Acc: 0.55           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [1/105], Loss: 2.605, Perp: 13.53, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [2/105], Loss: 2.604, Perp: 13.51, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [3/105], Loss: 2.603, Perp: 13.51, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [4/105], Loss: 2.603, Perp: 13.50, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [5/105], Loss: 2.602, Perp: 13.49, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [6/105], Loss: 2.602, Perp: 13.49, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [7/105], Loss: 2.601, Perp: 13.48, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [8/105], Loss: 2.601, Perp: 13.48, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [9/105], Loss: 2.601, Perp: 13.47, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [10/105], Loss: 2.601, Perp: 13.47, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [11/105], Loss: 2.600, Perp: 13.47, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [12/105], Loss: 2.600, Perp: 13.46, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [13/105], Loss: 2.600, Perp: 13.46, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [14/105], Loss: 2.600, Perp: 13.46, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [15/105], Loss: 2.600, Perp: 13.46, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [16/105], Loss: 2.599, Perp: 13.46, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [17/105], Loss: 2.599, Perp: 13.45, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [18/105], Loss: 2.599, Perp: 13.45, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [19/105], Loss: 2.599, Perp: 13.45, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [20/105], Loss: 2.599, Perp: 13.45, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [21/105], Loss: 2.599, Perp: 13.45, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [22/105], Loss: 2.598, Perp: 13.44, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [23/105], Loss: 2.598, Perp: 13.44, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [24/105], Loss: 2.598, Perp: 13.44, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [25/105], Loss: 2.598, Perp: 13.44, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [26/105], Loss: 2.598, Perp: 13.44, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [27/105], Loss: 2.598, Perp: 13.43, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [28/105], Loss: 2.598, Perp: 13.43, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [29/105], Loss: 2.598, Perp: 13.43, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [30/105], Loss: 2.598, Perp: 13.43, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [31/105], Loss: 2.597, Perp: 13.43, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [32/105], Loss: 2.597, Perp: 13.43, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [33/105], Loss: 2.597, Perp: 13.43, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [34/105], Loss: 2.597, Perp: 13.42, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [35/105], Loss: 2.597, Perp: 13.42, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [36/105], Loss: 2.597, Perp: 13.42, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [37/105], Loss: 2.597, Perp: 13.42, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [38/105], Loss: 2.597, Perp: 13.42, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [39/105], Loss: 2.597, Perp: 13.42, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [40/105], Loss: 2.597, Perp: 13.42, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [41/105], Loss: 2.597, Perp: 13.42, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [42/105], Loss: 2.596, Perp: 13.42, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [43/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [44/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [45/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [46/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [47/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [48/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [49/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [50/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [51/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [52/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [53/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [54/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [55/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [56/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [57/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [58/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [59/105], Loss: 2.596, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [60/105], Loss: 2.596, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [61/105], Loss: 2.596, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [62/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [63/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [64/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [65/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [28/40], Step [66/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [67/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [68/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [69/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [70/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [71/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [72/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [73/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [74/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [75/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [76/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [77/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [78/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [79/105], Loss: 2.595, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [80/105], Loss: 2.595, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [81/105], Loss: 2.595, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [82/105], Loss: 2.595, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [83/105], Loss: 2.595, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [84/105], Loss: 2.595, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [85/105], Loss: 2.595, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [86/105], Loss: 2.595, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [87/105], Loss: 2.595, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [88/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [89/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [90/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [91/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [92/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [93/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [94/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [95/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [96/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [97/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [98/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [99/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [100/105], Loss: 2.594, Perp: 13.38, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [101/105], Loss: 2.594, Perp: 13.38, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [102/105], Loss: 2.594, Perp: 13.38, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [103/105], Loss: 2.594, Perp: 13.38, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [104/105], Loss: 2.594, Perp: 13.38, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [28/40], Step [105/105], Loss: 2.594, Perp: 13.38, Acc: 0.46           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [1/26], Loss: 2.205, Perp: 9.07, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [2/26], Loss: 2.200, Perp: 9.02, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [3/26], Loss: 2.197, Perp: 9.00, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [4/26], Loss: 2.195, Perp: 8.98, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [5/26], Loss: 2.194, Perp: 8.97, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [6/26], Loss: 2.193, Perp: 8.96, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [7/26], Loss: 2.192, Perp: 8.95, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [8/26], Loss: 2.191, Perp: 8.94, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [9/26], Loss: 2.190, Perp: 8.94, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [10/26], Loss: 2.190, Perp: 8.93, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [11/26], Loss: 2.189, Perp: 8.93, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [12/26], Loss: 2.189, Perp: 8.92, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [13/26], Loss: 2.188, Perp: 8.92, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [14/26], Loss: 2.187, Perp: 8.91, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [15/26], Loss: 2.187, Perp: 8.91, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [16/26], Loss: 2.186, Perp: 8.90, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [17/26], Loss: 2.186, Perp: 8.90, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [18/26], Loss: 2.185, Perp: 8.90, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [19/26], Loss: 2.185, Perp: 8.89, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [20/26], Loss: 2.185, Perp: 8.89, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [21/26], Loss: 2.184, Perp: 8.88, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [22/26], Loss: 2.184, Perp: 8.88, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [23/26], Loss: 2.183, Perp: 8.88, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [24/26], Loss: 2.183, Perp: 8.87, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [25/26], Loss: 2.183, Perp: 8.87, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [28/40], Step [26/26], Loss: 2.182, Perp: 8.87, Acc: 0.57           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [1/105], Loss: 2.738, Perp: 15.45, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [2/105], Loss: 2.736, Perp: 15.42, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [3/105], Loss: 2.734, Perp: 15.40, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [4/105], Loss: 2.733, Perp: 15.38, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [5/105], Loss: 2.732, Perp: 15.37, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [6/105], Loss: 2.731, Perp: 15.35, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [7/105], Loss: 2.730, Perp: 15.33, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [8/105], Loss: 2.729, Perp: 15.32, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [9/105], Loss: 2.728, Perp: 15.31, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [10/105], Loss: 2.728, Perp: 15.30, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [11/105], Loss: 2.727, Perp: 15.29, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [12/105], Loss: 2.727, Perp: 15.28, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [13/105], Loss: 2.726, Perp: 15.28, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [14/105], Loss: 2.726, Perp: 15.27, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [15/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [16/105], Loss: 2.725, Perp: 15.26, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [17/105], Loss: 2.725, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [18/105], Loss: 2.724, Perp: 15.25, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [19/105], Loss: 2.724, Perp: 15.24, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [20/105], Loss: 2.724, Perp: 15.23, Acc: 0.45           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [29/40], Step [21/105], Loss: 2.723, Perp: 15.23, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [22/105], Loss: 2.723, Perp: 15.22, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [23/105], Loss: 2.723, Perp: 15.22, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [24/105], Loss: 2.722, Perp: 15.22, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [25/105], Loss: 2.722, Perp: 15.21, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [26/105], Loss: 2.722, Perp: 15.21, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [27/105], Loss: 2.722, Perp: 15.21, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [28/105], Loss: 2.721, Perp: 15.20, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [29/105], Loss: 2.721, Perp: 15.20, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [30/105], Loss: 2.721, Perp: 15.19, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [31/105], Loss: 2.721, Perp: 15.19, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [32/105], Loss: 2.721, Perp: 15.19, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [33/105], Loss: 2.720, Perp: 15.18, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [34/105], Loss: 2.720, Perp: 15.18, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [35/105], Loss: 2.720, Perp: 15.18, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [36/105], Loss: 2.720, Perp: 15.18, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [37/105], Loss: 2.719, Perp: 15.17, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [38/105], Loss: 2.719, Perp: 15.17, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [39/105], Loss: 2.719, Perp: 15.17, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [40/105], Loss: 2.719, Perp: 15.16, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [41/105], Loss: 2.719, Perp: 15.16, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [42/105], Loss: 2.719, Perp: 15.16, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [43/105], Loss: 2.718, Perp: 15.16, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [44/105], Loss: 2.718, Perp: 15.15, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [45/105], Loss: 2.718, Perp: 15.15, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [46/105], Loss: 2.718, Perp: 15.15, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [47/105], Loss: 2.718, Perp: 15.15, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [48/105], Loss: 2.718, Perp: 15.15, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [49/105], Loss: 2.718, Perp: 15.14, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [50/105], Loss: 2.718, Perp: 15.14, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [51/105], Loss: 2.717, Perp: 15.14, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [52/105], Loss: 2.717, Perp: 15.14, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [53/105], Loss: 2.717, Perp: 15.14, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [54/105], Loss: 2.717, Perp: 15.14, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [55/105], Loss: 2.717, Perp: 15.14, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [56/105], Loss: 2.717, Perp: 15.14, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [57/105], Loss: 2.717, Perp: 15.13, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [58/105], Loss: 2.717, Perp: 15.13, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [59/105], Loss: 2.717, Perp: 15.13, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [60/105], Loss: 2.717, Perp: 15.13, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [61/105], Loss: 2.717, Perp: 15.13, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [62/105], Loss: 2.716, Perp: 15.13, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [63/105], Loss: 2.716, Perp: 15.13, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [64/105], Loss: 2.716, Perp: 15.12, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [65/105], Loss: 2.716, Perp: 15.12, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [66/105], Loss: 2.716, Perp: 15.12, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [67/105], Loss: 2.716, Perp: 15.12, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [68/105], Loss: 2.716, Perp: 15.12, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [69/105], Loss: 2.716, Perp: 15.12, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [70/105], Loss: 2.716, Perp: 15.12, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [71/105], Loss: 2.716, Perp: 15.11, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [72/105], Loss: 2.716, Perp: 15.11, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [73/105], Loss: 2.715, Perp: 15.11, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [74/105], Loss: 2.715, Perp: 15.11, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [75/105], Loss: 2.715, Perp: 15.11, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [76/105], Loss: 2.715, Perp: 15.11, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [77/105], Loss: 2.715, Perp: 15.11, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [78/105], Loss: 2.715, Perp: 15.11, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [79/105], Loss: 2.715, Perp: 15.10, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [80/105], Loss: 2.715, Perp: 15.10, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [81/105], Loss: 2.715, Perp: 15.10, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [82/105], Loss: 2.715, Perp: 15.10, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [83/105], Loss: 2.715, Perp: 15.10, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [84/105], Loss: 2.715, Perp: 15.10, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [85/105], Loss: 2.714, Perp: 15.10, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [86/105], Loss: 2.714, Perp: 15.10, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [87/105], Loss: 2.714, Perp: 15.09, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [88/105], Loss: 2.714, Perp: 15.09, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [89/105], Loss: 2.714, Perp: 15.09, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [90/105], Loss: 2.714, Perp: 15.09, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [91/105], Loss: 2.714, Perp: 15.09, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [92/105], Loss: 2.714, Perp: 15.09, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [93/105], Loss: 2.714, Perp: 15.09, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [94/105], Loss: 2.714, Perp: 15.09, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [95/105], Loss: 2.714, Perp: 15.09, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [96/105], Loss: 2.714, Perp: 15.08, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [97/105], Loss: 2.714, Perp: 15.08, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [98/105], Loss: 2.714, Perp: 15.08, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [99/105], Loss: 2.713, Perp: 15.08, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [100/105], Loss: 2.713, Perp: 15.08, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [101/105], Loss: 2.713, Perp: 15.08, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [102/105], Loss: 2.713, Perp: 15.08, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [103/105], Loss: 2.713, Perp: 15.08, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [104/105], Loss: 2.713, Perp: 15.08, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [29/40], Step [105/105], Loss: 2.713, Perp: 15.08, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [1/26], Loss: 2.246, Perp: 9.45, Acc: 0.56           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [29/40], Step [2/26], Loss: 2.241, Perp: 9.40, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [3/26], Loss: 2.238, Perp: 9.37, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [4/26], Loss: 2.235, Perp: 9.35, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [5/26], Loss: 2.233, Perp: 9.33, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [6/26], Loss: 2.232, Perp: 9.31, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [7/26], Loss: 2.230, Perp: 9.30, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [8/26], Loss: 2.229, Perp: 9.29, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [9/26], Loss: 2.228, Perp: 9.29, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [10/26], Loss: 2.228, Perp: 9.28, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [11/26], Loss: 2.227, Perp: 9.27, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [12/26], Loss: 2.226, Perp: 9.26, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [13/26], Loss: 2.225, Perp: 9.26, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [14/26], Loss: 2.225, Perp: 9.25, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [15/26], Loss: 2.224, Perp: 9.24, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [16/26], Loss: 2.223, Perp: 9.24, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [17/26], Loss: 2.223, Perp: 9.23, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [18/26], Loss: 2.222, Perp: 9.23, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [19/26], Loss: 2.222, Perp: 9.22, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [20/26], Loss: 2.221, Perp: 9.22, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [21/26], Loss: 2.221, Perp: 9.21, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [22/26], Loss: 2.220, Perp: 9.21, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [23/26], Loss: 2.220, Perp: 9.21, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [24/26], Loss: 2.219, Perp: 9.20, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [25/26], Loss: 2.219, Perp: 9.20, Acc: 0.57           here\n",
      "here\n",
      "Validation: Epoch [29/40], Step [26/26], Loss: 2.219, Perp: 9.19, Acc: 0.57           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [1/105], Loss: 2.623, Perp: 13.78, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [2/105], Loss: 2.620, Perp: 13.74, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [3/105], Loss: 2.619, Perp: 13.72, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [4/105], Loss: 2.618, Perp: 13.70, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [5/105], Loss: 2.617, Perp: 13.69, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [6/105], Loss: 2.616, Perp: 13.68, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [7/105], Loss: 2.615, Perp: 13.67, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [8/105], Loss: 2.614, Perp: 13.66, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [9/105], Loss: 2.614, Perp: 13.65, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [10/105], Loss: 2.613, Perp: 13.64, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [11/105], Loss: 2.613, Perp: 13.63, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [12/105], Loss: 2.612, Perp: 13.63, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [13/105], Loss: 2.612, Perp: 13.62, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [14/105], Loss: 2.611, Perp: 13.62, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [15/105], Loss: 2.611, Perp: 13.61, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [16/105], Loss: 2.611, Perp: 13.61, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [17/105], Loss: 2.610, Perp: 13.60, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [18/105], Loss: 2.610, Perp: 13.60, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [19/105], Loss: 2.610, Perp: 13.59, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [20/105], Loss: 2.609, Perp: 13.59, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [21/105], Loss: 2.609, Perp: 13.59, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [22/105], Loss: 2.609, Perp: 13.58, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [23/105], Loss: 2.609, Perp: 13.58, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [24/105], Loss: 2.608, Perp: 13.58, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [25/105], Loss: 2.608, Perp: 13.57, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [26/105], Loss: 2.608, Perp: 13.57, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [27/105], Loss: 2.608, Perp: 13.57, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [28/105], Loss: 2.607, Perp: 13.56, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [29/105], Loss: 2.607, Perp: 13.56, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [30/105], Loss: 2.607, Perp: 13.56, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [31/105], Loss: 2.607, Perp: 13.56, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [32/105], Loss: 2.607, Perp: 13.55, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [33/105], Loss: 2.606, Perp: 13.55, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [34/105], Loss: 2.606, Perp: 13.55, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [35/105], Loss: 2.606, Perp: 13.55, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [36/105], Loss: 2.606, Perp: 13.54, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [37/105], Loss: 2.606, Perp: 13.54, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [38/105], Loss: 2.606, Perp: 13.54, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [39/105], Loss: 2.605, Perp: 13.54, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [40/105], Loss: 2.605, Perp: 13.54, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [41/105], Loss: 2.605, Perp: 13.53, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [42/105], Loss: 2.605, Perp: 13.53, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [43/105], Loss: 2.605, Perp: 13.53, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [44/105], Loss: 2.605, Perp: 13.53, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [45/105], Loss: 2.605, Perp: 13.53, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [46/105], Loss: 2.604, Perp: 13.52, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [47/105], Loss: 2.604, Perp: 13.52, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [48/105], Loss: 2.604, Perp: 13.52, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [49/105], Loss: 2.604, Perp: 13.52, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [50/105], Loss: 2.604, Perp: 13.52, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [51/105], Loss: 2.604, Perp: 13.52, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [52/105], Loss: 2.604, Perp: 13.52, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [53/105], Loss: 2.604, Perp: 13.51, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [54/105], Loss: 2.604, Perp: 13.51, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [55/105], Loss: 2.604, Perp: 13.51, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [56/105], Loss: 2.604, Perp: 13.51, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [57/105], Loss: 2.604, Perp: 13.51, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [58/105], Loss: 2.603, Perp: 13.51, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [59/105], Loss: 2.603, Perp: 13.51, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [60/105], Loss: 2.603, Perp: 13.51, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [61/105], Loss: 2.603, Perp: 13.51, Acc: 0.45           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [30/40], Step [62/105], Loss: 2.603, Perp: 13.51, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [63/105], Loss: 2.603, Perp: 13.51, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [64/105], Loss: 2.603, Perp: 13.51, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [65/105], Loss: 2.603, Perp: 13.50, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [66/105], Loss: 2.603, Perp: 13.50, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [67/105], Loss: 2.603, Perp: 13.50, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [68/105], Loss: 2.603, Perp: 13.50, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [69/105], Loss: 2.603, Perp: 13.50, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [70/105], Loss: 2.603, Perp: 13.50, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [71/105], Loss: 2.602, Perp: 13.50, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [72/105], Loss: 2.602, Perp: 13.50, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [73/105], Loss: 2.602, Perp: 13.50, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [74/105], Loss: 2.602, Perp: 13.49, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [75/105], Loss: 2.602, Perp: 13.49, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [76/105], Loss: 2.602, Perp: 13.49, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [77/105], Loss: 2.602, Perp: 13.49, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [78/105], Loss: 2.602, Perp: 13.49, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [79/105], Loss: 2.602, Perp: 13.49, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [80/105], Loss: 2.602, Perp: 13.49, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [81/105], Loss: 2.602, Perp: 13.49, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [82/105], Loss: 2.602, Perp: 13.49, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [83/105], Loss: 2.602, Perp: 13.48, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [84/105], Loss: 2.601, Perp: 13.48, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [85/105], Loss: 2.601, Perp: 13.48, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [86/105], Loss: 2.601, Perp: 13.48, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [87/105], Loss: 2.601, Perp: 13.48, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [88/105], Loss: 2.601, Perp: 13.48, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [89/105], Loss: 2.601, Perp: 13.48, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [90/105], Loss: 2.601, Perp: 13.48, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [91/105], Loss: 2.601, Perp: 13.48, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [92/105], Loss: 2.601, Perp: 13.48, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [93/105], Loss: 2.601, Perp: 13.48, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [94/105], Loss: 2.601, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [95/105], Loss: 2.601, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [96/105], Loss: 2.601, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [97/105], Loss: 2.601, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [98/105], Loss: 2.601, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [99/105], Loss: 2.601, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [100/105], Loss: 2.600, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [101/105], Loss: 2.600, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [102/105], Loss: 2.600, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [103/105], Loss: 2.600, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [104/105], Loss: 2.600, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Training: Epoch [30/40], Step [105/105], Loss: 2.600, Perp: 13.47, Acc: 0.45           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [1/26], Loss: 2.102, Perp: 8.18, Acc: 0.58           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [2/26], Loss: 2.096, Perp: 8.14, Acc: 0.58           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [3/26], Loss: 2.093, Perp: 8.11, Acc: 0.58           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [4/26], Loss: 2.091, Perp: 8.09, Acc: 0.58           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [5/26], Loss: 2.090, Perp: 8.08, Acc: 0.58           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [6/26], Loss: 2.088, Perp: 8.07, Acc: 0.58           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [7/26], Loss: 2.087, Perp: 8.06, Acc: 0.58           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [8/26], Loss: 2.086, Perp: 8.05, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [9/26], Loss: 2.086, Perp: 8.05, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [10/26], Loss: 2.085, Perp: 8.04, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [11/26], Loss: 2.084, Perp: 8.04, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [12/26], Loss: 2.084, Perp: 8.03, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [13/26], Loss: 2.083, Perp: 8.03, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [14/26], Loss: 2.082, Perp: 8.02, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [15/26], Loss: 2.082, Perp: 8.02, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [16/26], Loss: 2.081, Perp: 8.01, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [17/26], Loss: 2.081, Perp: 8.01, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [18/26], Loss: 2.080, Perp: 8.01, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [19/26], Loss: 2.080, Perp: 8.00, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [20/26], Loss: 2.079, Perp: 8.00, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [21/26], Loss: 2.079, Perp: 7.99, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [22/26], Loss: 2.078, Perp: 7.99, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [23/26], Loss: 2.078, Perp: 7.99, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [24/26], Loss: 2.078, Perp: 7.98, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [25/26], Loss: 2.077, Perp: 7.98, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [30/40], Step [26/26], Loss: 2.077, Perp: 7.98, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [1/105], Loss: 2.607, Perp: 13.56, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [2/105], Loss: 2.604, Perp: 13.52, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [3/105], Loss: 2.602, Perp: 13.49, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [4/105], Loss: 2.601, Perp: 13.48, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [5/105], Loss: 2.600, Perp: 13.46, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [6/105], Loss: 2.598, Perp: 13.44, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [7/105], Loss: 2.597, Perp: 13.43, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [8/105], Loss: 2.596, Perp: 13.42, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [9/105], Loss: 2.596, Perp: 13.41, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [10/105], Loss: 2.595, Perp: 13.40, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [11/105], Loss: 2.595, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [12/105], Loss: 2.594, Perp: 13.39, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [13/105], Loss: 2.594, Perp: 13.38, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [14/105], Loss: 2.593, Perp: 13.38, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [15/105], Loss: 2.593, Perp: 13.37, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [16/105], Loss: 2.593, Perp: 13.36, Acc: 0.46           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [31/40], Step [17/105], Loss: 2.592, Perp: 13.36, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [18/105], Loss: 2.592, Perp: 13.35, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [19/105], Loss: 2.592, Perp: 13.35, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [20/105], Loss: 2.591, Perp: 13.35, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [21/105], Loss: 2.591, Perp: 13.34, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [22/105], Loss: 2.591, Perp: 13.34, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [23/105], Loss: 2.590, Perp: 13.33, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [24/105], Loss: 2.590, Perp: 13.33, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [25/105], Loss: 2.590, Perp: 13.33, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [26/105], Loss: 2.590, Perp: 13.32, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [27/105], Loss: 2.589, Perp: 13.32, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [28/105], Loss: 2.589, Perp: 13.32, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [29/105], Loss: 2.589, Perp: 13.32, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [30/105], Loss: 2.589, Perp: 13.31, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [31/105], Loss: 2.589, Perp: 13.31, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [32/105], Loss: 2.588, Perp: 13.31, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [33/105], Loss: 2.588, Perp: 13.31, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [34/105], Loss: 2.588, Perp: 13.30, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [35/105], Loss: 2.588, Perp: 13.30, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [36/105], Loss: 2.588, Perp: 13.30, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [37/105], Loss: 2.587, Perp: 13.29, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [38/105], Loss: 2.587, Perp: 13.29, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [39/105], Loss: 2.587, Perp: 13.29, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [40/105], Loss: 2.587, Perp: 13.29, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [41/105], Loss: 2.587, Perp: 13.29, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [42/105], Loss: 2.587, Perp: 13.28, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [43/105], Loss: 2.586, Perp: 13.28, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [44/105], Loss: 2.586, Perp: 13.28, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [45/105], Loss: 2.586, Perp: 13.28, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [46/105], Loss: 2.586, Perp: 13.28, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [47/105], Loss: 2.586, Perp: 13.27, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [48/105], Loss: 2.586, Perp: 13.27, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [49/105], Loss: 2.586, Perp: 13.27, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [50/105], Loss: 2.586, Perp: 13.27, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [51/105], Loss: 2.585, Perp: 13.27, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [52/105], Loss: 2.585, Perp: 13.27, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [53/105], Loss: 2.585, Perp: 13.27, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [54/105], Loss: 2.585, Perp: 13.26, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [55/105], Loss: 2.585, Perp: 13.26, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [56/105], Loss: 2.585, Perp: 13.26, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [57/105], Loss: 2.585, Perp: 13.26, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [58/105], Loss: 2.585, Perp: 13.26, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [59/105], Loss: 2.585, Perp: 13.26, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [60/105], Loss: 2.585, Perp: 13.26, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [61/105], Loss: 2.585, Perp: 13.26, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [62/105], Loss: 2.584, Perp: 13.26, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [63/105], Loss: 2.584, Perp: 13.26, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [64/105], Loss: 2.584, Perp: 13.25, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [65/105], Loss: 2.584, Perp: 13.25, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [66/105], Loss: 2.584, Perp: 13.25, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [67/105], Loss: 2.584, Perp: 13.25, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [68/105], Loss: 2.584, Perp: 13.25, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [69/105], Loss: 2.584, Perp: 13.25, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [70/105], Loss: 2.584, Perp: 13.25, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [71/105], Loss: 2.584, Perp: 13.25, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [72/105], Loss: 2.584, Perp: 13.24, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [73/105], Loss: 2.583, Perp: 13.24, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [74/105], Loss: 2.583, Perp: 13.24, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [75/105], Loss: 2.583, Perp: 13.24, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [76/105], Loss: 2.583, Perp: 13.24, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [77/105], Loss: 2.583, Perp: 13.24, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [78/105], Loss: 2.583, Perp: 13.24, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [79/105], Loss: 2.583, Perp: 13.23, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [80/105], Loss: 2.583, Perp: 13.23, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [81/105], Loss: 2.583, Perp: 13.23, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [82/105], Loss: 2.583, Perp: 13.23, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [83/105], Loss: 2.582, Perp: 13.23, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [84/105], Loss: 2.582, Perp: 13.23, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [85/105], Loss: 2.582, Perp: 13.23, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [86/105], Loss: 2.582, Perp: 13.23, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [87/105], Loss: 2.582, Perp: 13.23, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [88/105], Loss: 2.582, Perp: 13.22, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [89/105], Loss: 2.582, Perp: 13.22, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [90/105], Loss: 2.582, Perp: 13.22, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [91/105], Loss: 2.582, Perp: 13.22, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [92/105], Loss: 2.582, Perp: 13.22, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [93/105], Loss: 2.582, Perp: 13.22, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [94/105], Loss: 2.582, Perp: 13.22, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [95/105], Loss: 2.582, Perp: 13.22, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [96/105], Loss: 2.581, Perp: 13.22, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [97/105], Loss: 2.581, Perp: 13.22, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [98/105], Loss: 2.581, Perp: 13.22, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [99/105], Loss: 2.581, Perp: 13.21, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [100/105], Loss: 2.581, Perp: 13.21, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [101/105], Loss: 2.581, Perp: 13.21, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [102/105], Loss: 2.581, Perp: 13.21, Acc: 0.46           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [31/40], Step [103/105], Loss: 2.581, Perp: 13.21, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [104/105], Loss: 2.581, Perp: 13.21, Acc: 0.46           here\n",
      "here\n",
      "Training: Epoch [31/40], Step [105/105], Loss: 2.581, Perp: 13.21, Acc: 0.46           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [1/26], Loss: 2.142, Perp: 8.51, Acc: 0.58           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [2/26], Loss: 2.136, Perp: 8.47, Acc: 0.58           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [3/26], Loss: 2.133, Perp: 8.44, Acc: 0.58           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [4/26], Loss: 2.130, Perp: 8.42, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [5/26], Loss: 2.129, Perp: 8.40, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [6/26], Loss: 2.127, Perp: 8.39, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [7/26], Loss: 2.126, Perp: 8.38, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [8/26], Loss: 2.125, Perp: 8.37, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [9/26], Loss: 2.124, Perp: 8.36, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [10/26], Loss: 2.123, Perp: 8.36, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [11/26], Loss: 2.122, Perp: 8.35, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [12/26], Loss: 2.122, Perp: 8.34, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [13/26], Loss: 2.121, Perp: 8.34, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [14/26], Loss: 2.120, Perp: 8.33, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [15/26], Loss: 2.119, Perp: 8.33, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [16/26], Loss: 2.119, Perp: 8.32, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [17/26], Loss: 2.118, Perp: 8.32, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [18/26], Loss: 2.118, Perp: 8.31, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [19/26], Loss: 2.117, Perp: 8.31, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [20/26], Loss: 2.117, Perp: 8.30, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [21/26], Loss: 2.116, Perp: 8.30, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [22/26], Loss: 2.116, Perp: 8.30, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [23/26], Loss: 2.115, Perp: 8.29, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [24/26], Loss: 2.115, Perp: 8.29, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [25/26], Loss: 2.114, Perp: 8.28, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [31/40], Step [26/26], Loss: 2.114, Perp: 8.28, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [1/105], Loss: 2.444, Perp: 11.52, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [2/105], Loss: 2.440, Perp: 11.47, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [3/105], Loss: 2.438, Perp: 11.45, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [4/105], Loss: 2.437, Perp: 11.44, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [5/105], Loss: 2.436, Perp: 11.43, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [6/105], Loss: 2.435, Perp: 11.42, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [7/105], Loss: 2.434, Perp: 11.40, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [8/105], Loss: 2.433, Perp: 11.40, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [9/105], Loss: 2.433, Perp: 11.39, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [10/105], Loss: 2.432, Perp: 11.39, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [11/105], Loss: 2.432, Perp: 11.38, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [12/105], Loss: 2.432, Perp: 11.38, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [13/105], Loss: 2.431, Perp: 11.38, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [14/105], Loss: 2.431, Perp: 11.37, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [15/105], Loss: 2.431, Perp: 11.37, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [16/105], Loss: 2.431, Perp: 11.37, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [17/105], Loss: 2.431, Perp: 11.37, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [18/105], Loss: 2.430, Perp: 11.36, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [19/105], Loss: 2.430, Perp: 11.36, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [20/105], Loss: 2.430, Perp: 11.36, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [21/105], Loss: 2.430, Perp: 11.36, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [22/105], Loss: 2.430, Perp: 11.35, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [23/105], Loss: 2.429, Perp: 11.35, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [24/105], Loss: 2.429, Perp: 11.35, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [25/105], Loss: 2.429, Perp: 11.35, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [26/105], Loss: 2.429, Perp: 11.34, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [27/105], Loss: 2.429, Perp: 11.34, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [28/105], Loss: 2.428, Perp: 11.34, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [29/105], Loss: 2.428, Perp: 11.34, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [30/105], Loss: 2.428, Perp: 11.34, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [31/105], Loss: 2.428, Perp: 11.33, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [32/105], Loss: 2.428, Perp: 11.33, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [33/105], Loss: 2.428, Perp: 11.33, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [34/105], Loss: 2.427, Perp: 11.33, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [35/105], Loss: 2.427, Perp: 11.33, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [36/105], Loss: 2.427, Perp: 11.33, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [37/105], Loss: 2.427, Perp: 11.32, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [38/105], Loss: 2.427, Perp: 11.32, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [39/105], Loss: 2.427, Perp: 11.32, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [40/105], Loss: 2.427, Perp: 11.32, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [41/105], Loss: 2.426, Perp: 11.32, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [42/105], Loss: 2.426, Perp: 11.32, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [43/105], Loss: 2.426, Perp: 11.31, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [44/105], Loss: 2.426, Perp: 11.31, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [45/105], Loss: 2.426, Perp: 11.31, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [46/105], Loss: 2.426, Perp: 11.31, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [47/105], Loss: 2.426, Perp: 11.31, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [48/105], Loss: 2.425, Perp: 11.31, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [49/105], Loss: 2.425, Perp: 11.31, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [50/105], Loss: 2.425, Perp: 11.31, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [51/105], Loss: 2.425, Perp: 11.31, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [52/105], Loss: 2.425, Perp: 11.30, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [53/105], Loss: 2.425, Perp: 11.30, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [54/105], Loss: 2.425, Perp: 11.30, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [55/105], Loss: 2.425, Perp: 11.30, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [56/105], Loss: 2.425, Perp: 11.30, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [57/105], Loss: 2.425, Perp: 11.30, Acc: 0.49           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [32/40], Step [58/105], Loss: 2.425, Perp: 11.30, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [59/105], Loss: 2.425, Perp: 11.30, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [60/105], Loss: 2.425, Perp: 11.30, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [61/105], Loss: 2.424, Perp: 11.30, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [62/105], Loss: 2.424, Perp: 11.30, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [63/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [64/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [65/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [66/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [67/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [68/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [69/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [70/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [71/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [72/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [73/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [74/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [75/105], Loss: 2.424, Perp: 11.29, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [76/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [77/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [78/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [79/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [80/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [81/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [82/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [83/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [84/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [85/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [86/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [87/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [88/105], Loss: 2.423, Perp: 11.28, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [89/105], Loss: 2.423, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [90/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [91/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [92/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [93/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [94/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [95/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [96/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [97/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [98/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [99/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [100/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [101/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [102/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [103/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [104/105], Loss: 2.422, Perp: 11.27, Acc: 0.49           here\n",
      "here\n",
      "Training: Epoch [32/40], Step [105/105], Loss: 2.422, Perp: 11.26, Acc: 0.49           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [1/26], Loss: 1.982, Perp: 7.25, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [2/26], Loss: 1.977, Perp: 7.22, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [3/26], Loss: 1.974, Perp: 7.20, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [4/26], Loss: 1.972, Perp: 7.18, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [5/26], Loss: 1.970, Perp: 7.17, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [6/26], Loss: 1.969, Perp: 7.17, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [7/26], Loss: 1.968, Perp: 7.16, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [8/26], Loss: 1.968, Perp: 7.15, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [9/26], Loss: 1.967, Perp: 7.15, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [10/26], Loss: 1.966, Perp: 7.14, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [11/26], Loss: 1.966, Perp: 7.14, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [12/26], Loss: 1.965, Perp: 7.14, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [13/26], Loss: 1.965, Perp: 7.13, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [14/26], Loss: 1.964, Perp: 7.13, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [15/26], Loss: 1.963, Perp: 7.12, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [16/26], Loss: 1.963, Perp: 7.12, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [17/26], Loss: 1.962, Perp: 7.12, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [18/26], Loss: 1.962, Perp: 7.11, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [19/26], Loss: 1.962, Perp: 7.11, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [20/26], Loss: 1.961, Perp: 7.11, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [21/26], Loss: 1.961, Perp: 7.10, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [22/26], Loss: 1.960, Perp: 7.10, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [23/26], Loss: 1.960, Perp: 7.10, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [24/26], Loss: 1.960, Perp: 7.10, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [25/26], Loss: 1.959, Perp: 7.09, Acc: 0.61           here\n",
      "here\n",
      "Validation: Epoch [32/40], Step [26/26], Loss: 1.959, Perp: 7.09, Acc: 0.61           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [1/105], Loss: 2.290, Perp: 9.88, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [2/105], Loss: 2.288, Perp: 9.85, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [3/105], Loss: 2.288, Perp: 9.85, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [4/105], Loss: 2.287, Perp: 9.85, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [5/105], Loss: 2.286, Perp: 9.84, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [6/105], Loss: 2.286, Perp: 9.83, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [7/105], Loss: 2.285, Perp: 9.83, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [8/105], Loss: 2.285, Perp: 9.82, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [9/105], Loss: 2.284, Perp: 9.82, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [10/105], Loss: 2.284, Perp: 9.82, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [11/105], Loss: 2.284, Perp: 9.81, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [12/105], Loss: 2.284, Perp: 9.81, Acc: 0.51           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [33/40], Step [13/105], Loss: 2.283, Perp: 9.81, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [14/105], Loss: 2.283, Perp: 9.81, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [15/105], Loss: 2.283, Perp: 9.81, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [16/105], Loss: 2.283, Perp: 9.80, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [17/105], Loss: 2.283, Perp: 9.80, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [18/105], Loss: 2.282, Perp: 9.80, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [19/105], Loss: 2.282, Perp: 9.80, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [20/105], Loss: 2.282, Perp: 9.80, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [21/105], Loss: 2.282, Perp: 9.80, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [22/105], Loss: 2.282, Perp: 9.80, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [23/105], Loss: 2.282, Perp: 9.79, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [24/105], Loss: 2.282, Perp: 9.79, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [25/105], Loss: 2.282, Perp: 9.79, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [26/105], Loss: 2.281, Perp: 9.79, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [27/105], Loss: 2.281, Perp: 9.79, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [28/105], Loss: 2.281, Perp: 9.79, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [29/105], Loss: 2.281, Perp: 9.79, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [30/105], Loss: 2.281, Perp: 9.78, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [31/105], Loss: 2.281, Perp: 9.78, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [32/105], Loss: 2.281, Perp: 9.78, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [33/105], Loss: 2.280, Perp: 9.78, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [34/105], Loss: 2.280, Perp: 9.78, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [35/105], Loss: 2.280, Perp: 9.78, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [36/105], Loss: 2.280, Perp: 9.78, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [37/105], Loss: 2.280, Perp: 9.78, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [38/105], Loss: 2.280, Perp: 9.78, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [39/105], Loss: 2.280, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [40/105], Loss: 2.280, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [41/105], Loss: 2.280, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [42/105], Loss: 2.279, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [43/105], Loss: 2.279, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [44/105], Loss: 2.279, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [45/105], Loss: 2.279, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [46/105], Loss: 2.279, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [47/105], Loss: 2.279, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [48/105], Loss: 2.279, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [49/105], Loss: 2.279, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [50/105], Loss: 2.279, Perp: 9.77, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [51/105], Loss: 2.279, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [52/105], Loss: 2.279, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [53/105], Loss: 2.279, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [54/105], Loss: 2.279, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [55/105], Loss: 2.279, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [56/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [57/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [58/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [59/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [60/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [61/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [62/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [63/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [64/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [65/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [66/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [67/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [68/105], Loss: 2.278, Perp: 9.76, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [69/105], Loss: 2.278, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [70/105], Loss: 2.278, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [71/105], Loss: 2.278, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [72/105], Loss: 2.278, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [73/105], Loss: 2.278, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [74/105], Loss: 2.278, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [75/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [76/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [77/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [78/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [79/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [80/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [81/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [82/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [83/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [84/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [85/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [86/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [87/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [88/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [89/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [90/105], Loss: 2.277, Perp: 9.75, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [91/105], Loss: 2.277, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [92/105], Loss: 2.277, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [93/105], Loss: 2.277, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [94/105], Loss: 2.277, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [95/105], Loss: 2.277, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [96/105], Loss: 2.277, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [97/105], Loss: 2.277, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [98/105], Loss: 2.277, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [99/105], Loss: 2.276, Perp: 9.74, Acc: 0.51           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [33/40], Step [100/105], Loss: 2.276, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [101/105], Loss: 2.276, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [102/105], Loss: 2.276, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [103/105], Loss: 2.276, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [104/105], Loss: 2.276, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Training: Epoch [33/40], Step [105/105], Loss: 2.276, Perp: 9.74, Acc: 0.51           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [1/26], Loss: 1.889, Perp: 6.61, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [2/26], Loss: 1.883, Perp: 6.57, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [3/26], Loss: 1.880, Perp: 6.55, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [4/26], Loss: 1.877, Perp: 6.54, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [5/26], Loss: 1.876, Perp: 6.53, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [6/26], Loss: 1.874, Perp: 6.52, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [7/26], Loss: 1.873, Perp: 6.51, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [8/26], Loss: 1.872, Perp: 6.50, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [9/26], Loss: 1.872, Perp: 6.50, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [10/26], Loss: 1.871, Perp: 6.49, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [11/26], Loss: 1.870, Perp: 6.49, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [12/26], Loss: 1.870, Perp: 6.49, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [13/26], Loss: 1.869, Perp: 6.48, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [14/26], Loss: 1.868, Perp: 6.48, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [15/26], Loss: 1.868, Perp: 6.47, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [16/26], Loss: 1.867, Perp: 6.47, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [17/26], Loss: 1.867, Perp: 6.47, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [18/26], Loss: 1.866, Perp: 6.46, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [19/26], Loss: 1.866, Perp: 6.46, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [20/26], Loss: 1.865, Perp: 6.46, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [21/26], Loss: 1.865, Perp: 6.45, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [22/26], Loss: 1.864, Perp: 6.45, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [23/26], Loss: 1.864, Perp: 6.45, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [24/26], Loss: 1.864, Perp: 6.45, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [25/26], Loss: 1.863, Perp: 6.44, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [33/40], Step [26/26], Loss: 1.863, Perp: 6.44, Acc: 0.64           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [1/105], Loss: 2.266, Perp: 9.64, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [2/105], Loss: 2.263, Perp: 9.61, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [3/105], Loss: 2.262, Perp: 9.60, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [4/105], Loss: 2.261, Perp: 9.59, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [5/105], Loss: 2.260, Perp: 9.58, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [6/105], Loss: 2.259, Perp: 9.57, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [7/105], Loss: 2.258, Perp: 9.57, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [8/105], Loss: 2.258, Perp: 9.56, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [9/105], Loss: 2.257, Perp: 9.56, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [10/105], Loss: 2.257, Perp: 9.55, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [11/105], Loss: 2.256, Perp: 9.55, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [12/105], Loss: 2.256, Perp: 9.55, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [13/105], Loss: 2.256, Perp: 9.54, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [14/105], Loss: 2.256, Perp: 9.54, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [15/105], Loss: 2.255, Perp: 9.54, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [16/105], Loss: 2.255, Perp: 9.53, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [17/105], Loss: 2.255, Perp: 9.53, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [18/105], Loss: 2.254, Perp: 9.53, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [19/105], Loss: 2.254, Perp: 9.53, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [20/105], Loss: 2.254, Perp: 9.53, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [21/105], Loss: 2.254, Perp: 9.52, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [22/105], Loss: 2.254, Perp: 9.52, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [23/105], Loss: 2.254, Perp: 9.52, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [24/105], Loss: 2.253, Perp: 9.52, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [25/105], Loss: 2.253, Perp: 9.52, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [26/105], Loss: 2.253, Perp: 9.52, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [27/105], Loss: 2.253, Perp: 9.52, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [28/105], Loss: 2.253, Perp: 9.51, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [29/105], Loss: 2.253, Perp: 9.51, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [30/105], Loss: 2.252, Perp: 9.51, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [31/105], Loss: 2.252, Perp: 9.51, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [32/105], Loss: 2.252, Perp: 9.51, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [33/105], Loss: 2.252, Perp: 9.51, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [34/105], Loss: 2.252, Perp: 9.51, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [35/105], Loss: 2.252, Perp: 9.50, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [36/105], Loss: 2.252, Perp: 9.50, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [37/105], Loss: 2.251, Perp: 9.50, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [38/105], Loss: 2.251, Perp: 9.50, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [39/105], Loss: 2.251, Perp: 9.50, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [40/105], Loss: 2.251, Perp: 9.50, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [41/105], Loss: 2.251, Perp: 9.50, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [42/105], Loss: 2.251, Perp: 9.50, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [43/105], Loss: 2.251, Perp: 9.50, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [44/105], Loss: 2.251, Perp: 9.49, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [45/105], Loss: 2.251, Perp: 9.49, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [46/105], Loss: 2.250, Perp: 9.49, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [47/105], Loss: 2.250, Perp: 9.49, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [48/105], Loss: 2.250, Perp: 9.49, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [49/105], Loss: 2.250, Perp: 9.49, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [50/105], Loss: 2.250, Perp: 9.49, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [51/105], Loss: 2.250, Perp: 9.49, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [52/105], Loss: 2.250, Perp: 9.49, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [53/105], Loss: 2.250, Perp: 9.49, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [54/105], Loss: 2.250, Perp: 9.49, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [55/105], Loss: 2.250, Perp: 9.48, Acc: 0.52           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [34/40], Step [56/105], Loss: 2.250, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [57/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [58/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [59/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [60/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [61/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [62/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [63/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [64/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [65/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [66/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [67/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [68/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [69/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [70/105], Loss: 2.249, Perp: 9.48, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [71/105], Loss: 2.249, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [72/105], Loss: 2.249, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [73/105], Loss: 2.249, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [74/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [75/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [76/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [77/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [78/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [79/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [80/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [81/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [82/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [83/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [84/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [85/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [86/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [87/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [88/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [89/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [90/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [91/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [92/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [93/105], Loss: 2.248, Perp: 9.47, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [94/105], Loss: 2.248, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [95/105], Loss: 2.248, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [96/105], Loss: 2.248, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [97/105], Loss: 2.247, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [98/105], Loss: 2.247, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [99/105], Loss: 2.247, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [100/105], Loss: 2.247, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [101/105], Loss: 2.247, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [102/105], Loss: 2.247, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [103/105], Loss: 2.247, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [104/105], Loss: 2.247, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [34/40], Step [105/105], Loss: 2.247, Perp: 9.46, Acc: 0.52           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [1/26], Loss: 1.888, Perp: 6.61, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [2/26], Loss: 1.882, Perp: 6.57, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [3/26], Loss: 1.879, Perp: 6.54, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [4/26], Loss: 1.876, Perp: 6.53, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [5/26], Loss: 1.874, Perp: 6.52, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [6/26], Loss: 1.873, Perp: 6.51, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [7/26], Loss: 1.872, Perp: 6.50, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [8/26], Loss: 1.871, Perp: 6.49, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [9/26], Loss: 1.870, Perp: 6.49, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [10/26], Loss: 1.869, Perp: 6.48, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [11/26], Loss: 1.868, Perp: 6.48, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [12/26], Loss: 1.868, Perp: 6.47, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [13/26], Loss: 1.867, Perp: 6.47, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [14/26], Loss: 1.866, Perp: 6.46, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [15/26], Loss: 1.866, Perp: 6.46, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [16/26], Loss: 1.865, Perp: 6.46, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [17/26], Loss: 1.864, Perp: 6.45, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [18/26], Loss: 1.864, Perp: 6.45, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [19/26], Loss: 1.863, Perp: 6.45, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [20/26], Loss: 1.863, Perp: 6.44, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [21/26], Loss: 1.863, Perp: 6.44, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [22/26], Loss: 1.862, Perp: 6.44, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [23/26], Loss: 1.862, Perp: 6.44, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [24/26], Loss: 1.861, Perp: 6.43, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [25/26], Loss: 1.861, Perp: 6.43, Acc: 0.63           here\n",
      "here\n",
      "Validation: Epoch [34/40], Step [26/26], Loss: 1.861, Perp: 6.43, Acc: 0.63           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [1/105], Loss: 2.191, Perp: 8.95, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [2/105], Loss: 2.189, Perp: 8.92, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [3/105], Loss: 2.188, Perp: 8.92, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [4/105], Loss: 2.187, Perp: 8.91, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [5/105], Loss: 2.186, Perp: 8.90, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [6/105], Loss: 2.185, Perp: 8.89, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [7/105], Loss: 2.184, Perp: 8.89, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [8/105], Loss: 2.184, Perp: 8.88, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [9/105], Loss: 2.183, Perp: 8.88, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [10/105], Loss: 2.183, Perp: 8.87, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [11/105], Loss: 2.183, Perp: 8.87, Acc: 0.52           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [35/40], Step [12/105], Loss: 2.182, Perp: 8.87, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [13/105], Loss: 2.182, Perp: 8.86, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [14/105], Loss: 2.182, Perp: 8.86, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [15/105], Loss: 2.181, Perp: 8.86, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [16/105], Loss: 2.181, Perp: 8.86, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [17/105], Loss: 2.181, Perp: 8.86, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [18/105], Loss: 2.181, Perp: 8.85, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [19/105], Loss: 2.181, Perp: 8.85, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [20/105], Loss: 2.180, Perp: 8.85, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [21/105], Loss: 2.180, Perp: 8.85, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [22/105], Loss: 2.180, Perp: 8.85, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [23/105], Loss: 2.180, Perp: 8.84, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [24/105], Loss: 2.180, Perp: 8.84, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [25/105], Loss: 2.180, Perp: 8.84, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [26/105], Loss: 2.179, Perp: 8.84, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [27/105], Loss: 2.179, Perp: 8.84, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [28/105], Loss: 2.179, Perp: 8.84, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [29/105], Loss: 2.179, Perp: 8.84, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [30/105], Loss: 2.179, Perp: 8.84, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [31/105], Loss: 2.179, Perp: 8.83, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [32/105], Loss: 2.178, Perp: 8.83, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [33/105], Loss: 2.178, Perp: 8.83, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [34/105], Loss: 2.178, Perp: 8.83, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [35/105], Loss: 2.178, Perp: 8.83, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [36/105], Loss: 2.178, Perp: 8.83, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [37/105], Loss: 2.178, Perp: 8.83, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [38/105], Loss: 2.178, Perp: 8.83, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [39/105], Loss: 2.178, Perp: 8.83, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [40/105], Loss: 2.178, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [41/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [42/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [43/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [44/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [45/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [46/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [47/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [48/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [49/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [50/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [51/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [52/105], Loss: 2.177, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [53/105], Loss: 2.176, Perp: 8.82, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [54/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [55/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [56/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [57/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [58/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [59/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [60/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [61/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [62/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [63/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [64/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [65/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [66/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [67/105], Loss: 2.176, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [68/105], Loss: 2.175, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [69/105], Loss: 2.175, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [70/105], Loss: 2.175, Perp: 8.81, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [71/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [72/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [73/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [74/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [75/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [76/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [77/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [78/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [79/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [80/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [81/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [82/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [83/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [84/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [85/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [86/105], Loss: 2.175, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [87/105], Loss: 2.174, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [88/105], Loss: 2.174, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [89/105], Loss: 2.174, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [90/105], Loss: 2.174, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [91/105], Loss: 2.174, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [92/105], Loss: 2.174, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [93/105], Loss: 2.174, Perp: 8.80, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [94/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [95/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [96/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [97/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [98/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [35/40], Step [99/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [100/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [101/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [102/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [103/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [104/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n",
      "Training: Epoch [35/40], Step [105/105], Loss: 2.174, Perp: 8.79, Acc: 0.52           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [1/26], Loss: 1.855, Perp: 6.39, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [2/26], Loss: 1.849, Perp: 6.35, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [3/26], Loss: 1.846, Perp: 6.33, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [4/26], Loss: 1.843, Perp: 6.32, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [5/26], Loss: 1.841, Perp: 6.31, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [6/26], Loss: 1.840, Perp: 6.30, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [7/26], Loss: 1.839, Perp: 6.29, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [8/26], Loss: 1.838, Perp: 6.28, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [9/26], Loss: 1.837, Perp: 6.28, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [10/26], Loss: 1.836, Perp: 6.27, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [11/26], Loss: 1.835, Perp: 6.27, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [12/26], Loss: 1.835, Perp: 6.26, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [13/26], Loss: 1.834, Perp: 6.26, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [14/26], Loss: 1.833, Perp: 6.25, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [15/26], Loss: 1.832, Perp: 6.25, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [16/26], Loss: 1.832, Perp: 6.25, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [17/26], Loss: 1.831, Perp: 6.24, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [18/26], Loss: 1.831, Perp: 6.24, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [19/26], Loss: 1.830, Perp: 6.24, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [20/26], Loss: 1.830, Perp: 6.23, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [21/26], Loss: 1.829, Perp: 6.23, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [22/26], Loss: 1.829, Perp: 6.23, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [23/26], Loss: 1.829, Perp: 6.22, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [24/26], Loss: 1.828, Perp: 6.22, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [25/26], Loss: 1.828, Perp: 6.22, Acc: 0.64           here\n",
      "here\n",
      "Validation: Epoch [35/40], Step [26/26], Loss: 1.827, Perp: 6.22, Acc: 0.64           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [1/105], Loss: 2.109, Perp: 8.24, Acc: 0.53           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [2/105], Loss: 2.106, Perp: 8.22, Acc: 0.53           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [3/105], Loss: 2.105, Perp: 8.21, Acc: 0.53           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [4/105], Loss: 2.104, Perp: 8.20, Acc: 0.53           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [5/105], Loss: 2.103, Perp: 8.19, Acc: 0.53           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [6/105], Loss: 2.103, Perp: 8.19, Acc: 0.53           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [7/105], Loss: 2.102, Perp: 8.18, Acc: 0.53           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [8/105], Loss: 2.101, Perp: 8.18, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [9/105], Loss: 2.101, Perp: 8.17, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [10/105], Loss: 2.101, Perp: 8.17, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [11/105], Loss: 2.100, Perp: 8.17, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [12/105], Loss: 2.100, Perp: 8.17, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [13/105], Loss: 2.100, Perp: 8.16, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [14/105], Loss: 2.099, Perp: 8.16, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [15/105], Loss: 2.099, Perp: 8.16, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [16/105], Loss: 2.099, Perp: 8.16, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [17/105], Loss: 2.099, Perp: 8.16, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [18/105], Loss: 2.098, Perp: 8.15, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [19/105], Loss: 2.098, Perp: 8.15, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [20/105], Loss: 2.098, Perp: 8.15, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [21/105], Loss: 2.098, Perp: 8.15, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [22/105], Loss: 2.098, Perp: 8.15, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [23/105], Loss: 2.098, Perp: 8.15, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [24/105], Loss: 2.098, Perp: 8.15, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [25/105], Loss: 2.097, Perp: 8.14, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [26/105], Loss: 2.097, Perp: 8.14, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [27/105], Loss: 2.097, Perp: 8.14, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [28/105], Loss: 2.097, Perp: 8.14, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [29/105], Loss: 2.097, Perp: 8.14, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [30/105], Loss: 2.097, Perp: 8.14, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [31/105], Loss: 2.097, Perp: 8.14, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [32/105], Loss: 2.096, Perp: 8.14, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [33/105], Loss: 2.096, Perp: 8.14, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [34/105], Loss: 2.096, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [35/105], Loss: 2.096, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [36/105], Loss: 2.096, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [37/105], Loss: 2.096, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [38/105], Loss: 2.096, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [39/105], Loss: 2.096, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [40/105], Loss: 2.096, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [41/105], Loss: 2.096, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [42/105], Loss: 2.095, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [43/105], Loss: 2.095, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [44/105], Loss: 2.095, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [45/105], Loss: 2.095, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [46/105], Loss: 2.095, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [47/105], Loss: 2.095, Perp: 8.13, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [48/105], Loss: 2.095, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [49/105], Loss: 2.095, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [50/105], Loss: 2.095, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [51/105], Loss: 2.095, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [52/105], Loss: 2.095, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [53/105], Loss: 2.095, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [54/105], Loss: 2.095, Perp: 8.12, Acc: 0.54           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [36/40], Step [55/105], Loss: 2.095, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [56/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [57/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [58/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [59/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [60/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [61/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [62/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [63/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [64/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [65/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [66/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [67/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [68/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [69/105], Loss: 2.094, Perp: 8.12, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [70/105], Loss: 2.094, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [71/105], Loss: 2.094, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [72/105], Loss: 2.094, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [73/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [74/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [75/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [76/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [77/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [78/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [79/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [80/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [81/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [82/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [83/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [84/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [85/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [86/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [87/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [88/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [89/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [90/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [91/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [92/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [93/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [94/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [95/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [96/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [97/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [98/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [99/105], Loss: 2.093, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [100/105], Loss: 2.092, Perp: 8.11, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [101/105], Loss: 2.092, Perp: 8.10, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [102/105], Loss: 2.092, Perp: 8.10, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [103/105], Loss: 2.092, Perp: 8.10, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [104/105], Loss: 2.092, Perp: 8.10, Acc: 0.54           here\n",
      "here\n",
      "Training: Epoch [36/40], Step [105/105], Loss: 2.092, Perp: 8.10, Acc: 0.54           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [1/26], Loss: 1.760, Perp: 5.82, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [2/26], Loss: 1.754, Perp: 5.78, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [3/26], Loss: 1.751, Perp: 5.76, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [4/26], Loss: 1.748, Perp: 5.74, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [5/26], Loss: 1.747, Perp: 5.74, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [6/26], Loss: 1.745, Perp: 5.73, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [7/26], Loss: 1.744, Perp: 5.72, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [8/26], Loss: 1.743, Perp: 5.71, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [9/26], Loss: 1.742, Perp: 5.71, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [10/26], Loss: 1.741, Perp: 5.71, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [11/26], Loss: 1.741, Perp: 5.70, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [12/26], Loss: 1.740, Perp: 5.70, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [13/26], Loss: 1.739, Perp: 5.69, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [14/26], Loss: 1.739, Perp: 5.69, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [15/26], Loss: 1.738, Perp: 5.69, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [16/26], Loss: 1.737, Perp: 5.68, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [17/26], Loss: 1.737, Perp: 5.68, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [18/26], Loss: 1.736, Perp: 5.68, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [19/26], Loss: 1.736, Perp: 5.67, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [20/26], Loss: 1.736, Perp: 5.67, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [21/26], Loss: 1.735, Perp: 5.67, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [22/26], Loss: 1.735, Perp: 5.67, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [23/26], Loss: 1.734, Perp: 5.66, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [24/26], Loss: 1.734, Perp: 5.66, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [25/26], Loss: 1.733, Perp: 5.66, Acc: 0.66           here\n",
      "here\n",
      "Validation: Epoch [36/40], Step [26/26], Loss: 1.733, Perp: 5.66, Acc: 0.66           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [1/105], Loss: 2.021, Perp: 7.55, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [2/105], Loss: 2.019, Perp: 7.53, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [3/105], Loss: 2.018, Perp: 7.52, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [4/105], Loss: 2.017, Perp: 7.52, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [5/105], Loss: 2.017, Perp: 7.51, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [6/105], Loss: 2.016, Perp: 7.51, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [7/105], Loss: 2.015, Perp: 7.50, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [8/105], Loss: 2.015, Perp: 7.50, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [9/105], Loss: 2.015, Perp: 7.50, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [10/105], Loss: 2.014, Perp: 7.50, Acc: 0.56           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [37/40], Step [11/105], Loss: 2.014, Perp: 7.49, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [12/105], Loss: 2.014, Perp: 7.49, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [13/105], Loss: 2.014, Perp: 7.49, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [14/105], Loss: 2.013, Perp: 7.49, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [15/105], Loss: 2.013, Perp: 7.49, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [16/105], Loss: 2.013, Perp: 7.49, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [17/105], Loss: 2.013, Perp: 7.48, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [18/105], Loss: 2.013, Perp: 7.48, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [19/105], Loss: 2.012, Perp: 7.48, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [20/105], Loss: 2.012, Perp: 7.48, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [21/105], Loss: 2.012, Perp: 7.48, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [22/105], Loss: 2.012, Perp: 7.48, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [23/105], Loss: 2.012, Perp: 7.48, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [24/105], Loss: 2.012, Perp: 7.48, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [25/105], Loss: 2.012, Perp: 7.48, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [26/105], Loss: 2.011, Perp: 7.47, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [27/105], Loss: 2.011, Perp: 7.47, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [28/105], Loss: 2.011, Perp: 7.47, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [29/105], Loss: 2.011, Perp: 7.47, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [30/105], Loss: 2.011, Perp: 7.47, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [31/105], Loss: 2.011, Perp: 7.47, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [32/105], Loss: 2.011, Perp: 7.47, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [33/105], Loss: 2.011, Perp: 7.47, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [34/105], Loss: 2.010, Perp: 7.47, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [35/105], Loss: 2.010, Perp: 7.47, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [36/105], Loss: 2.010, Perp: 7.47, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [37/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [38/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [39/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [40/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [41/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [42/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [43/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [44/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [45/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [46/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [47/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [48/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [49/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [50/105], Loss: 2.010, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [51/105], Loss: 2.009, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [52/105], Loss: 2.009, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [53/105], Loss: 2.009, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [54/105], Loss: 2.009, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [55/105], Loss: 2.009, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [56/105], Loss: 2.009, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [57/105], Loss: 2.009, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [58/105], Loss: 2.009, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [59/105], Loss: 2.009, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [60/105], Loss: 2.009, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [61/105], Loss: 2.009, Perp: 7.46, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [62/105], Loss: 2.009, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [63/105], Loss: 2.009, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [64/105], Loss: 2.009, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [65/105], Loss: 2.009, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [66/105], Loss: 2.009, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [67/105], Loss: 2.009, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [68/105], Loss: 2.009, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [69/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [70/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [71/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [72/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [73/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [74/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [75/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [76/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [77/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [78/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [79/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [80/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [81/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [82/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [83/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [84/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [85/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [86/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [87/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [88/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [89/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [90/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [91/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [92/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [93/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [94/105], Loss: 2.008, Perp: 7.45, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [95/105], Loss: 2.008, Perp: 7.44, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [96/105], Loss: 2.008, Perp: 7.44, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [97/105], Loss: 2.007, Perp: 7.44, Acc: 0.56           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [37/40], Step [98/105], Loss: 2.007, Perp: 7.44, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [99/105], Loss: 2.007, Perp: 7.44, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [100/105], Loss: 2.007, Perp: 7.44, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [101/105], Loss: 2.007, Perp: 7.44, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [102/105], Loss: 2.007, Perp: 7.44, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [103/105], Loss: 2.007, Perp: 7.44, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [104/105], Loss: 2.007, Perp: 7.44, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [37/40], Step [105/105], Loss: 2.007, Perp: 7.44, Acc: 0.56           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [1/26], Loss: 1.712, Perp: 5.54, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [2/26], Loss: 1.705, Perp: 5.50, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [3/26], Loss: 1.702, Perp: 5.48, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [4/26], Loss: 1.699, Perp: 5.47, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [5/26], Loss: 1.697, Perp: 5.46, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [6/26], Loss: 1.696, Perp: 5.45, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [7/26], Loss: 1.694, Perp: 5.44, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [8/26], Loss: 1.694, Perp: 5.44, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [9/26], Loss: 1.693, Perp: 5.43, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [10/26], Loss: 1.692, Perp: 5.43, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [11/26], Loss: 1.691, Perp: 5.43, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [12/26], Loss: 1.690, Perp: 5.42, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [13/26], Loss: 1.690, Perp: 5.42, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [14/26], Loss: 1.689, Perp: 5.41, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [15/26], Loss: 1.688, Perp: 5.41, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [16/26], Loss: 1.688, Perp: 5.41, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [17/26], Loss: 1.687, Perp: 5.40, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [18/26], Loss: 1.687, Perp: 5.40, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [19/26], Loss: 1.686, Perp: 5.40, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [20/26], Loss: 1.686, Perp: 5.40, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [21/26], Loss: 1.685, Perp: 5.39, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [22/26], Loss: 1.685, Perp: 5.39, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [23/26], Loss: 1.685, Perp: 5.39, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [24/26], Loss: 1.684, Perp: 5.39, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [25/26], Loss: 1.684, Perp: 5.39, Acc: 0.67           here\n",
      "here\n",
      "Validation: Epoch [37/40], Step [26/26], Loss: 1.683, Perp: 5.38, Acc: 0.67           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [1/105], Loss: 1.965, Perp: 7.13, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [2/105], Loss: 1.963, Perp: 7.12, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [3/105], Loss: 1.962, Perp: 7.11, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [4/105], Loss: 1.961, Perp: 7.11, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [5/105], Loss: 1.960, Perp: 7.10, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [6/105], Loss: 1.960, Perp: 7.10, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [7/105], Loss: 1.959, Perp: 7.09, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [8/105], Loss: 1.959, Perp: 7.09, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [9/105], Loss: 1.959, Perp: 7.09, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [10/105], Loss: 1.958, Perp: 7.09, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [11/105], Loss: 1.958, Perp: 7.09, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [12/105], Loss: 1.958, Perp: 7.08, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [13/105], Loss: 1.958, Perp: 7.08, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [14/105], Loss: 1.958, Perp: 7.08, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [15/105], Loss: 1.957, Perp: 7.08, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [16/105], Loss: 1.957, Perp: 7.08, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [17/105], Loss: 1.957, Perp: 7.08, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [18/105], Loss: 1.957, Perp: 7.08, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [19/105], Loss: 1.957, Perp: 7.08, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [20/105], Loss: 1.956, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [21/105], Loss: 1.956, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [22/105], Loss: 1.956, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [23/105], Loss: 1.956, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [24/105], Loss: 1.956, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [25/105], Loss: 1.956, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [26/105], Loss: 1.956, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [27/105], Loss: 1.956, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [28/105], Loss: 1.955, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [29/105], Loss: 1.955, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [30/105], Loss: 1.955, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [31/105], Loss: 1.955, Perp: 7.07, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [32/105], Loss: 1.955, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [33/105], Loss: 1.955, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [34/105], Loss: 1.955, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [35/105], Loss: 1.955, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [36/105], Loss: 1.955, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [37/105], Loss: 1.955, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [38/105], Loss: 1.954, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [39/105], Loss: 1.954, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [40/105], Loss: 1.954, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [41/105], Loss: 1.954, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [42/105], Loss: 1.954, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [43/105], Loss: 1.954, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [44/105], Loss: 1.954, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [45/105], Loss: 1.954, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [46/105], Loss: 1.954, Perp: 7.06, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [47/105], Loss: 1.954, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [48/105], Loss: 1.954, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [49/105], Loss: 1.954, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [50/105], Loss: 1.954, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [51/105], Loss: 1.954, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [52/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [53/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [38/40], Step [54/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [55/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [56/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [57/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [58/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [59/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [60/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [61/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [62/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [63/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [64/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [65/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [66/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [67/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [68/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [69/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [70/105], Loss: 1.953, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [71/105], Loss: 1.952, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [72/105], Loss: 1.952, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [73/105], Loss: 1.952, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [74/105], Loss: 1.952, Perp: 7.05, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [75/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [76/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [77/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [78/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [79/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [80/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [81/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [82/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [83/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [84/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [85/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [86/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [87/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [88/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [89/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [90/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [91/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [92/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [93/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [94/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [95/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [96/105], Loss: 1.952, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [97/105], Loss: 1.951, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [98/105], Loss: 1.951, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [99/105], Loss: 1.951, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [100/105], Loss: 1.951, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [101/105], Loss: 1.951, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [102/105], Loss: 1.951, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [103/105], Loss: 1.951, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [104/105], Loss: 1.951, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Training: Epoch [38/40], Step [105/105], Loss: 1.951, Perp: 7.04, Acc: 0.56           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [1/26], Loss: 1.605, Perp: 4.98, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [2/26], Loss: 1.598, Perp: 4.94, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [3/26], Loss: 1.594, Perp: 4.92, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [4/26], Loss: 1.591, Perp: 4.91, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [5/26], Loss: 1.590, Perp: 4.90, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [6/26], Loss: 1.588, Perp: 4.89, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [7/26], Loss: 1.587, Perp: 4.89, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [8/26], Loss: 1.586, Perp: 4.88, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [9/26], Loss: 1.585, Perp: 4.88, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [10/26], Loss: 1.584, Perp: 4.87, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [11/26], Loss: 1.583, Perp: 4.87, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [12/26], Loss: 1.582, Perp: 4.87, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [13/26], Loss: 1.581, Perp: 4.86, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [14/26], Loss: 1.581, Perp: 4.86, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [15/26], Loss: 1.580, Perp: 4.85, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [16/26], Loss: 1.579, Perp: 4.85, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [17/26], Loss: 1.579, Perp: 4.85, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [18/26], Loss: 1.578, Perp: 4.85, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [19/26], Loss: 1.578, Perp: 4.84, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [20/26], Loss: 1.577, Perp: 4.84, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [21/26], Loss: 1.577, Perp: 4.84, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [22/26], Loss: 1.576, Perp: 4.84, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [23/26], Loss: 1.576, Perp: 4.84, Acc: 0.70           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [24/26], Loss: 1.575, Perp: 4.83, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [25/26], Loss: 1.575, Perp: 4.83, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [38/40], Step [26/26], Loss: 1.575, Perp: 4.83, Acc: 0.71           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [1/105], Loss: 1.898, Perp: 6.68, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [2/105], Loss: 1.896, Perp: 6.66, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [3/105], Loss: 1.896, Perp: 6.66, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [4/105], Loss: 1.895, Perp: 6.65, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [5/105], Loss: 1.895, Perp: 6.65, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [6/105], Loss: 1.894, Perp: 6.65, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [7/105], Loss: 1.894, Perp: 6.64, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [8/105], Loss: 1.893, Perp: 6.64, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [9/105], Loss: 1.893, Perp: 6.64, Acc: 0.58           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [39/40], Step [10/105], Loss: 1.893, Perp: 6.64, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [11/105], Loss: 1.892, Perp: 6.64, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [12/105], Loss: 1.892, Perp: 6.63, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [13/105], Loss: 1.892, Perp: 6.63, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [14/105], Loss: 1.892, Perp: 6.63, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [15/105], Loss: 1.892, Perp: 6.63, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [16/105], Loss: 1.892, Perp: 6.63, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [17/105], Loss: 1.891, Perp: 6.63, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [18/105], Loss: 1.891, Perp: 6.63, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [19/105], Loss: 1.891, Perp: 6.63, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [20/105], Loss: 1.891, Perp: 6.63, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [21/105], Loss: 1.891, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [22/105], Loss: 1.891, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [23/105], Loss: 1.891, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [24/105], Loss: 1.891, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [25/105], Loss: 1.890, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [26/105], Loss: 1.890, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [27/105], Loss: 1.890, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [28/105], Loss: 1.890, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [29/105], Loss: 1.890, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [30/105], Loss: 1.890, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [31/105], Loss: 1.890, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [32/105], Loss: 1.890, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [33/105], Loss: 1.890, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [34/105], Loss: 1.890, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [35/105], Loss: 1.889, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [36/105], Loss: 1.889, Perp: 6.62, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [37/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [38/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [39/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [40/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [41/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [42/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [43/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [44/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [45/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [46/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [47/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [48/105], Loss: 1.889, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [49/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [50/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [51/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [52/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [53/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [54/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [55/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [56/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [57/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [58/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [59/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [60/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [61/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [62/105], Loss: 1.888, Perp: 6.61, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [63/105], Loss: 1.888, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [64/105], Loss: 1.888, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [65/105], Loss: 1.888, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [66/105], Loss: 1.888, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [67/105], Loss: 1.888, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [68/105], Loss: 1.888, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [69/105], Loss: 1.888, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [70/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [71/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [72/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [73/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [74/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [75/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [76/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [77/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [78/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [79/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [80/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [81/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [82/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [83/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [84/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [85/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [86/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [87/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [88/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [89/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [90/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [91/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [92/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [93/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [94/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [95/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [96/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [39/40], Step [97/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [98/105], Loss: 1.887, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [99/105], Loss: 1.886, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [100/105], Loss: 1.886, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [101/105], Loss: 1.886, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [102/105], Loss: 1.886, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [103/105], Loss: 1.886, Perp: 6.60, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [104/105], Loss: 1.886, Perp: 6.59, Acc: 0.58           here\n",
      "here\n",
      "Training: Epoch [39/40], Step [105/105], Loss: 1.886, Perp: 6.59, Acc: 0.58           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [1/26], Loss: 1.565, Perp: 4.78, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [2/26], Loss: 1.557, Perp: 4.75, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [3/26], Loss: 1.553, Perp: 4.73, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [4/26], Loss: 1.550, Perp: 4.71, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [5/26], Loss: 1.549, Perp: 4.70, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [6/26], Loss: 1.547, Perp: 4.70, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [7/26], Loss: 1.545, Perp: 4.69, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [8/26], Loss: 1.544, Perp: 4.69, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [9/26], Loss: 1.543, Perp: 4.68, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [10/26], Loss: 1.543, Perp: 4.68, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [11/26], Loss: 1.542, Perp: 4.67, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [12/26], Loss: 1.541, Perp: 4.67, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [13/26], Loss: 1.540, Perp: 4.66, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [14/26], Loss: 1.539, Perp: 4.66, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [15/26], Loss: 1.539, Perp: 4.66, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [16/26], Loss: 1.538, Perp: 4.66, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [17/26], Loss: 1.537, Perp: 4.65, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [18/26], Loss: 1.537, Perp: 4.65, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [19/26], Loss: 1.536, Perp: 4.65, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [20/26], Loss: 1.536, Perp: 4.65, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [21/26], Loss: 1.535, Perp: 4.64, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [22/26], Loss: 1.535, Perp: 4.64, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [23/26], Loss: 1.534, Perp: 4.64, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [24/26], Loss: 1.534, Perp: 4.64, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [25/26], Loss: 1.534, Perp: 4.63, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [39/40], Step [26/26], Loss: 1.533, Perp: 4.63, Acc: 0.72           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [1/105], Loss: 1.855, Perp: 6.39, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [2/105], Loss: 1.852, Perp: 6.37, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [3/105], Loss: 1.852, Perp: 6.37, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [4/105], Loss: 1.851, Perp: 6.37, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [5/105], Loss: 1.850, Perp: 6.36, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [6/105], Loss: 1.850, Perp: 6.36, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [7/105], Loss: 1.849, Perp: 6.35, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [8/105], Loss: 1.849, Perp: 6.35, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [9/105], Loss: 1.848, Perp: 6.35, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [10/105], Loss: 1.848, Perp: 6.35, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [11/105], Loss: 1.848, Perp: 6.35, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [12/105], Loss: 1.848, Perp: 6.34, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [13/105], Loss: 1.848, Perp: 6.34, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [14/105], Loss: 1.847, Perp: 6.34, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [15/105], Loss: 1.847, Perp: 6.34, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [16/105], Loss: 1.847, Perp: 6.34, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [17/105], Loss: 1.847, Perp: 6.34, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [18/105], Loss: 1.847, Perp: 6.34, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [19/105], Loss: 1.846, Perp: 6.34, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [20/105], Loss: 1.846, Perp: 6.34, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [21/105], Loss: 1.846, Perp: 6.34, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [22/105], Loss: 1.846, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [23/105], Loss: 1.846, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [24/105], Loss: 1.846, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [25/105], Loss: 1.846, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [26/105], Loss: 1.846, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [27/105], Loss: 1.846, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [28/105], Loss: 1.845, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [29/105], Loss: 1.845, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [30/105], Loss: 1.845, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [31/105], Loss: 1.845, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [32/105], Loss: 1.845, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [33/105], Loss: 1.845, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [34/105], Loss: 1.845, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [35/105], Loss: 1.845, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [36/105], Loss: 1.845, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [37/105], Loss: 1.845, Perp: 6.33, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [38/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [39/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [40/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [41/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [42/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [43/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [44/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [45/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [46/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [47/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [48/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [49/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [50/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [51/105], Loss: 1.844, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [52/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [40/40], Step [53/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [54/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [55/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [56/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [57/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [58/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [59/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [60/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [61/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [62/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [63/105], Loss: 1.843, Perp: 6.32, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [64/105], Loss: 1.843, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [65/105], Loss: 1.843, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [66/105], Loss: 1.843, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [67/105], Loss: 1.843, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [68/105], Loss: 1.843, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [69/105], Loss: 1.843, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [70/105], Loss: 1.843, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [71/105], Loss: 1.843, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [72/105], Loss: 1.843, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [73/105], Loss: 1.843, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [74/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [75/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [76/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [77/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [78/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [79/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [80/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [81/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [82/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [83/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [84/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [85/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [86/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [87/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [88/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [89/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [90/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [91/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [92/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [93/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [94/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [95/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [96/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [97/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [98/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [99/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [100/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [101/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [102/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [103/105], Loss: 1.842, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [104/105], Loss: 1.841, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Training: Epoch [40/40], Step [105/105], Loss: 1.841, Perp: 6.31, Acc: 0.59           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [1/26], Loss: 1.574, Perp: 4.83, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [2/26], Loss: 1.567, Perp: 4.79, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [3/26], Loss: 1.562, Perp: 4.77, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [4/26], Loss: 1.560, Perp: 4.76, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [5/26], Loss: 1.558, Perp: 4.75, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [6/26], Loss: 1.556, Perp: 4.74, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [7/26], Loss: 1.555, Perp: 4.73, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [8/26], Loss: 1.554, Perp: 4.73, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [9/26], Loss: 1.553, Perp: 4.73, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [10/26], Loss: 1.552, Perp: 4.72, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [11/26], Loss: 1.551, Perp: 4.72, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [12/26], Loss: 1.550, Perp: 4.71, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [13/26], Loss: 1.550, Perp: 4.71, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [14/26], Loss: 1.549, Perp: 4.71, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [15/26], Loss: 1.548, Perp: 4.70, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [16/26], Loss: 1.548, Perp: 4.70, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [17/26], Loss: 1.547, Perp: 4.70, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [18/26], Loss: 1.546, Perp: 4.69, Acc: 0.71           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [19/26], Loss: 1.546, Perp: 4.69, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [20/26], Loss: 1.545, Perp: 4.69, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [21/26], Loss: 1.545, Perp: 4.69, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [22/26], Loss: 1.544, Perp: 4.69, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [23/26], Loss: 1.544, Perp: 4.68, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [24/26], Loss: 1.544, Perp: 4.68, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [25/26], Loss: 1.543, Perp: 4.68, Acc: 0.72           here\n",
      "here\n",
      "Validation: Epoch [40/40], Step [26/26], Loss: 1.543, Perp: 4.68, Acc: 0.72           "
     ]
    }
   ],
   "source": [
    "hist = train(model, trn_ids, val_ids, \n",
    "             criterion, optimizer, scheduler, \n",
    "             num_epochs, batch_size, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'masnavi-lm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 494\n",
      "1: 240\n",
      "2: 170\n",
      "3: 96\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "p = torch.FloatTensor([0.5, 0.25, 0.15, 0.10])\n",
    "p = torch.FloatTensor([50, 25, 15, 10])\n",
    "\n",
    "counter = Counter()\n",
    "# Draw N samples\n",
    "for _ in range(N):\n",
    "    sample = torch.multinomial(p, num_samples=1, replacement=True).numpy()[0]\n",
    "    counter[sample] += 1\n",
    "\n",
    "for sample, count in counter.most_common():\n",
    "    print(\"{:d}: {:2d}\".format(sample, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(model, sample_len):\n",
    "    model.eval()\n",
    "    sample = ''\n",
    "    state = model.init_hidden(1)\n",
    "\n",
    "    # select a random word id to start sampling\n",
    "    probs = torch.ones(vocab_size)\n",
    "    inp = to_var(torch.multinomial(probs, num_samples=1).unsqueeze(1), volatile=True)\n",
    "    print (inp)\n",
    "    for i in tqdm_notebook(range(sample_len)):\n",
    "        output, state = model(inp, state)\n",
    "\n",
    "        # Sample an id\n",
    "        probs = output.squeeze().data.exp().cpu()\n",
    "        word_id = torch.multinomial(probs, 1).numpy()[0]\n",
    "\n",
    "        # Feed sampled word id to next time step\n",
    "        inp.data.fill_(word_id)\n",
    "\n",
    "        # write to file\n",
    "        word = corpus.vocabulary.index2word[word_id]\n",
    "        if word == '<EOS>':\n",
    "            sample += '\\n'\n",
    "        else:\n",
    "            sample += ' ' + word\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[23264]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdee0e1ae26640a0b3cee7c64f8906e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " کان به نیست بی جوهری\n",
      " نیست سر مرگ ما شرع\n",
      " مختلف هم حدث از ضلال\n",
      " باز سله و بی ندید\n",
      " خانه خونابه و زیر نیز\n",
      " که آسمانهاست و مردمان\n",
      " کای آسمانها از راه\n",
      " تا فرو دست دیو\n",
      " وقت بازرگان و پهلوان\n",
      " نقش یک فرو گشته\n",
      " یا فجر و خشک ها\n",
      " چون عقلند و می شنید\n",
      " تا مگیر و نبیه\n",
      " گرچه دیگر سازد چون حیات\n",
      " از حدوث و لا سقیم\n",
      " از رحمت و در نالیده\n",
      " شه خر ز لطف القلوب\n",
      " چونک در نیارد در بیم\n",
      " زانک اینست بتر سر حق\n",
      " کو شدی تا جود و جو\n",
      " ای زیان ز سایه و ما\n",
      " لقمه بحر اگر یافت\n",
      " آدمی چندان چو در نهاد\n",
      " پیش اژدرها و سوز تنگ\n",
      " کای یزدان بی باغ\n",
      " دردسر و شراب کان\n",
      " کرده پیمودن ز قهر خویش\n",
      " که نعیم و کم ساز\n",
      " گاو مرده چه می نمود\n",
      " ای صاحب چو می خوردمی\n",
      " از قصه هر می آمدی\n",
      " این مخنث و می نجست\n",
      " معده و شهسواران آن ندید\n",
      " در حی که در یافتند\n",
      " زندگی در\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_LM(vocab_size, embed_size=1500, hidden_size=1500, num_layers=2)\n",
    "model.load_state_dict(torch.load('masnavi-lm.pth'))\n",
    "model = model.cuda()\n",
    "sample = get_sample(model, 200)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_LM(vocab_size, embed_size=1500, hidden_size=1500, num_layers=2)\n",
    "model.load_state_dict(torch.load('lm-masnavi-epoch-38-em-1500-hi-1500-nl-2-1.53-4.63.pth'))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[18976]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb1b421b352444aae8493d4ffe322cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " هر دو پیش دین\n",
      " تا العارفین بر ترس\n",
      " زان به زخم می\n",
      " تا شهواتنا آن شرع\n",
      " تا اسباب و زیر و کشند\n",
      " چار تقوی یک مرد سخت\n",
      " وا زراد و ملک مرد\n",
      " بود دیگر و دیو و چفت\n",
      " گرگ را دهد یک بدان\n",
      " ای قلاووزم این مشکل\n",
      " از کف خوار چون بهشت\n",
      " تا استانید و خانه بود\n",
      " همچو دانیش سوی خواب\n",
      " که حمال و بانگ گرفت\n",
      " دست ندیده می خانه رسید\n",
      " صدقوهم و کف و بود\n",
      " در حسد و دار و سخن\n",
      " که جنبیکم و حیلت و\n",
      " ای گبری و ره و\n",
      " هست دوزانند از خانه تنگ\n",
      " ای اذان از سر به\n",
      " در درویشی و تا خاص\n",
      " چنگ بگریزد بر گردون\n",
      " جوش بگریزد بر بحر\n",
      " کز گردونست و پاکی\n",
      " بی هوای باز چرخ\n",
      " کو حیات رفته ساز\n",
      " هاویه و نموده و\n",
      " می درمانده بی حال\n",
      " پرده ساله و داد\n",
      " گر تغب و طاووس\n",
      " کای عیسی شده پیش بشیر\n",
      " قطره گشته آراست و ریش\n",
      " پیش صد ندیدی بی یقین\n",
      " بس دیگر گشته از قبور\n",
      " لیک رب بود بر زلتست\n",
      " لیک یک خفتن و انتقام\n",
      " زهر زن پیش ای ستیر\n",
      " هرچه چه نگردد چون عزیز\n",
      " چون گشادش و هر چه\n",
      " باز برگیرم بهر بحر و\n",
      " همچو اینجا چو ناری\n",
      " وآن حیوان و عار\n",
      " کرد هر حالهای در کریم\n",
      " ز بحرم و در میگذرد\n",
      " سر دیگر کاندرین در غرف\n",
      " لیک ما و فعل کاسدست\n",
      " قوت و ترکیب و سماع\n",
      " سست دان بر آتش حلق\n",
      " تا فزونی و سرگین\n",
      " گوهر پنهان برآرد و خطاب\n",
      " چون مرادت و جای\n",
      " بخوان آخر رها\n"
     ]
    }
   ],
   "source": [
    "sample = get_sample(model, 300)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
